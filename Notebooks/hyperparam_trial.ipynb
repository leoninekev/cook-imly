{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Iris dataset to test #\n",
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "dataset_name = \"UCI Iris\"\n",
    "dataset_info = automation_script.get_url(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import iris dataset #\n",
    "url = \"../data/iris.csv\" if path.exists(\"../data/iris.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
    "class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "data.iloc[:,-1] = index\n",
    "data = data.loc[data[4] != 2]\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "type(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "scikit_score, scikit_params, predictions = automation_script.get_scikit_params(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.Series(predictions)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 1ms/step\n",
      "60/60 [==============================] - 0s 270us/step\n",
      "\n",
      "acc: 93.33%\n",
      "\n",
      "acc: 93.33%\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'epoch': 200,\n",
    "    'batch_size': 10,\n",
    "    'verbose': 0,\n",
    "    'model_info': {\n",
    "        'loss':'binary_crossentropy',\n",
    "        'optimizer':'adam',\n",
    "        'metrics':['accuracy']\n",
    "    }\n",
    "}\n",
    "\n",
    "keras_score,keras_params = automation_script.get_keras_params(X,Y,predictions,dataset_info,config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Talos trial ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/48 [00:00<?, ?it/s]\n",
      "\n",
      "  2%|▏         | 1/48 [00:06<05:05,  6.50s/it]\n",
      "\n",
      "  4%|▍         | 2/48 [00:15<05:28,  7.13s/it]\n",
      "\n",
      "  6%|▋         | 3/48 [00:22<05:25,  7.24s/it]\n",
      "\n",
      "  8%|▊         | 4/48 [00:30<05:26,  7.41s/it]\n",
      "\n",
      " 10%|█         | 5/48 [00:36<04:58,  6.94s/it]\n",
      "\n",
      " 12%|█▎        | 6/48 [00:43<04:56,  7.05s/it]\n",
      "\n",
      " 15%|█▍        | 7/48 [00:48<04:23,  6.44s/it]\n",
      "\n",
      " 17%|█▋        | 8/48 [00:53<03:57,  5.94s/it]\n",
      "\n",
      " 19%|█▉        | 9/48 [00:58<03:45,  5.77s/it]\n",
      "\n",
      " 21%|██        | 10/48 [01:06<03:57,  6.25s/it]\n",
      "\n",
      " 23%|██▎       | 11/48 [01:13<04:09,  6.73s/it]\n",
      "\n",
      " 25%|██▌       | 12/48 [01:19<03:54,  6.51s/it]\n",
      "\n",
      " 27%|██▋       | 13/48 [01:25<03:34,  6.12s/it]\n",
      "\n",
      " 29%|██▉       | 14/48 [01:34<03:58,  7.02s/it]\n",
      "\n",
      " 31%|███▏      | 15/48 [01:41<03:56,  7.16s/it]\n",
      "\n",
      " 33%|███▎      | 16/48 [01:46<03:28,  6.50s/it]\n",
      "\n",
      " 35%|███▌      | 17/48 [01:52<03:18,  6.40s/it]\n",
      "\n",
      " 38%|███▊      | 18/48 [01:58<03:05,  6.18s/it]\n",
      "\n",
      " 40%|███▉      | 19/48 [02:06<03:14,  6.70s/it]\n",
      "\n",
      " 42%|████▏     | 20/48 [02:12<02:59,  6.42s/it]\n",
      "\n",
      " 44%|████▍     | 21/48 [02:18<02:48,  6.24s/it]\n",
      "\n",
      " 46%|████▌     | 22/48 [02:27<03:11,  7.35s/it]\n",
      "\n",
      " 48%|████▊     | 23/48 [02:33<02:49,  6.79s/it]\n",
      "\n",
      " 50%|█████     | 24/48 [02:38<02:33,  6.38s/it]\n",
      "\n",
      " 52%|█████▏    | 25/48 [02:45<02:26,  6.36s/it]\n",
      "\n",
      " 54%|█████▍    | 26/48 [02:53<02:33,  6.99s/it]\n",
      "\n",
      " 56%|█████▋    | 27/48 [02:58<02:12,  6.30s/it]\n",
      "\n",
      " 58%|█████▊    | 28/48 [03:02<01:51,  5.55s/it]\n",
      "\n",
      " 60%|██████    | 29/48 [03:12<02:12,  6.96s/it]\n",
      "\n",
      " 62%|██████▎   | 30/48 [03:26<02:41,  8.97s/it]\n",
      "\n",
      " 65%|██████▍   | 31/48 [03:37<02:45,  9.75s/it]\n",
      "\n",
      " 67%|██████▋   | 32/48 [03:46<02:30,  9.43s/it]\n",
      "\n",
      " 69%|██████▉   | 33/48 [03:59<02:40, 10.70s/it]\n",
      "\n",
      " 71%|███████   | 34/48 [04:06<02:13,  9.57s/it]\n",
      "\n",
      " 73%|███████▎  | 35/48 [04:17<02:06,  9.73s/it]\n",
      "\n",
      " 75%|███████▌  | 36/48 [04:26<01:55,  9.63s/it]\n",
      "\n",
      " 77%|███████▋  | 37/48 [04:35<01:45,  9.57s/it]\n",
      "\n",
      " 79%|███████▉  | 38/48 [04:41<01:22,  8.27s/it]\n",
      "\n",
      " 81%|████████▏ | 39/48 [04:46<01:07,  7.47s/it]\n",
      "\n",
      " 83%|████████▎ | 40/48 [04:54<00:59,  7.49s/it]\n",
      "\n",
      " 85%|████████▌ | 41/48 [04:59<00:48,  6.89s/it]\n",
      "\n",
      " 88%|████████▊ | 42/48 [05:08<00:45,  7.52s/it]\n",
      "\n",
      " 90%|████████▉ | 43/48 [05:17<00:39,  7.98s/it]\n",
      "\n",
      " 92%|█████████▏| 44/48 [05:23<00:29,  7.25s/it]\n",
      "\n",
      " 94%|█████████▍| 45/48 [05:30<00:21,  7.31s/it]\n",
      "\n",
      " 96%|█████████▌| 46/48 [05:38<00:14,  7.41s/it]\n",
      "\n",
      " 98%|█████████▊| 47/48 [05:44<00:06,  6.91s/it]\n",
      "\n",
      "100%|██████████| 48/48 [05:51<00:00,  7.07s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.losses import categorical_crossentropy, logcosh\n",
    "from keras.activations import sigmoid\n",
    "import talos as ta\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x, y = ta.datasets.iris()\n",
    "\n",
    "# then define the parameter boundaries\n",
    "\n",
    "p = {'lr': (2, 10, 30),\n",
    "     'first_neuron': [3],\n",
    "     'batch_size': [20, 30, 40],\n",
    "     'epochs': [300],\n",
    "     'weight_regulizer': [None],\n",
    "     'emb_output_dims': [None],\n",
    "     'optimizer': ['adam', 'nadam'],\n",
    "     'losses': [categorical_crossentropy, logcosh],\n",
    "     'activation': [sigmoid]\n",
    "    }\n",
    "\n",
    "\n",
    "# then define your Keras model\n",
    "def iris_model(x_train, y_train, x_val, y_val, params):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'],\n",
    "                    input_dim=x_train.shape[1],\n",
    "                    activation=params['activation']))\n",
    "\n",
    "    model.compile(optimizer=params['optimizer'],\n",
    "                  loss=params['losses'],\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    out = model.fit(x_train, y_train,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'],\n",
    "                    verbose=0,\n",
    "                    validation_data=[x_val, y_val])\n",
    "\n",
    "    return out, model\n",
    "\n",
    "\n",
    "# and run the scan\n",
    "h = ta.Scan(x, y,\n",
    "            params=p,\n",
    "            dataset_name='first_test',\n",
    "            experiment_no='a',\n",
    "            model=iris_model,\n",
    "            grid_downsample=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
