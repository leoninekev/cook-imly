{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps involved in creating a neural network #\n",
    "\n",
    "1) Define the model\n",
    "2) Compile the model\n",
    "3) Fit the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object <genexpr> at 0x7f0d487441a8>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(<generator object <genexpr> at 0x7f0d5a2cd410>, dtype=object) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-85532fa37cd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2072\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2074\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2076\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \"\"\"\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \"\"\"\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[0;32m--> 142\u001b[0;31m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Singleton array array(<generator object <genexpr> at 0x7f0d5a2cd410>, dtype=object) cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "# Import iris dataset #\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "# X = (x for x in X if Y!=2)\n",
    "# Y = (y for y in Y if Y!=2)\n",
    "# Convert to dataframes/ numpy arrays #\n",
    "iris.data.shape\n",
    "print(Y)\n",
    "\n",
    "\n",
    "# Split the dataset into test and train datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.7497 - acc: 0.2833\n",
      "Epoch 2/150\n",
      "60/60 [==============================] - 0s 113us/step - loss: 0.7338 - acc: 0.2833\n",
      "Epoch 3/150\n",
      "60/60 [==============================] - 0s 83us/step - loss: 0.7146 - acc: 0.2833\n",
      "Epoch 4/150\n",
      "60/60 [==============================] - 0s 73us/step - loss: 0.6997 - acc: 0.2833\n",
      "Epoch 5/150\n",
      "60/60 [==============================] - 0s 107us/step - loss: 0.6845 - acc: 0.2833\n",
      "Epoch 6/150\n",
      "60/60 [==============================] - 0s 105us/step - loss: 0.6677 - acc: 0.2833\n",
      "Epoch 7/150\n",
      "60/60 [==============================] - 0s 111us/step - loss: 0.6531 - acc: 0.2833\n",
      "Epoch 8/150\n",
      "60/60 [==============================] - 0s 85us/step - loss: 0.6386 - acc: 0.2833\n",
      "Epoch 9/150\n",
      "60/60 [==============================] - 0s 117us/step - loss: 0.6266 - acc: 0.2833\n",
      "Epoch 10/150\n",
      "60/60 [==============================] - 0s 107us/step - loss: 0.6132 - acc: 0.2833\n",
      "Epoch 11/150\n",
      "60/60 [==============================] - 0s 115us/step - loss: 0.5984 - acc: 0.2833\n",
      "Epoch 12/150\n",
      "60/60 [==============================] - 0s 94us/step - loss: 0.5853 - acc: 0.2833\n",
      "Epoch 13/150\n",
      "60/60 [==============================] - 0s 126us/step - loss: 0.5709 - acc: 0.2833\n",
      "Epoch 14/150\n",
      "60/60 [==============================] - 0s 81us/step - loss: 0.5608 - acc: 0.2833\n",
      "Epoch 15/150\n",
      "60/60 [==============================] - 0s 76us/step - loss: 0.5469 - acc: 0.2833\n",
      "Epoch 16/150\n",
      "60/60 [==============================] - 0s 112us/step - loss: 0.5332 - acc: 0.2833\n",
      "Epoch 17/150\n",
      "60/60 [==============================] - 0s 102us/step - loss: 0.5216 - acc: 0.2833\n",
      "Epoch 18/150\n",
      "60/60 [==============================] - 0s 122us/step - loss: 0.5093 - acc: 0.2833\n",
      "Epoch 19/150\n",
      "60/60 [==============================] - 0s 86us/step - loss: 0.4982 - acc: 0.2833\n",
      "Epoch 20/150\n",
      "60/60 [==============================] - 0s 71us/step - loss: 0.4843 - acc: 0.2833\n",
      "Epoch 21/150\n",
      "60/60 [==============================] - 0s 146us/step - loss: 0.4729 - acc: 0.2833\n",
      "Epoch 22/150\n",
      "60/60 [==============================] - 0s 125us/step - loss: 0.4606 - acc: 0.2833\n",
      "Epoch 23/150\n",
      "60/60 [==============================] - 0s 105us/step - loss: 0.4498 - acc: 0.2833\n",
      "Epoch 24/150\n",
      "60/60 [==============================] - 0s 76us/step - loss: 0.4387 - acc: 0.2833\n",
      "Epoch 25/150\n",
      "60/60 [==============================] - 0s 142us/step - loss: 0.4275 - acc: 0.2833\n",
      "Epoch 26/150\n",
      "60/60 [==============================] - 0s 150us/step - loss: 0.4148 - acc: 0.2833\n",
      "Epoch 27/150\n",
      "60/60 [==============================] - 0s 88us/step - loss: 0.4053 - acc: 0.2833\n",
      "Epoch 28/150\n",
      "60/60 [==============================] - 0s 86us/step - loss: 0.3931 - acc: 0.2833\n",
      "Epoch 29/150\n",
      "60/60 [==============================] - 0s 135us/step - loss: 0.3811 - acc: 0.2833\n",
      "Epoch 30/150\n",
      "60/60 [==============================] - 0s 95us/step - loss: 0.3702 - acc: 0.2833\n",
      "Epoch 31/150\n",
      "60/60 [==============================] - 0s 128us/step - loss: 0.3598 - acc: 0.2833\n",
      "Epoch 32/150\n",
      "60/60 [==============================] - 0s 96us/step - loss: 0.3482 - acc: 0.2833\n",
      "Epoch 33/150\n",
      "60/60 [==============================] - 0s 124us/step - loss: 0.3375 - acc: 0.2833\n",
      "Epoch 34/150\n",
      "60/60 [==============================] - 0s 105us/step - loss: 0.3265 - acc: 0.2833\n",
      "Epoch 35/150\n",
      "60/60 [==============================] - 0s 86us/step - loss: 0.3153 - acc: 0.2833\n",
      "Epoch 36/150\n",
      "60/60 [==============================] - 0s 116us/step - loss: 0.3048 - acc: 0.2833\n",
      "Epoch 37/150\n",
      "60/60 [==============================] - 0s 101us/step - loss: 0.2942 - acc: 0.2833\n",
      "Epoch 38/150\n",
      "60/60 [==============================] - 0s 95us/step - loss: 0.2840 - acc: 0.2833\n",
      "Epoch 39/150\n",
      "60/60 [==============================] - 0s 183us/step - loss: 0.2723 - acc: 0.2833\n",
      "Epoch 40/150\n",
      "60/60 [==============================] - 0s 101us/step - loss: 0.2608 - acc: 0.2833\n",
      "Epoch 41/150\n",
      "60/60 [==============================] - 0s 76us/step - loss: 0.2509 - acc: 0.2833\n",
      "Epoch 42/150\n",
      "60/60 [==============================] - 0s 140us/step - loss: 0.2424 - acc: 0.2833\n",
      "Epoch 43/150\n",
      "60/60 [==============================] - 0s 87us/step - loss: 0.2289 - acc: 0.2833\n",
      "Epoch 44/150\n",
      "60/60 [==============================] - 0s 120us/step - loss: 0.2191 - acc: 0.2833\n",
      "Epoch 45/150\n",
      "60/60 [==============================] - 0s 82us/step - loss: 0.2087 - acc: 0.2833\n",
      "Epoch 46/150\n",
      "60/60 [==============================] - 0s 89us/step - loss: 0.1981 - acc: 0.2833\n",
      "Epoch 47/150\n",
      "60/60 [==============================] - 0s 133us/step - loss: 0.1870 - acc: 0.2833\n",
      "Epoch 48/150\n",
      "60/60 [==============================] - 0s 111us/step - loss: 0.1762 - acc: 0.2833\n",
      "Epoch 49/150\n",
      "60/60 [==============================] - 0s 118us/step - loss: 0.1666 - acc: 0.2833\n",
      "Epoch 50/150\n",
      "60/60 [==============================] - 0s 95us/step - loss: 0.1556 - acc: 0.2833\n",
      "Epoch 51/150\n",
      "60/60 [==============================] - 0s 120us/step - loss: 0.1453 - acc: 0.2833\n",
      "Epoch 52/150\n",
      "60/60 [==============================] - 0s 100us/step - loss: 0.1354 - acc: 0.2833\n",
      "Epoch 53/150\n",
      "60/60 [==============================] - 0s 79us/step - loss: 0.1248 - acc: 0.2833\n",
      "Epoch 54/150\n",
      "60/60 [==============================] - 0s 133us/step - loss: 0.1141 - acc: 0.2833\n",
      "Epoch 55/150\n",
      "60/60 [==============================] - 0s 75us/step - loss: 0.1036 - acc: 0.2833\n",
      "Epoch 56/150\n",
      "60/60 [==============================] - 0s 145us/step - loss: 0.0949 - acc: 0.2833\n",
      "Epoch 57/150\n",
      "60/60 [==============================] - 0s 120us/step - loss: 0.0831 - acc: 0.2833\n",
      "Epoch 58/150\n",
      "60/60 [==============================] - 0s 92us/step - loss: 0.0727 - acc: 0.2833\n",
      "Epoch 59/150\n",
      "60/60 [==============================] - 0s 141us/step - loss: 0.0623 - acc: 0.2833\n",
      "Epoch 60/150\n",
      "60/60 [==============================] - 0s 113us/step - loss: 0.0533 - acc: 0.2833\n",
      "Epoch 61/150\n",
      "60/60 [==============================] - 0s 102us/step - loss: 0.0426 - acc: 0.2833\n",
      "Epoch 62/150\n",
      "60/60 [==============================] - 0s 87us/step - loss: 0.0323 - acc: 0.2833\n",
      "Epoch 63/150\n",
      "60/60 [==============================] - 0s 122us/step - loss: 0.0217 - acc: 0.2833\n",
      "Epoch 64/150\n",
      "60/60 [==============================] - 0s 92us/step - loss: 0.0114 - acc: 0.2833\n",
      "Epoch 65/150\n",
      "60/60 [==============================] - 0s 98us/step - loss: 0.0023 - acc: 0.2833\n",
      "Epoch 66/150\n",
      "60/60 [==============================] - 0s 109us/step - loss: -0.0096 - acc: 0.2833\n",
      "Epoch 67/150\n",
      "60/60 [==============================] - 0s 89us/step - loss: -0.0179 - acc: 0.2833\n",
      "Epoch 68/150\n",
      "60/60 [==============================] - 0s 86us/step - loss: -0.0286 - acc: 0.2833\n",
      "Epoch 69/150\n",
      "60/60 [==============================] - 0s 91us/step - loss: -0.0391 - acc: 0.2833\n",
      "Epoch 70/150\n",
      "60/60 [==============================] - 0s 79us/step - loss: -0.0483 - acc: 0.2833\n",
      "Epoch 71/150\n",
      "60/60 [==============================] - 0s 86us/step - loss: -0.0592 - acc: 0.2833\n",
      "Epoch 72/150\n",
      "60/60 [==============================] - 0s 98us/step - loss: -0.0689 - acc: 0.2833\n",
      "Epoch 73/150\n",
      "60/60 [==============================] - 0s 89us/step - loss: -0.0791 - acc: 0.2833\n",
      "Epoch 74/150\n",
      "60/60 [==============================] - 0s 87us/step - loss: -0.0890 - acc: 0.2833\n",
      "Epoch 75/150\n",
      "60/60 [==============================] - 0s 130us/step - loss: -0.0997 - acc: 0.2833\n",
      "Epoch 76/150\n",
      "60/60 [==============================] - 0s 88us/step - loss: -0.1091 - acc: 0.2833\n",
      "Epoch 77/150\n",
      "60/60 [==============================] - 0s 88us/step - loss: -0.1197 - acc: 0.2833\n",
      "Epoch 78/150\n",
      "60/60 [==============================] - 0s 84us/step - loss: -0.1291 - acc: 0.2833\n",
      "Epoch 79/150\n",
      "60/60 [==============================] - 0s 89us/step - loss: -0.1394 - acc: 0.2833\n",
      "Epoch 80/150\n",
      "60/60 [==============================] - 0s 92us/step - loss: -0.1487 - acc: 0.2833\n",
      "Epoch 81/150\n",
      "60/60 [==============================] - 0s 92us/step - loss: -0.1585 - acc: 0.2833\n",
      "Epoch 82/150\n",
      "60/60 [==============================] - 0s 85us/step - loss: -0.1685 - acc: 0.2833\n",
      "Epoch 83/150\n",
      "60/60 [==============================] - 0s 92us/step - loss: -0.1785 - acc: 0.2833\n",
      "Epoch 84/150\n",
      "60/60 [==============================] - 0s 121us/step - loss: -0.1900 - acc: 0.2833\n",
      "Epoch 85/150\n",
      "60/60 [==============================] - 0s 103us/step - loss: -0.1985 - acc: 0.2833\n",
      "Epoch 86/150\n",
      "60/60 [==============================] - 0s 117us/step - loss: -0.2086 - acc: 0.2833\n",
      "Epoch 87/150\n",
      "60/60 [==============================] - 0s 99us/step - loss: -0.2195 - acc: 0.2833\n",
      "Epoch 88/150\n",
      "60/60 [==============================] - 0s 93us/step - loss: -0.2286 - acc: 0.2833\n",
      "Epoch 89/150\n",
      "60/60 [==============================] - 0s 90us/step - loss: -0.2396 - acc: 0.2833\n",
      "Epoch 90/150\n",
      "60/60 [==============================] - 0s 94us/step - loss: -0.2485 - acc: 0.2833\n",
      "Epoch 91/150\n",
      "60/60 [==============================] - 0s 80us/step - loss: -0.2581 - acc: 0.2833\n",
      "Epoch 92/150\n",
      "60/60 [==============================] - 0s 75us/step - loss: -0.2690 - acc: 0.2833\n",
      "Epoch 93/150\n",
      "60/60 [==============================] - 0s 90us/step - loss: -0.2786 - acc: 0.2833\n",
      "Epoch 94/150\n",
      "60/60 [==============================] - 0s 78us/step - loss: -0.2888 - acc: 0.2833\n",
      "Epoch 95/150\n",
      "60/60 [==============================] - 0s 81us/step - loss: -0.2981 - acc: 0.2833\n",
      "Epoch 96/150\n",
      "60/60 [==============================] - 0s 109us/step - loss: -0.3093 - acc: 0.2833\n",
      "Epoch 97/150\n",
      "60/60 [==============================] - 0s 83us/step - loss: -0.3182 - acc: 0.2833\n",
      "Epoch 98/150\n",
      "60/60 [==============================] - 0s 74us/step - loss: -0.3288 - acc: 0.2833\n",
      "Epoch 99/150\n",
      "60/60 [==============================] - 0s 128us/step - loss: -0.3384 - acc: 0.2833\n",
      "Epoch 100/150\n",
      "60/60 [==============================] - 0s 77us/step - loss: -0.3491 - acc: 0.2833\n",
      "Epoch 101/150\n",
      "60/60 [==============================] - 0s 76us/step - loss: -0.3583 - acc: 0.2833\n",
      "Epoch 102/150\n",
      "60/60 [==============================] - 0s 101us/step - loss: -0.3679 - acc: 0.2833\n",
      "Epoch 103/150\n",
      "60/60 [==============================] - 0s 90us/step - loss: -0.3783 - acc: 0.2833\n",
      "Epoch 104/150\n",
      "60/60 [==============================] - 0s 76us/step - loss: -0.3886 - acc: 0.2833\n",
      "Epoch 105/150\n",
      "60/60 [==============================] - 0s 98us/step - loss: -0.3987 - acc: 0.2833\n",
      "Epoch 106/150\n",
      "60/60 [==============================] - 0s 98us/step - loss: -0.4091 - acc: 0.2833\n",
      "Epoch 107/150\n",
      "60/60 [==============================] - 0s 74us/step - loss: -0.4171 - acc: 0.2833\n",
      "Epoch 108/150\n",
      "60/60 [==============================] - 0s 82us/step - loss: -0.4273 - acc: 0.2833\n",
      "Epoch 109/150\n",
      "60/60 [==============================] - 0s 89us/step - loss: -0.4394 - acc: 0.2833\n",
      "Epoch 110/150\n",
      "60/60 [==============================] - 0s 84us/step - loss: -0.4486 - acc: 0.2833\n",
      "Epoch 111/150\n",
      "60/60 [==============================] - 0s 86us/step - loss: -0.4585 - acc: 0.2833\n",
      "Epoch 112/150\n",
      "60/60 [==============================] - 0s 152us/step - loss: -0.4685 - acc: 0.2833\n",
      "Epoch 113/150\n",
      "60/60 [==============================] - 0s 82us/step - loss: -0.4781 - acc: 0.2833\n",
      "Epoch 114/150\n",
      "60/60 [==============================] - 0s 91us/step - loss: -0.4886 - acc: 0.2833\n",
      "Epoch 115/150\n",
      "60/60 [==============================] - 0s 97us/step - loss: -0.4983 - acc: 0.2833\n",
      "Epoch 116/150\n",
      "60/60 [==============================] - 0s 80us/step - loss: -0.5067 - acc: 0.2833\n",
      "Epoch 117/150\n",
      "60/60 [==============================] - 0s 92us/step - loss: -0.5169 - acc: 0.2833\n",
      "Epoch 118/150\n",
      "60/60 [==============================] - 0s 94us/step - loss: -0.5282 - acc: 0.2833\n",
      "Epoch 119/150\n",
      "60/60 [==============================] - 0s 85us/step - loss: -0.5389 - acc: 0.2833\n",
      "Epoch 120/150\n",
      "60/60 [==============================] - 0s 108us/step - loss: -0.5483 - acc: 0.2833\n",
      "Epoch 121/150\n",
      "60/60 [==============================] - 0s 85us/step - loss: -0.5585 - acc: 0.2833\n",
      "Epoch 122/150\n",
      "60/60 [==============================] - ETA: 0s - loss: -1.5637 - acc: 0.30 - 0s 78us/step - loss: -0.5680 - acc: 0.2833\n",
      "Epoch 123/150\n",
      "60/60 [==============================] - 0s 99us/step - loss: -0.5782 - acc: 0.2833\n",
      "Epoch 124/150\n",
      "60/60 [==============================] - 0s 83us/step - loss: -0.5881 - acc: 0.2833\n",
      "Epoch 125/150\n",
      "60/60 [==============================] - 0s 79us/step - loss: -0.5982 - acc: 0.2833\n",
      "Epoch 126/150\n",
      "60/60 [==============================] - 0s 115us/step - loss: -0.6071 - acc: 0.2833\n",
      "Epoch 127/150\n",
      "60/60 [==============================] - 0s 95us/step - loss: -0.6179 - acc: 0.2833\n",
      "Epoch 128/150\n",
      "60/60 [==============================] - 0s 90us/step - loss: -0.6281 - acc: 0.2833\n",
      "Epoch 129/150\n",
      "60/60 [==============================] - 0s 95us/step - loss: -0.6371 - acc: 0.2833\n",
      "Epoch 130/150\n",
      "60/60 [==============================] - 0s 78us/step - loss: -0.6474 - acc: 0.2833\n",
      "Epoch 131/150\n",
      "60/60 [==============================] - 0s 86us/step - loss: -0.6578 - acc: 0.2833\n",
      "Epoch 132/150\n",
      "60/60 [==============================] - 0s 88us/step - loss: -0.6655 - acc: 0.2833\n",
      "Epoch 133/150\n",
      "60/60 [==============================] - 0s 85us/step - loss: -0.6764 - acc: 0.2833\n",
      "Epoch 134/150\n",
      "60/60 [==============================] - 0s 86us/step - loss: -0.6881 - acc: 0.2833\n",
      "Epoch 135/150\n",
      "60/60 [==============================] - 0s 131us/step - loss: -0.6976 - acc: 0.2833\n",
      "Epoch 136/150\n",
      "60/60 [==============================] - 0s 86us/step - loss: -0.7075 - acc: 0.2833\n",
      "Epoch 137/150\n",
      "60/60 [==============================] - 0s 106us/step - loss: -0.7161 - acc: 0.2833\n",
      "Epoch 138/150\n",
      "60/60 [==============================] - 0s 106us/step - loss: -0.7273 - acc: 0.2833\n",
      "Epoch 139/150\n",
      "60/60 [==============================] - 0s 103us/step - loss: -0.7370 - acc: 0.2833\n",
      "Epoch 140/150\n",
      "60/60 [==============================] - 0s 89us/step - loss: -0.7474 - acc: 0.2833\n",
      "Epoch 141/150\n",
      "60/60 [==============================] - 0s 90us/step - loss: -0.7566 - acc: 0.2833\n",
      "Epoch 142/150\n",
      "60/60 [==============================] - 0s 81us/step - loss: -0.7673 - acc: 0.2833\n",
      "Epoch 143/150\n",
      "60/60 [==============================] - 0s 117us/step - loss: -0.7765 - acc: 0.2833\n",
      "Epoch 144/150\n",
      "60/60 [==============================] - 0s 86us/step - loss: -0.7866 - acc: 0.2833\n",
      "Epoch 145/150\n",
      "60/60 [==============================] - 0s 86us/step - loss: -0.7967 - acc: 0.2833\n",
      "Epoch 146/150\n",
      "60/60 [==============================] - 0s 122us/step - loss: -0.8066 - acc: 0.2833\n",
      "Epoch 147/150\n",
      "60/60 [==============================] - 0s 101us/step - loss: -0.8174 - acc: 0.2833\n",
      "Epoch 148/150\n",
      "60/60 [==============================] - 0s 134us/step - loss: -0.8268 - acc: 0.2833\n",
      "Epoch 149/150\n",
      "60/60 [==============================] - 0s 94us/step - loss: -0.8370 - acc: 0.2833\n",
      "Epoch 150/150\n",
      "60/60 [==============================] - 0s 87us/step - loss: -0.8457 - acc: 0.2833\n",
      "90/90 [==============================] - 0s 417us/step\n",
      "\n",
      "acc: 36.67%\n"
     ]
    }
   ],
   "source": [
    "### Logistic regression using DNN ###\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import numpy\n",
    "numpy.random.seed(7)\n",
    "\n",
    "# Defining model #\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1,input_dim=4,activation='sigmoid'))\n",
    "# model.add(Dense(16,activation='sigmoid'))\n",
    "# model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "# Compile the model #\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model #\n",
    "\n",
    "model.fit(x_train, y_train, epochs=150, batch_size=10)\n",
    "# model.summary()\n",
    "\n",
    "# Precision #\n",
    "\n",
    "# Confusion matrix #\n",
    "\n",
    "\n",
    "# Evaluate the model #\n",
    "\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 26  0]\n",
      " [ 0 33  0]\n",
      " [ 0 31  0]]\n"
     ]
    }
   ],
   "source": [
    "# Prediction #\n",
    "prediction = model.predict(x_test)\n",
    "prediction = (prediction>0.5)\n",
    "# prediction.shape\n",
    "# print(prediction)\n",
    "\n",
    "# Creating the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, prediction)\n",
    "print(cm)\n",
    "# Remove the 3rd class #\n",
    "# Loss function and response variable encoding(y_observed) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "150/150 [==============================] - 0s 736us/step - loss: 14.5943 - acc: 0.0000e+00\n",
      "Epoch 2/150\n",
      "150/150 [==============================] - 0s 78us/step - loss: 14.2649 - acc: 0.0000e+00\n",
      "Epoch 3/150\n",
      "150/150 [==============================] - 0s 52us/step - loss: 13.9160 - acc: 0.0000e+00\n",
      "Epoch 4/150\n",
      "150/150 [==============================] - 0s 69us/step - loss: 13.5840 - acc: 0.0000e+00\n",
      "Epoch 5/150\n",
      "150/150 [==============================] - 0s 59us/step - loss: 13.2629 - acc: 0.0000e+00\n",
      "Epoch 6/150\n",
      "150/150 [==============================] - 0s 89us/step - loss: 12.9343 - acc: 0.0000e+00\n",
      "Epoch 7/150\n",
      "150/150 [==============================] - 0s 57us/step - loss: 12.5969 - acc: 0.0000e+00\n",
      "Epoch 8/150\n",
      "150/150 [==============================] - 0s 62us/step - loss: 12.2641 - acc: 0.0000e+00\n",
      "Epoch 9/150\n",
      "150/150 [==============================] - 0s 73us/step - loss: 11.9373 - acc: 0.0000e+00\n",
      "Epoch 10/150\n",
      "150/150 [==============================] - 0s 69us/step - loss: 11.6006 - acc: 0.0000e+00\n",
      "Epoch 11/150\n",
      "150/150 [==============================] - 0s 60us/step - loss: 11.2680 - acc: 0.0000e+00\n",
      "Epoch 12/150\n",
      "150/150 [==============================] - 0s 56us/step - loss: 10.9373 - acc: 0.0000e+00\n",
      "Epoch 13/150\n",
      "150/150 [==============================] - 0s 82us/step - loss: 10.6188 - acc: 0.0000e+00\n",
      "Epoch 14/150\n",
      "150/150 [==============================] - 0s 63us/step - loss: 10.2730 - acc: 0.0000e+00\n",
      "Epoch 15/150\n",
      "150/150 [==============================] - 0s 82us/step - loss: 9.9460 - acc: 0.0000e+00\n",
      "Epoch 16/150\n",
      "150/150 [==============================] - 0s 64us/step - loss: 9.6056 - acc: 0.0000e+00\n",
      "Epoch 17/150\n",
      "150/150 [==============================] - 0s 79us/step - loss: 9.2829 - acc: 0.0000e+00\n",
      "Epoch 18/150\n",
      "150/150 [==============================] - 0s 70us/step - loss: 8.9356 - acc: 0.0000e+00\n",
      "Epoch 19/150\n",
      "150/150 [==============================] - 0s 72us/step - loss: 8.6158 - acc: 0.0000e+00\n",
      "Epoch 20/150\n",
      "150/150 [==============================] - 0s 59us/step - loss: 8.2780 - acc: 0.0000e+00\n",
      "Epoch 21/150\n",
      "150/150 [==============================] - 0s 89us/step - loss: 7.9418 - acc: 0.0000e+00\n",
      "Epoch 22/150\n",
      "150/150 [==============================] - 0s 61us/step - loss: 7.6112 - acc: 0.0000e+00\n",
      "Epoch 23/150\n",
      "150/150 [==============================] - 0s 78us/step - loss: 7.2775 - acc: 0.0000e+00\n",
      "Epoch 24/150\n",
      "150/150 [==============================] - 0s 67us/step - loss: 6.9619 - acc: 0.0000e+00\n",
      "Epoch 25/150\n",
      "150/150 [==============================] - 0s 74us/step - loss: 6.6155 - acc: 0.0000e+00\n",
      "Epoch 26/150\n",
      "150/150 [==============================] - 0s 87us/step - loss: 6.2945 - acc: 0.0000e+00\n",
      "Epoch 27/150\n",
      "150/150 [==============================] - 0s 89us/step - loss: 5.9510 - acc: 0.0000e+00\n",
      "Epoch 28/150\n",
      "150/150 [==============================] - 0s 91us/step - loss: 5.6290 - acc: 0.0000e+00\n",
      "Epoch 29/150\n",
      "150/150 [==============================] - 0s 81us/step - loss: 5.2868 - acc: 0.0000e+00\n",
      "Epoch 30/150\n",
      "150/150 [==============================] - 0s 79us/step - loss: 4.9732 - acc: 0.0000e+00\n",
      "Epoch 31/150\n",
      "150/150 [==============================] - 0s 87us/step - loss: 4.6262 - acc: 0.0000e+00\n",
      "Epoch 32/150\n",
      "150/150 [==============================] - 0s 76us/step - loss: 4.3040 - acc: 0.0000e+00\n",
      "Epoch 33/150\n",
      "150/150 [==============================] - 0s 69us/step - loss: 3.9558 - acc: 0.0000e+00\n",
      "Epoch 34/150\n",
      "150/150 [==============================] - 0s 77us/step - loss: 3.6362 - acc: 0.0000e+00\n",
      "Epoch 35/150\n",
      "150/150 [==============================] - 0s 62us/step - loss: 3.3046 - acc: 0.0000e+00\n",
      "Epoch 36/150\n",
      "150/150 [==============================] - 0s 81us/step - loss: 2.9821 - acc: 0.0000e+00\n",
      "Epoch 37/150\n",
      "150/150 [==============================] - 0s 76us/step - loss: 2.6388 - acc: 0.0000e+00\n",
      "Epoch 38/150\n",
      "150/150 [==============================] - 0s 86us/step - loss: 2.3042 - acc: 0.0000e+00\n",
      "Epoch 39/150\n",
      "150/150 [==============================] - 0s 86us/step - loss: 1.9806 - acc: 0.0000e+00\n",
      "Epoch 40/150\n",
      "150/150 [==============================] - 0s 86us/step - loss: 1.6663 - acc: 0.0067\n",
      "Epoch 41/150\n",
      "150/150 [==============================] - 0s 66us/step - loss: 1.3825 - acc: 0.0067\n",
      "Epoch 42/150\n",
      "150/150 [==============================] - 0s 84us/step - loss: 1.1169 - acc: 0.0133\n",
      "Epoch 43/150\n",
      "150/150 [==============================] - 0s 65us/step - loss: 0.8729 - acc: 0.0533\n",
      "Epoch 44/150\n",
      "150/150 [==============================] - 0s 77us/step - loss: 0.6834 - acc: 0.1600\n",
      "Epoch 45/150\n",
      "150/150 [==============================] - 0s 71us/step - loss: 0.5883 - acc: 0.2400\n",
      "Epoch 46/150\n",
      "150/150 [==============================] - 0s 75us/step - loss: 0.5322 - acc: 0.3000\n",
      "Epoch 47/150\n",
      "150/150 [==============================] - 0s 84us/step - loss: 0.5072 - acc: 0.3067\n",
      "Epoch 48/150\n",
      "150/150 [==============================] - 0s 71us/step - loss: 0.4870 - acc: 0.3133\n",
      "Epoch 49/150\n",
      "150/150 [==============================] - 0s 61us/step - loss: 0.4735 - acc: 0.3400\n",
      "Epoch 50/150\n",
      "150/150 [==============================] - 0s 88us/step - loss: 0.4637 - acc: 0.3800\n",
      "Epoch 51/150\n",
      "150/150 [==============================] - 0s 102us/step - loss: 0.4547 - acc: 0.4000\n",
      "Epoch 52/150\n",
      "150/150 [==============================] - 0s 64us/step - loss: 0.4493 - acc: 0.4333\n",
      "Epoch 53/150\n",
      "150/150 [==============================] - 0s 61us/step - loss: 0.4451 - acc: 0.4400\n",
      "Epoch 54/150\n",
      "150/150 [==============================] - 0s 86us/step - loss: 0.4414 - acc: 0.4467\n",
      "Epoch 55/150\n",
      "150/150 [==============================] - 0s 85us/step - loss: 0.4369 - acc: 0.4600\n",
      "Epoch 56/150\n",
      "150/150 [==============================] - 0s 79us/step - loss: 0.4334 - acc: 0.4800\n",
      "Epoch 57/150\n",
      "150/150 [==============================] - 0s 122us/step - loss: 0.4288 - acc: 0.5200\n",
      "Epoch 58/150\n",
      "150/150 [==============================] - 0s 89us/step - loss: 0.4244 - acc: 0.5467\n",
      "Epoch 59/150\n",
      "150/150 [==============================] - 0s 62us/step - loss: 0.4205 - acc: 0.5600\n",
      "Epoch 60/150\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.4170 - acc: 0.5733\n",
      "Epoch 61/150\n",
      "150/150 [==============================] - 0s 62us/step - loss: 0.4132 - acc: 0.5933\n",
      "Epoch 62/150\n",
      "150/150 [==============================] - 0s 100us/step - loss: 0.4099 - acc: 0.6200\n",
      "Epoch 63/150\n",
      "150/150 [==============================] - 0s 77us/step - loss: 0.4063 - acc: 0.6267\n",
      "Epoch 64/150\n",
      "150/150 [==============================] - 0s 96us/step - loss: 0.4028 - acc: 0.6267\n",
      "Epoch 65/150\n",
      "150/150 [==============================] - 0s 107us/step - loss: 0.3998 - acc: 0.6400\n",
      "Epoch 66/150\n",
      "150/150 [==============================] - 0s 105us/step - loss: 0.3955 - acc: 0.6400\n",
      "Epoch 67/150\n",
      "150/150 [==============================] - 0s 68us/step - loss: 0.3920 - acc: 0.6533\n",
      "Epoch 68/150\n",
      "150/150 [==============================] - 0s 88us/step - loss: 0.3894 - acc: 0.6600\n",
      "Epoch 69/150\n",
      "150/150 [==============================] - 0s 70us/step - loss: 0.3846 - acc: 0.6733\n",
      "Epoch 70/150\n",
      "150/150 [==============================] - 0s 72us/step - loss: 0.3809 - acc: 0.6733\n",
      "Epoch 71/150\n",
      "150/150 [==============================] - 0s 86us/step - loss: 0.3772 - acc: 0.6733\n",
      "Epoch 72/150\n",
      "150/150 [==============================] - 0s 89us/step - loss: 0.3736 - acc: 0.6867\n",
      "Epoch 73/150\n",
      "150/150 [==============================] - 0s 78us/step - loss: 0.3696 - acc: 0.7000\n",
      "Epoch 74/150\n",
      "150/150 [==============================] - 0s 69us/step - loss: 0.3660 - acc: 0.7000\n",
      "Epoch 75/150\n",
      "150/150 [==============================] - 0s 87us/step - loss: 0.3626 - acc: 0.7000\n",
      "Epoch 76/150\n",
      "150/150 [==============================] - 0s 76us/step - loss: 0.3591 - acc: 0.7333\n",
      "Epoch 77/150\n",
      "150/150 [==============================] - 0s 72us/step - loss: 0.3557 - acc: 0.7400\n",
      "Epoch 78/150\n",
      "150/150 [==============================] - 0s 78us/step - loss: 0.3527 - acc: 0.7400\n",
      "Epoch 79/150\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.3496 - acc: 0.7400\n",
      "Epoch 80/150\n",
      "150/150 [==============================] - 0s 75us/step - loss: 0.3465 - acc: 0.7533\n",
      "Epoch 81/150\n",
      "150/150 [==============================] - 0s 69us/step - loss: 0.3434 - acc: 0.7600\n",
      "Epoch 82/150\n",
      "150/150 [==============================] - 0s 88us/step - loss: 0.3404 - acc: 0.7667\n",
      "Epoch 83/150\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.3375 - acc: 0.7667\n",
      "Epoch 84/150\n",
      "150/150 [==============================] - 0s 65us/step - loss: 0.3342 - acc: 0.7667\n",
      "Epoch 85/150\n",
      "150/150 [==============================] - 0s 77us/step - loss: 0.3313 - acc: 0.7933\n",
      "Epoch 86/150\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.3280 - acc: 0.7933\n",
      "Epoch 87/150\n",
      "150/150 [==============================] - 0s 65us/step - loss: 0.3249 - acc: 0.7933\n",
      "Epoch 88/150\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.3216 - acc: 0.8000\n",
      "Epoch 89/150\n",
      "150/150 [==============================] - 0s 65us/step - loss: 0.3185 - acc: 0.8067\n",
      "Epoch 90/150\n",
      "150/150 [==============================] - 0s 68us/step - loss: 0.3152 - acc: 0.8067\n",
      "Epoch 91/150\n",
      "150/150 [==============================] - 0s 77us/step - loss: 0.3120 - acc: 0.8000\n",
      "Epoch 92/150\n",
      "150/150 [==============================] - 0s 64us/step - loss: 0.3092 - acc: 0.8000\n",
      "Epoch 93/150\n",
      "150/150 [==============================] - 0s 68us/step - loss: 0.3057 - acc: 0.8000\n",
      "Epoch 94/150\n",
      "150/150 [==============================] - 0s 58us/step - loss: 0.3029 - acc: 0.8000\n",
      "Epoch 95/150\n",
      "150/150 [==============================] - 0s 79us/step - loss: 0.2994 - acc: 0.8000\n",
      "Epoch 96/150\n",
      "150/150 [==============================] - 0s 69us/step - loss: 0.2963 - acc: 0.8000\n",
      "Epoch 97/150\n",
      "150/150 [==============================] - 0s 70us/step - loss: 0.2928 - acc: 0.8000\n",
      "Epoch 98/150\n",
      "150/150 [==============================] - 0s 59us/step - loss: 0.2895 - acc: 0.8000\n",
      "Epoch 99/150\n",
      "150/150 [==============================] - 0s 75us/step - loss: 0.2862 - acc: 0.8000\n",
      "Epoch 100/150\n",
      "150/150 [==============================] - 0s 59us/step - loss: 0.2830 - acc: 0.8000\n",
      "Epoch 101/150\n",
      "150/150 [==============================] - 0s 66us/step - loss: 0.2794 - acc: 0.8000\n",
      "Epoch 102/150\n",
      "150/150 [==============================] - 0s 58us/step - loss: 0.2761 - acc: 0.8133\n",
      "Epoch 103/150\n",
      "150/150 [==============================] - 0s 66us/step - loss: 0.2726 - acc: 0.8067\n",
      "Epoch 104/150\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2691 - acc: 0.8133\n",
      "Epoch 105/150\n",
      "150/150 [==============================] - 0s 64us/step - loss: 0.2655 - acc: 0.8133\n",
      "Epoch 106/150\n",
      "150/150 [==============================] - 0s 64us/step - loss: 0.2622 - acc: 0.8133\n",
      "Epoch 107/150\n",
      "150/150 [==============================] - 0s 88us/step - loss: 0.2592 - acc: 0.8067\n",
      "Epoch 108/150\n",
      "150/150 [==============================] - 0s 82us/step - loss: 0.2552 - acc: 0.7867\n",
      "Epoch 109/150\n",
      "150/150 [==============================] - 0s 95us/step - loss: 0.2513 - acc: 0.7867\n",
      "Epoch 110/150\n",
      "150/150 [==============================] - 0s 77us/step - loss: 0.2475 - acc: 0.7733\n",
      "Epoch 111/150\n",
      "150/150 [==============================] - 0s 97us/step - loss: 0.2439 - acc: 0.7667\n",
      "Epoch 112/150\n",
      "150/150 [==============================] - 0s 69us/step - loss: 0.2403 - acc: 0.7733\n",
      "Epoch 113/150\n",
      "150/150 [==============================] - 0s 84us/step - loss: 0.2363 - acc: 0.7600\n",
      "Epoch 114/150\n",
      "150/150 [==============================] - 0s 86us/step - loss: 0.2326 - acc: 0.7667\n",
      "Epoch 115/150\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.2288 - acc: 0.7667\n",
      "Epoch 116/150\n",
      "150/150 [==============================] - 0s 93us/step - loss: 0.2249 - acc: 0.7467\n",
      "Epoch 117/150\n",
      "150/150 [==============================] - 0s 70us/step - loss: 0.2209 - acc: 0.7467\n",
      "Epoch 118/150\n",
      "150/150 [==============================] - 0s 74us/step - loss: 0.2172 - acc: 0.7400\n",
      "Epoch 119/150\n",
      "150/150 [==============================] - 0s 70us/step - loss: 0.2135 - acc: 0.7267\n",
      "Epoch 120/150\n",
      "150/150 [==============================] - 0s 78us/step - loss: 0.2095 - acc: 0.7267\n",
      "Epoch 121/150\n",
      "150/150 [==============================] - 0s 84us/step - loss: 0.2058 - acc: 0.7000\n",
      "Epoch 122/150\n",
      "150/150 [==============================] - 0s 68us/step - loss: 0.2016 - acc: 0.6800\n",
      "Epoch 123/150\n",
      "150/150 [==============================] - 0s 78us/step - loss: 0.1980 - acc: 0.6800\n",
      "Epoch 124/150\n",
      "150/150 [==============================] - 0s 59us/step - loss: 0.1940 - acc: 0.6733\n",
      "Epoch 125/150\n",
      "150/150 [==============================] - 0s 78us/step - loss: 0.1902 - acc: 0.6467\n",
      "Epoch 126/150\n",
      "150/150 [==============================] - 0s 71us/step - loss: 0.1862 - acc: 0.6333\n",
      "Epoch 127/150\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.1821 - acc: 0.6400\n",
      "Epoch 128/150\n",
      "150/150 [==============================] - 0s 66us/step - loss: 0.1783 - acc: 0.6333\n",
      "Epoch 129/150\n",
      "150/150 [==============================] - 0s 65us/step - loss: 0.1744 - acc: 0.6267\n",
      "Epoch 130/150\n",
      "150/150 [==============================] - 0s 62us/step - loss: 0.1704 - acc: 0.6267\n",
      "Epoch 131/150\n",
      "150/150 [==============================] - 0s 64us/step - loss: 0.1667 - acc: 0.6200\n",
      "Epoch 132/150\n",
      "150/150 [==============================] - 0s 65us/step - loss: 0.1626 - acc: 0.6200\n",
      "Epoch 133/150\n",
      "150/150 [==============================] - 0s 62us/step - loss: 0.1588 - acc: 0.6133\n",
      "Epoch 134/150\n",
      "150/150 [==============================] - 0s 78us/step - loss: 0.1551 - acc: 0.6200\n",
      "Epoch 135/150\n",
      "150/150 [==============================] - 0s 76us/step - loss: 0.1507 - acc: 0.6133\n",
      "Epoch 136/150\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.1468 - acc: 0.6067\n",
      "Epoch 137/150\n",
      "150/150 [==============================] - 0s 61us/step - loss: 0.1428 - acc: 0.5867\n",
      "Epoch 138/150\n",
      "150/150 [==============================] - 0s 70us/step - loss: 0.1398 - acc: 0.5933\n",
      "Epoch 139/150\n",
      "150/150 [==============================] - 0s 76us/step - loss: 0.1354 - acc: 0.5933\n",
      "Epoch 140/150\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.1320 - acc: 0.5933\n",
      "Epoch 141/150\n",
      "150/150 [==============================] - 0s 61us/step - loss: 0.1286 - acc: 0.5933\n",
      "Epoch 142/150\n",
      "150/150 [==============================] - 0s 64us/step - loss: 0.1251 - acc: 0.5933\n",
      "Epoch 143/150\n",
      "150/150 [==============================] - 0s 64us/step - loss: 0.1217 - acc: 0.5933\n",
      "Epoch 144/150\n",
      "150/150 [==============================] - 0s 76us/step - loss: 0.1182 - acc: 0.5933\n",
      "Epoch 145/150\n",
      "150/150 [==============================] - 0s 76us/step - loss: 0.1145 - acc: 0.5933\n",
      "Epoch 146/150\n",
      "150/150 [==============================] - 0s 66us/step - loss: 0.1112 - acc: 0.6067\n",
      "Epoch 147/150\n",
      "150/150 [==============================] - 0s 71us/step - loss: 0.1078 - acc: 0.6067\n",
      "Epoch 148/150\n",
      "150/150 [==============================] - 0s 59us/step - loss: 0.1044 - acc: 0.6067\n",
      "Epoch 149/150\n",
      "150/150 [==============================] - 0s 75us/step - loss: 0.1007 - acc: 0.6067\n",
      "Epoch 150/150\n",
      "150/150 [==============================] - 0s 68us/step - loss: 0.0976 - acc: 0.6133\n",
      "150/150 [==============================] - 0s 156us/step\n",
      "\n",
      "acc: 61.33%\n"
     ]
    }
   ],
   "source": [
    "### SVM using DNN ###\n",
    "\n",
    "# Defining model #\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1,input_dim=4,activation='linear'))\n",
    "# model.add(Dense(1,activation='linear'))\n",
    "\n",
    "# Compile the model #\n",
    "\n",
    "model.compile(loss='categorical_hinge', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model #\n",
    "\n",
    "model.fit(X, Y, epochs=150, batch_size=10)\n",
    "\n",
    "# Evaluate the model #\n",
    "\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
