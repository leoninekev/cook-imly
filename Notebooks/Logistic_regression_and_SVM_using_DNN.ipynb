{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps involved in creating a neural network #\n",
    "\n",
    "1) Define the model\n",
    "2) Compile the model\n",
    "3) Fit the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Import iris dataset #\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=np.c_[iris['data'],iris['target']],\n",
    "                    columns=iris['feature_names'] + ['target'])\n",
    "iris_df = iris_df.loc[iris_df['target'] != 2]\n",
    "\n",
    "feature_vector = iris_df.columns.str.contains('cm')\n",
    "X = iris_df.loc[:,feature_vector]\n",
    "Y = iris_df[['target']]\n",
    "\n",
    "# Split the dataset into test and train datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "# \"\"\"\n",
    "# Objective - Convert the dataset to binary dataset\n",
    "# 1. Convert it to a dataframe. Why? What is a dataframe? DONE\n",
    "# 2. Filter target with !=2 and features with corresponding value. DONE\n",
    "# 3. What is the current data type of iris variable? DONE\n",
    "#     + Bunch data type by sklearn. A dictionary with two numpy arrays -- data and target.\n",
    "#     Contains additional details about the dataset as well.\n",
    "# 4. Qs\n",
    "#     + Cross check the parameters in train_test_split()\n",
    "# \"\"\"\n",
    "\n",
    "# Check class distribution #\n",
    "print(iris_df['target'].value_counts()[0]/iris_df.shape[0])\n",
    "print(iris_df['target'].value_counts()[1]/iris_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression using DNN #\n",
    "    1. The model\n",
    "    2. Confusion matrix\n",
    "    3. Classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "40/40 [==============================] - 13s 322ms/step - loss: 1.3947 - acc: 0.5500\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 0s 324us/step - loss: 1.3838 - acc: 0.5500\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 0s 367us/step - loss: 1.3706 - acc: 0.5500\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 0s 376us/step - loss: 1.3582 - acc: 0.5500\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 0s 323us/step - loss: 1.3481 - acc: 0.5500\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 0s 324us/step - loss: 1.3347 - acc: 0.5500\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 0s 360us/step - loss: 1.3230 - acc: 0.5500\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 0s 324us/step - loss: 1.3116 - acc: 0.5500\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 0s 298us/step - loss: 1.2994 - acc: 0.5500\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 0s 358us/step - loss: 1.2893 - acc: 0.5500\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 0s 335us/step - loss: 1.2813 - acc: 0.5500\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 0s 327us/step - loss: 1.2688 - acc: 0.5500\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 0s 374us/step - loss: 1.2582 - acc: 0.5500\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 0s 374us/step - loss: 1.2500 - acc: 0.5500\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 0s 327us/step - loss: 1.2383 - acc: 0.5500\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 0s 308us/step - loss: 1.2320 - acc: 0.5500\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 0s 376us/step - loss: 1.2222 - acc: 0.5500\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 0s 361us/step - loss: 1.2147 - acc: 0.5500\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 0s 336us/step - loss: 1.2048 - acc: 0.5500\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 0s 398us/step - loss: 1.1971 - acc: 0.5500\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 0s 424us/step - loss: 1.1883 - acc: 0.5500\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 0s 348us/step - loss: 1.1813 - acc: 0.5500\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 0s 324us/step - loss: 1.1729 - acc: 0.5500\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 0s 316us/step - loss: 1.1645 - acc: 0.5500\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 0s 306us/step - loss: 1.1579 - acc: 0.5500\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 0s 324us/step - loss: 1.1503 - acc: 0.5500\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 0s 299us/step - loss: 1.1431 - acc: 0.5500\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 0s 297us/step - loss: 1.1365 - acc: 0.5500\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 0s 348us/step - loss: 1.1283 - acc: 0.5500\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 0s 340us/step - loss: 1.1215 - acc: 0.5500\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 0s 333us/step - loss: 1.1152 - acc: 0.5500\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 0s 324us/step - loss: 1.1087 - acc: 0.5500\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 0s 304us/step - loss: 1.1007 - acc: 0.5500\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 0s 274us/step - loss: 1.0949 - acc: 0.5500\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 0s 315us/step - loss: 1.0901 - acc: 0.5500\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 0s 377us/step - loss: 1.0815 - acc: 0.5500\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 0s 362us/step - loss: 1.0761 - acc: 0.5500\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 0s 364us/step - loss: 1.0688 - acc: 0.5500\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 0s 381us/step - loss: 1.0636 - acc: 0.5500\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 0s 357us/step - loss: 1.0580 - acc: 0.5500\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 0s 324us/step - loss: 1.0514 - acc: 0.5500\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 0s 399us/step - loss: 1.0455 - acc: 0.5500\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 0s 326us/step - loss: 1.0396 - acc: 0.5500\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 0s 285us/step - loss: 1.0337 - acc: 0.5500\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 0s 321us/step - loss: 1.0277 - acc: 0.5500\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 0s 374us/step - loss: 1.0224 - acc: 0.5500\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 0s 349us/step - loss: 1.0168 - acc: 0.5500\n",
      "Epoch 48/200\n",
      "40/40 [==============================] - 0s 347us/step - loss: 1.0110 - acc: 0.5500\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 0s 340us/step - loss: 1.0049 - acc: 0.5500\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 0s 344us/step - loss: 0.9994 - acc: 0.5500\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 0s 348us/step - loss: 0.9940 - acc: 0.5500\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 0s 352us/step - loss: 0.9887 - acc: 0.5500\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - 0s 340us/step - loss: 0.9835 - acc: 0.5500\n",
      "Epoch 54/200\n",
      "40/40 [==============================] - 0s 375us/step - loss: 0.9782 - acc: 0.5500\n",
      "Epoch 55/200\n",
      "40/40 [==============================] - 0s 428us/step - loss: 0.9723 - acc: 0.5500\n",
      "Epoch 56/200\n",
      "40/40 [==============================] - 0s 331us/step - loss: 0.9668 - acc: 0.5500\n",
      "Epoch 57/200\n",
      "40/40 [==============================] - 0s 328us/step - loss: 0.9618 - acc: 0.5500\n",
      "Epoch 58/200\n",
      "40/40 [==============================] - 0s 324us/step - loss: 0.9562 - acc: 0.5500\n",
      "Epoch 59/200\n",
      "40/40 [==============================] - 0s 328us/step - loss: 0.9512 - acc: 0.5500\n",
      "Epoch 60/200\n",
      "40/40 [==============================] - 0s 367us/step - loss: 0.9463 - acc: 0.5500\n",
      "Epoch 61/200\n",
      "40/40 [==============================] - 0s 374us/step - loss: 0.9405 - acc: 0.5500\n",
      "Epoch 62/200\n",
      "40/40 [==============================] - 0s 374us/step - loss: 0.9359 - acc: 0.5500\n",
      "Epoch 63/200\n",
      "40/40 [==============================] - 0s 335us/step - loss: 0.9303 - acc: 0.5500\n",
      "Epoch 64/200\n",
      "40/40 [==============================] - 0s 374us/step - loss: 0.9260 - acc: 0.5500\n",
      "Epoch 65/200\n",
      "40/40 [==============================] - 0s 350us/step - loss: 0.9203 - acc: 0.5500\n",
      "Epoch 66/200\n",
      "40/40 [==============================] - 0s 370us/step - loss: 0.9156 - acc: 0.5500\n",
      "Epoch 67/200\n",
      "40/40 [==============================] - 0s 324us/step - loss: 0.9101 - acc: 0.5500\n",
      "Epoch 68/200\n",
      "40/40 [==============================] - 0s 374us/step - loss: 0.9055 - acc: 0.5500\n",
      "Epoch 69/200\n",
      "40/40 [==============================] - 0s 307us/step - loss: 0.9003 - acc: 0.5500\n",
      "Epoch 70/200\n",
      "40/40 [==============================] - 0s 321us/step - loss: 0.8957 - acc: 0.5500\n",
      "Epoch 71/200\n",
      "40/40 [==============================] - 0s 341us/step - loss: 0.8911 - acc: 0.5500\n",
      "Epoch 72/200\n",
      "40/40 [==============================] - 0s 374us/step - loss: 0.8862 - acc: 0.5500\n",
      "Epoch 73/200\n",
      "40/40 [==============================] - 0s 305us/step - loss: 0.8815 - acc: 0.5500\n",
      "Epoch 74/200\n",
      "40/40 [==============================] - 0s 337us/step - loss: 0.8766 - acc: 0.5500\n",
      "Epoch 75/200\n",
      "40/40 [==============================] - 0s 374us/step - loss: 0.8716 - acc: 0.5500\n",
      "Epoch 76/200\n",
      "40/40 [==============================] - 0s 274us/step - loss: 0.8673 - acc: 0.5500\n",
      "Epoch 77/200\n",
      "40/40 [==============================] - 0s 317us/step - loss: 0.8624 - acc: 0.5500\n",
      "Epoch 78/200\n",
      "40/40 [==============================] - 0s 331us/step - loss: 0.8579 - acc: 0.5500\n",
      "Epoch 79/200\n",
      "40/40 [==============================] - 0s 374us/step - loss: 0.8533 - acc: 0.5500\n",
      "Epoch 80/200\n",
      "40/40 [==============================] - 0s 299us/step - loss: 0.8488 - acc: 0.5500\n",
      "Epoch 81/200\n",
      "40/40 [==============================] - 0s 324us/step - loss: 0.8448 - acc: 0.5500\n",
      "Epoch 82/200\n",
      "40/40 [==============================] - 0s 349us/step - loss: 0.8396 - acc: 0.5500\n",
      "Epoch 83/200\n",
      "40/40 [==============================] - 0s 267us/step - loss: 0.8353 - acc: 0.5500\n",
      "Epoch 84/200\n",
      "40/40 [==============================] - 0s 324us/step - loss: 0.8309 - acc: 0.5500\n",
      "Epoch 85/200\n",
      "40/40 [==============================] - 0s 299us/step - loss: 0.8266 - acc: 0.5500\n",
      "Epoch 86/200\n",
      "40/40 [==============================] - 0s 317us/step - loss: 0.8223 - acc: 0.5500\n",
      "Epoch 87/200\n",
      "40/40 [==============================] - 0s 349us/step - loss: 0.8180 - acc: 0.5500\n",
      "Epoch 88/200\n",
      "40/40 [==============================] - 0s 299us/step - loss: 0.8135 - acc: 0.5500\n",
      "Epoch 89/200\n",
      "40/40 [==============================] - 0s 399us/step - loss: 0.8092 - acc: 0.5500\n",
      "Epoch 90/200\n",
      "40/40 [==============================] - 0s 368us/step - loss: 0.8050 - acc: 0.5500\n",
      "Epoch 91/200\n",
      "40/40 [==============================] - 0s 297us/step - loss: 0.8008 - acc: 0.5500\n",
      "Epoch 92/200\n",
      "40/40 [==============================] - 0s 294us/step - loss: 0.7969 - acc: 0.5500\n",
      "Epoch 93/200\n",
      "40/40 [==============================] - 0s 374us/step - loss: 0.7926 - acc: 0.5500\n",
      "Epoch 94/200\n",
      "40/40 [==============================] - 0s 362us/step - loss: 0.7885 - acc: 0.5500\n",
      "Epoch 95/200\n",
      "40/40 [==============================] - 0s 346us/step - loss: 0.7841 - acc: 0.5500\n",
      "Epoch 96/200\n",
      "40/40 [==============================] - 0s 374us/step - loss: 0.7802 - acc: 0.5500\n",
      "Epoch 97/200\n",
      "40/40 [==============================] - 0s 348us/step - loss: 0.7762 - acc: 0.5500\n",
      "Epoch 98/200\n",
      "40/40 [==============================] - 0s 374us/step - loss: 0.7722 - acc: 0.5500\n",
      "Epoch 99/200\n",
      "40/40 [==============================] - 0s 374us/step - loss: 0.7680 - acc: 0.5500\n",
      "Epoch 100/200\n",
      "40/40 [==============================] - 0s 349us/step - loss: 0.7639 - acc: 0.5500\n",
      "Epoch 101/200\n",
      "40/40 [==============================] - 0s 349us/step - loss: 0.7601 - acc: 0.5500\n",
      "Epoch 102/200\n",
      "40/40 [==============================] - 0s 299us/step - loss: 0.7564 - acc: 0.5500\n",
      "Epoch 103/200\n",
      "40/40 [==============================] - 0s 332us/step - loss: 0.7522 - acc: 0.5500\n",
      "Epoch 104/200\n",
      "40/40 [==============================] - 0s 399us/step - loss: 0.7482 - acc: 0.5500\n",
      "Epoch 105/200\n",
      "40/40 [==============================] - 0s 424us/step - loss: 0.7444 - acc: 0.5500\n",
      "Epoch 106/200\n",
      "40/40 [==============================] - 0s 349us/step - loss: 0.7408 - acc: 0.5500\n",
      "Epoch 107/200\n",
      "40/40 [==============================] - 0s 374us/step - loss: 0.7367 - acc: 0.5500\n",
      "Epoch 108/200\n",
      "40/40 [==============================] - 0s 324us/step - loss: 0.7330 - acc: 0.5500\n",
      "Epoch 109/200\n",
      "40/40 [==============================] - 0s 370us/step - loss: 0.7291 - acc: 0.5500\n",
      "Epoch 110/200\n",
      "40/40 [==============================] - 0s 341us/step - loss: 0.7254 - acc: 0.5500\n",
      "Epoch 111/200\n",
      "40/40 [==============================] - 0s 349us/step - loss: 0.7217 - acc: 0.5500\n",
      "Epoch 112/200\n",
      "40/40 [==============================] - 0s 361us/step - loss: 0.7181 - acc: 0.5500\n",
      "Epoch 113/200\n",
      "40/40 [==============================] - 0s 336us/step - loss: 0.7142 - acc: 0.5500\n",
      "Epoch 114/200\n",
      "40/40 [==============================] - 0s 374us/step - loss: 0.7105 - acc: 0.5500\n",
      "Epoch 115/200\n",
      "40/40 [==============================] - 0s 374us/step - loss: 0.7070 - acc: 0.5500\n",
      "Epoch 116/200\n",
      "40/40 [==============================] - 0s 344us/step - loss: 0.7037 - acc: 0.5500\n",
      "Epoch 117/200\n",
      "40/40 [==============================] - 0s 327us/step - loss: 0.6997 - acc: 0.5500\n",
      "Epoch 118/200\n",
      "40/40 [==============================] - 0s 324us/step - loss: 0.6961 - acc: 0.5500\n",
      "Epoch 119/200\n",
      "40/40 [==============================] - 0s 313us/step - loss: 0.6926 - acc: 0.5500\n",
      "Epoch 120/200\n",
      "40/40 [==============================] - 0s 351us/step - loss: 0.6895 - acc: 0.5500\n",
      "Epoch 121/200\n",
      "40/40 [==============================] - 0s 424us/step - loss: 0.6855 - acc: 0.5500\n",
      "Epoch 122/200\n",
      "40/40 [==============================] - 0s 374us/step - loss: 0.6820 - acc: 0.5500\n",
      "Epoch 123/200\n",
      "40/40 [==============================] - 0s 349us/step - loss: 0.6787 - acc: 0.5500\n",
      "Epoch 124/200\n",
      "40/40 [==============================] - 0s 349us/step - loss: 0.6752 - acc: 0.5500\n",
      "Epoch 125/200\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7509 - acc: 0.400 - 0s 317us/step - loss: 0.6718 - acc: 0.5500\n",
      "Epoch 126/200\n",
      "40/40 [==============================] - 0s 299us/step - loss: 0.6683 - acc: 0.5500\n",
      "Epoch 127/200\n",
      "40/40 [==============================] - 0s 331us/step - loss: 0.6650 - acc: 0.5500\n",
      "Epoch 128/200\n",
      "40/40 [==============================] - 0s 320us/step - loss: 0.6617 - acc: 0.5500\n",
      "Epoch 129/200\n",
      "40/40 [==============================] - 0s 321us/step - loss: 0.6582 - acc: 0.5500\n",
      "Epoch 130/200\n",
      "40/40 [==============================] - 0s 319us/step - loss: 0.6549 - acc: 0.5500\n",
      "Epoch 131/200\n",
      "40/40 [==============================] - 0s 328us/step - loss: 0.6516 - acc: 0.5500\n",
      "Epoch 132/200\n",
      "40/40 [==============================] - 0s 324us/step - loss: 0.6484 - acc: 0.5500\n",
      "Epoch 133/200\n",
      "40/40 [==============================] - 0s 330us/step - loss: 0.6453 - acc: 0.5500\n",
      "Epoch 134/200\n",
      "40/40 [==============================] - 0s 349us/step - loss: 0.6419 - acc: 0.5500\n",
      "Epoch 135/200\n",
      "40/40 [==============================] - 0s 348us/step - loss: 0.6387 - acc: 0.5500\n",
      "Epoch 136/200\n",
      "40/40 [==============================] - 0s 388us/step - loss: 0.6356 - acc: 0.5500\n",
      "Epoch 137/200\n",
      "40/40 [==============================] - 0s 366us/step - loss: 0.6324 - acc: 0.5500\n",
      "Epoch 138/200\n",
      "40/40 [==============================] - 0s 385us/step - loss: 0.6294 - acc: 0.5500\n",
      "Epoch 139/200\n",
      "40/40 [==============================] - 0s 349us/step - loss: 0.6261 - acc: 0.5500\n",
      "Epoch 140/200\n",
      "40/40 [==============================] - 0s 318us/step - loss: 0.6229 - acc: 0.5500\n",
      "Epoch 141/200\n",
      "40/40 [==============================] - 0s 336us/step - loss: 0.6201 - acc: 0.5500\n",
      "Epoch 142/200\n",
      "40/40 [==============================] - 0s 321us/step - loss: 0.6167 - acc: 0.5500\n",
      "Epoch 143/200\n",
      "40/40 [==============================] - 0s 318us/step - loss: 0.6137 - acc: 0.5500\n",
      "Epoch 144/200\n",
      "40/40 [==============================] - 0s 349us/step - loss: 0.6107 - acc: 0.5500\n",
      "Epoch 145/200\n",
      "40/40 [==============================] - 0s 313us/step - loss: 0.6077 - acc: 0.5500\n",
      "Epoch 146/200\n",
      "40/40 [==============================] - 0s 312us/step - loss: 0.6048 - acc: 0.5500\n",
      "Epoch 147/200\n",
      "40/40 [==============================] - 0s 301us/step - loss: 0.6017 - acc: 0.5500\n",
      "Epoch 148/200\n",
      "40/40 [==============================] - 0s 305us/step - loss: 0.5987 - acc: 0.5500\n",
      "Epoch 149/200\n",
      "40/40 [==============================] - 0s 355us/step - loss: 0.5959 - acc: 0.5500\n",
      "Epoch 150/200\n",
      "40/40 [==============================] - 0s 334us/step - loss: 0.5930 - acc: 0.5500\n",
      "Epoch 151/200\n",
      "40/40 [==============================] - 0s 299us/step - loss: 0.5900 - acc: 0.5500\n",
      "Epoch 152/200\n",
      "40/40 [==============================] - 0s 374us/step - loss: 0.5870 - acc: 0.5500\n",
      "Epoch 153/200\n",
      "40/40 [==============================] - 0s 324us/step - loss: 0.5841 - acc: 0.5500\n",
      "Epoch 154/200\n",
      "40/40 [==============================] - 0s 324us/step - loss: 0.5814 - acc: 0.5500\n",
      "Epoch 155/200\n",
      "40/40 [==============================] - 0s 313us/step - loss: 0.5785 - acc: 0.5500\n",
      "Epoch 156/200\n",
      "40/40 [==============================] - 0s 307us/step - loss: 0.5756 - acc: 0.5500\n",
      "Epoch 157/200\n",
      "40/40 [==============================] - 0s 349us/step - loss: 0.5728 - acc: 0.5500\n",
      "Epoch 158/200\n",
      "40/40 [==============================] - 0s 274us/step - loss: 0.5703 - acc: 0.5500\n",
      "Epoch 159/200\n",
      "40/40 [==============================] - 0s 345us/step - loss: 0.5673 - acc: 0.5500\n",
      "Epoch 160/200\n",
      "40/40 [==============================] - 0s 314us/step - loss: 0.5645 - acc: 0.5500\n",
      "Epoch 161/200\n",
      "40/40 [==============================] - 0s 312us/step - loss: 0.5618 - acc: 0.5500\n",
      "Epoch 162/200\n",
      "40/40 [==============================] - 0s 309us/step - loss: 0.5591 - acc: 0.5500\n",
      "Epoch 163/200\n",
      "40/40 [==============================] - 0s 337us/step - loss: 0.5563 - acc: 0.5500\n",
      "Epoch 164/200\n",
      "40/40 [==============================] - 0s 439us/step - loss: 0.5539 - acc: 0.5500\n",
      "Epoch 165/200\n",
      "40/40 [==============================] - 0s 384us/step - loss: 0.5510 - acc: 0.5500\n",
      "Epoch 166/200\n",
      "40/40 [==============================] - 0s 399us/step - loss: 0.5485 - acc: 0.5500\n",
      "Epoch 167/200\n",
      "40/40 [==============================] - 0s 324us/step - loss: 0.5457 - acc: 0.5500\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 352us/step - loss: 0.5432 - acc: 0.5500\n",
      "Epoch 169/200\n",
      "40/40 [==============================] - 0s 427us/step - loss: 0.5405 - acc: 0.5500\n",
      "Epoch 170/200\n",
      "40/40 [==============================] - 0s 424us/step - loss: 0.5380 - acc: 0.5500\n",
      "Epoch 171/200\n",
      "40/40 [==============================] - 0s 338us/step - loss: 0.5354 - acc: 0.5500\n",
      "Epoch 172/200\n",
      "40/40 [==============================] - 0s 435us/step - loss: 0.5330 - acc: 0.5500\n",
      "Epoch 173/200\n",
      "40/40 [==============================] - 0s 381us/step - loss: 0.5304 - acc: 0.5500\n",
      "Epoch 174/200\n",
      "40/40 [==============================] - 0s 412us/step - loss: 0.5279 - acc: 0.5750\n",
      "Epoch 175/200\n",
      "40/40 [==============================] - 0s 424us/step - loss: 0.5254 - acc: 0.6500\n",
      "Epoch 176/200\n",
      "40/40 [==============================] - 0s 387us/step - loss: 0.5231 - acc: 0.6500\n",
      "Epoch 177/200\n",
      "40/40 [==============================] - 0s 428us/step - loss: 0.5204 - acc: 0.6500\n",
      "Epoch 178/200\n",
      "40/40 [==============================] - 0s 417us/step - loss: 0.5180 - acc: 0.6500\n",
      "Epoch 179/200\n",
      "40/40 [==============================] - 0s 386us/step - loss: 0.5155 - acc: 0.6500\n",
      "Epoch 180/200\n",
      "40/40 [==============================] - 0s 399us/step - loss: 0.5131 - acc: 0.6750\n",
      "Epoch 181/200\n",
      "40/40 [==============================] - 0s 457us/step - loss: 0.5107 - acc: 0.6750\n",
      "Epoch 182/200\n",
      "40/40 [==============================] - 0s 475us/step - loss: 0.5084 - acc: 0.7000\n",
      "Epoch 183/200\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.5059 - acc: 0.7500\n",
      "Epoch 184/200\n",
      "40/40 [==============================] - 0s 398us/step - loss: 0.5036 - acc: 0.7750\n",
      "Epoch 185/200\n",
      "40/40 [==============================] - 0s 474us/step - loss: 0.5012 - acc: 0.8000\n",
      "Epoch 186/200\n",
      "40/40 [==============================] - 0s 424us/step - loss: 0.4990 - acc: 0.8750\n",
      "Epoch 187/200\n",
      "40/40 [==============================] - 0s 396us/step - loss: 0.4966 - acc: 0.8750\n",
      "Epoch 188/200\n",
      "40/40 [==============================] - 0s 399us/step - loss: 0.4942 - acc: 0.9000\n",
      "Epoch 189/200\n",
      "40/40 [==============================] - 0s 442us/step - loss: 0.4919 - acc: 0.9000\n",
      "Epoch 190/200\n",
      "40/40 [==============================] - 0s 399us/step - loss: 0.4897 - acc: 0.9000\n",
      "Epoch 191/200\n",
      "40/40 [==============================] - 0s 425us/step - loss: 0.4875 - acc: 0.9250\n",
      "Epoch 192/200\n",
      "40/40 [==============================] - 0s 449us/step - loss: 0.4851 - acc: 0.9250\n",
      "Epoch 193/200\n",
      "40/40 [==============================] - 0s 383us/step - loss: 0.4829 - acc: 0.9250\n",
      "Epoch 194/200\n",
      "40/40 [==============================] - 0s 386us/step - loss: 0.4809 - acc: 0.9250\n",
      "Epoch 195/200\n",
      "40/40 [==============================] - 0s 433us/step - loss: 0.4785 - acc: 0.9250\n",
      "Epoch 196/200\n",
      "40/40 [==============================] - 0s 416us/step - loss: 0.4762 - acc: 0.9250\n",
      "Epoch 197/200\n",
      "40/40 [==============================] - 0s 416us/step - loss: 0.4741 - acc: 0.9250\n",
      "Epoch 198/200\n",
      "40/40 [==============================] - 0s 424us/step - loss: 0.4720 - acc: 0.9250\n",
      "Epoch 199/200\n",
      "40/40 [==============================] - 0s 424us/step - loss: 0.4697 - acc: 0.9250\n",
      "Epoch 200/200\n",
      "40/40 [==============================] - 0s 399us/step - loss: 0.4676 - acc: 0.9250\n",
      "60/60 [==============================] - 0s 576us/step\n",
      "\n",
      "acc: 93.33%\n"
     ]
    }
   ],
   "source": [
    "### Logistic regression using DNN ###\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "\n",
    "np.random.seed(7)\n",
    "nb_classes = 4\n",
    "\n",
    "# Defining model #\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1,input_dim=4,activation='sigmoid'))\n",
    "\n",
    "# Compile the model #\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model #\n",
    "\n",
    "# model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=200, batch_size=10)\n",
    "model.fit(x_train, y_train, epochs=200, batch_size=10)\n",
    "# Evaluate the model #\n",
    "\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# \"\"\"\n",
    "# Classification report and optimization\n",
    "#     1. Adding an exhaustive classification report\n",
    "#     2. Analyse the report\n",
    "#     3. Improve the model\n",
    "#     4. Cross check the existing code\n",
    "# \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K fold cross validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 100.00%\n",
      "acc: 100.00%\n",
      "acc: 50.00%\n",
      "acc: 90.00%\n",
      "acc: 100.00%\n",
      "acc: 90.00%\n",
      "acc: 100.00%\n",
      "acc: 50.00%\n",
      "acc: 100.00%\n",
      "acc: 100.00%\n",
      "88.00% (+/- 19.39%)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "\n",
    "for train, test in kfold.split(X, Y):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1,input_dim=4,activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    # model.fit(X[train], Y[train], epochs=150, batch_size=10, verbose=0)\n",
    "    model.fit(X.iloc[train], Y.iloc[train], epochs=90, batch_size=10, verbose=0)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X.iloc[test], Y.iloc[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ROC Curve and Confusion Matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31  1]\n",
      " [ 0 28]]\n"
     ]
    }
   ],
   "source": [
    "# Prediction #\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = (y_pred>0.5)\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve. Sensitivity vs specificity\n",
    "# Try changing the threshold value\n",
    "# prediction.shape\n",
    "# print(prediction)\n",
    "\n",
    "# Creating the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "# Remove the 3rd class #\n",
    "# Loss function and response variable encoding(y_observed) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Classification Report__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa', 'versicolor']\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      0.97      0.98        32\n",
      " versicolor       0.97      1.00      0.98        28\n",
      "\n",
      "avg / total       0.98      0.98      0.98        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = [iris.target_names[0], iris.target_names[1]]\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using DNN #\n",
    "\n",
    "    1. The model\n",
    "    2. Confusion matrix\n",
    "    3. Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.8721 - acc: 0.1100\n",
      "Epoch 2/60\n",
      "100/100 [==============================] - 0s 110us/step - loss: 1.8194 - acc: 0.2200\n",
      "Epoch 3/60\n",
      "100/100 [==============================] - 0s 79us/step - loss: 1.7660 - acc: 0.3900\n",
      "Epoch 4/60\n",
      "100/100 [==============================] - 0s 120us/step - loss: 1.7166 - acc: 0.4800\n",
      "Epoch 5/60\n",
      "100/100 [==============================] - 0s 80us/step - loss: 1.6821 - acc: 0.5000\n",
      "Epoch 6/60\n",
      "100/100 [==============================] - 0s 100us/step - loss: 1.6562 - acc: 0.5000\n",
      "Epoch 7/60\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.6399 - acc: 0.5000\n",
      "Epoch 8/60\n",
      "100/100 [==============================] - 0s 90us/step - loss: 1.6244 - acc: 0.5000\n",
      "Epoch 9/60\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.6092 - acc: 0.5000\n",
      "Epoch 10/60\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.5913 - acc: 0.5000\n",
      "Epoch 11/60\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.5755 - acc: 0.5000\n",
      "Epoch 12/60\n",
      "100/100 [==============================] - 0s 90us/step - loss: 1.5582 - acc: 0.5000\n",
      "Epoch 13/60\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.5427 - acc: 0.5000\n",
      "Epoch 14/60\n",
      "100/100 [==============================] - 0s 100us/step - loss: 1.5258 - acc: 0.5000\n",
      "Epoch 15/60\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.5104 - acc: 0.5000\n",
      "Epoch 16/60\n",
      "100/100 [==============================] - 0s 80us/step - loss: 1.4935 - acc: 0.5000\n",
      "Epoch 17/60\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.4776 - acc: 0.5000\n",
      "Epoch 18/60\n",
      "100/100 [==============================] - 0s 90us/step - loss: 1.4612 - acc: 0.5000\n",
      "Epoch 19/60\n",
      "100/100 [==============================] - 0s 80us/step - loss: 1.4437 - acc: 0.5000\n",
      "Epoch 20/60\n",
      "100/100 [==============================] - 0s 80us/step - loss: 1.4281 - acc: 0.5000\n",
      "Epoch 21/60\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.4132 - acc: 0.5000\n",
      "Epoch 22/60\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.3960 - acc: 0.5000\n",
      "Epoch 23/60\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.3794 - acc: 0.5000\n",
      "Epoch 24/60\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.3629 - acc: 0.5000\n",
      "Epoch 25/60\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.3472 - acc: 0.5000\n",
      "Epoch 26/60\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.3311 - acc: 0.5000\n",
      "Epoch 27/60\n",
      "100/100 [==============================] - 0s 90us/step - loss: 1.3146 - acc: 0.5000\n",
      "Epoch 28/60\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.2988 - acc: 0.5000\n",
      "Epoch 29/60\n",
      "100/100 [==============================] - 0s 90us/step - loss: 1.2829 - acc: 0.5000\n",
      "Epoch 30/60\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.2666 - acc: 0.5000\n",
      "Epoch 31/60\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.2505 - acc: 0.5000\n",
      "Epoch 32/60\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.2347 - acc: 0.5000\n",
      "Epoch 33/60\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.2181 - acc: 0.5000\n",
      "Epoch 34/60\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.2028 - acc: 0.5000\n",
      "Epoch 35/60\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.1863 - acc: 0.5000\n",
      "Epoch 36/60\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.1705 - acc: 0.5000\n",
      "Epoch 37/60\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.1549 - acc: 0.5000\n",
      "Epoch 38/60\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.1416 - acc: 0.5000\n",
      "Epoch 39/60\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.1229 - acc: 0.5000\n",
      "Epoch 40/60\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.1070 - acc: 0.5000\n",
      "Epoch 41/60\n",
      "100/100 [==============================] - 0s 50us/step - loss: 1.0912 - acc: 0.5000\n",
      "Epoch 42/60\n",
      "100/100 [==============================] - 0s 120us/step - loss: 1.0762 - acc: 0.5000\n",
      "Epoch 43/60\n",
      "100/100 [==============================] - 0s 80us/step - loss: 1.0605 - acc: 0.5000\n",
      "Epoch 44/60\n",
      "100/100 [==============================] - 0s 60us/step - loss: 1.0448 - acc: 0.5000\n",
      "Epoch 45/60\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.0301 - acc: 0.5000\n",
      "Epoch 46/60\n",
      "100/100 [==============================] - 0s 70us/step - loss: 1.0143 - acc: 0.5000\n",
      "Epoch 47/60\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.9989 - acc: 0.5000\n",
      "Epoch 48/60\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.9837 - acc: 0.5000\n",
      "Epoch 49/60\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.9688 - acc: 0.5000\n",
      "Epoch 50/60\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.9525 - acc: 0.5000\n",
      "Epoch 51/60\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.9376 - acc: 0.5000\n",
      "Epoch 52/60\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.9224 - acc: 0.5000\n",
      "Epoch 53/60\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.9065 - acc: 0.5000\n",
      "Epoch 54/60\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.8916 - acc: 0.5000\n",
      "Epoch 55/60\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.8769 - acc: 0.5000\n",
      "Epoch 56/60\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.8610 - acc: 0.5200\n",
      "Epoch 57/60\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.8451 - acc: 0.5400\n",
      "Epoch 58/60\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.8306 - acc: 0.6000\n",
      "Epoch 59/60\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.8152 - acc: 0.6800\n",
      "Epoch 60/60\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.8009 - acc: 0.7500\n",
      "100/100 [==============================] - 0s 957us/step\n",
      "\n",
      "acc: 81.00%\n"
     ]
    }
   ],
   "source": [
    "### SVM using DNN ###\n",
    "\n",
    "# Defining model #\n",
    "np.random.seed(7)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1,input_dim=4,activation='linear'))\n",
    "# model.add(Dense(1,activation='linear'))\n",
    "\n",
    "# Compile the model #\n",
    "\n",
    "model.compile(loss='categorical_hinge', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model #\n",
    "\n",
    "model.fit(X, Y, epochs=60, batch_size=10)\n",
    "\n",
    "# Evaluate the model #\n",
    "\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qs/Doubts #\n",
    "1. Core methods to analyse\n",
    "    + Sequential\n",
    "    + add\n",
    "    + compile\n",
    "    + fit\n",
    "    + evaluate\n",
    "2. What exactly is sequential for?\n",
    "3. Classification report\n",
    "    + precision\n",
    "    + recall\n",
    "    + f1 score\n",
    "    + support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
