{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes \n",
    "\n",
    "To-Do  \n",
    "  \n",
    "1. Hyperparamter tuning\n",
    "    1. Do the scan in the defined boundary\n",
    "    2. Gather the best model\n",
    "    3. Read about GPU usage in Talos\n",
    "2. Saving the best model to ONNX format\n",
    "    1. Use deploy to save as JSON\n",
    "    2. save method in Keras\n",
    "    3. ONNX options\n",
    "        + Use onnxmltool\n",
    "    4. Is there an option to retrieve the best model from the  \n",
    "    Talos scan_object without using Deploy.\n",
    "    5. Problem with Deploy -- you have to save it locally and then read it back\n",
    "3. Research on the best models\n",
    "4. LaTeX equations\n",
    "5. Create decorator\n",
    "    + Returns ONNX model\n",
    "    + Writes keras and scikit params to master sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2548.0723987259703"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "sc = StandardScaler()\n",
    "diabetes.data = sc.fit_transform(diabetes.data)\n",
    "\n",
    "x = diabetes_X\n",
    "y = diabetes.target\n",
    "\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes.target[:-20]\n",
    "diabetes_y_test = diabetes.target[-20:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
    "\n",
    "score = regr.score(diabetes_X_test,diabetes_y_test)\n",
    "mean_squared_error(diabetes_y_test, diabetes_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.80050009,  1.06548848,  1.29708846, ..., -0.05449919,\n",
       "         0.41855058, -0.37098854],\n",
       "       [-0.03956713, -0.93853666, -1.08218016, ..., -0.83030083,\n",
       "        -1.43655059, -1.93847913],\n",
       "       [ 1.79330681,  1.06548848,  0.93453324, ..., -0.05449919,\n",
       "         0.06020733, -0.54515416],\n",
       "       ...,\n",
       "       [ 0.87686984,  1.06548848, -0.33441002, ..., -0.23293356,\n",
       "        -0.98558469,  0.32567395],\n",
       "       [-0.9560041 , -0.93853666,  0.82123474, ...,  0.55838411,\n",
       "         0.93615545, -0.54515416],\n",
       "       [-0.9560041 , -0.93853666, -1.53537419, ..., -0.83030083,\n",
       "        -0.08871747,  0.06442552]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/96 [00:00<?, ?it/s]\n",
      "  1%|          | 1/96 [00:17<27:09, 17.15s/it]\n",
      "  2%|▏         | 2/96 [00:21<21:02, 13.44s/it]\n",
      "  3%|▎         | 3/96 [00:30<18:47, 12.12s/it]\n",
      "  4%|▍         | 4/96 [00:40<17:30, 11.41s/it]\n",
      "  5%|▌         | 5/96 [00:57<19:55, 13.14s/it]\n",
      "  6%|▋         | 6/96 [01:02<16:03, 10.70s/it]\n",
      "  7%|▋         | 7/96 [01:06<12:53,  8.69s/it]\n",
      "  8%|▊         | 8/96 [01:08<09:49,  6.70s/it]\n",
      "  9%|▉         | 9/96 [01:18<10:44,  7.40s/it]\n",
      " 10%|█         | 10/96 [01:34<14:33, 10.16s/it]\n",
      " 11%|█▏        | 11/96 [02:07<24:13, 17.10s/it]\n",
      " 12%|█▎        | 12/96 [02:15<19:59, 14.28s/it]\n",
      " 14%|█▎        | 13/96 [02:21<16:17, 11.78s/it]\n",
      " 15%|█▍        | 14/96 [02:25<12:54,  9.44s/it]\n",
      " 16%|█▌        | 15/96 [02:34<12:33,  9.30s/it]\n",
      " 17%|█▋        | 16/96 [02:42<11:42,  8.78s/it]\n",
      " 18%|█▊        | 17/96 [03:00<15:20, 11.65s/it]\n",
      " 19%|█▉        | 18/96 [03:09<14:06, 10.85s/it]\n",
      " 20%|█▉        | 19/96 [03:26<16:20, 12.73s/it]\n",
      " 21%|██        | 20/96 [03:29<12:20,  9.74s/it]\n",
      " 22%|██▏       | 21/96 [03:36<11:21,  9.09s/it]\n",
      " 23%|██▎       | 22/96 [03:39<08:47,  7.12s/it]\n",
      " 24%|██▍       | 23/96 [03:54<11:42,  9.62s/it]\n",
      " 25%|██▌       | 24/96 [04:00<10:05,  8.40s/it]\n",
      " 26%|██▌       | 25/96 [04:05<08:49,  7.46s/it]\n",
      " 27%|██▋       | 26/96 [04:11<07:58,  6.84s/it]\n",
      " 28%|██▊       | 27/96 [04:29<11:51, 10.31s/it]\n",
      " 29%|██▉       | 28/96 [04:33<09:32,  8.42s/it]\n",
      " 30%|███       | 29/96 [04:36<07:36,  6.82s/it]\n",
      " 31%|███▏      | 30/96 [04:44<07:54,  7.19s/it]\n",
      " 32%|███▏      | 31/96 [05:19<16:52, 15.58s/it]\n",
      " 33%|███▎      | 32/96 [05:31<15:24, 14.45s/it]\n",
      " 34%|███▍      | 33/96 [05:46<15:19, 14.59s/it]\n",
      " 35%|███▌      | 34/96 [05:52<12:27, 12.05s/it]\n",
      " 36%|███▋      | 35/96 [06:07<13:02, 12.82s/it]\n",
      " 38%|███▊      | 36/96 [06:11<10:18, 10.30s/it]\n",
      " 39%|███▊      | 37/96 [06:21<10:02, 10.22s/it]\n",
      " 40%|███▉      | 38/96 [06:29<09:05,  9.41s/it]\n",
      " 41%|████      | 39/96 [06:33<07:34,  7.97s/it]\n",
      " 42%|████▏     | 40/96 [06:48<09:20, 10.01s/it]\n",
      " 43%|████▎     | 41/96 [07:06<11:14, 12.26s/it]\n",
      " 44%|████▍     | 42/96 [07:23<12:25, 13.81s/it]\n",
      " 45%|████▍     | 43/96 [07:32<10:55, 12.37s/it]\n",
      " 46%|████▌     | 44/96 [07:49<11:50, 13.66s/it]\n",
      " 47%|████▋     | 45/96 [07:58<10:23, 12.22s/it]\n",
      " 48%|████▊     | 46/96 [08:05<09:05, 10.91s/it]\n",
      " 49%|████▉     | 47/96 [08:08<06:46,  8.29s/it]\n",
      " 50%|█████     | 48/96 [08:10<05:13,  6.52s/it]\n",
      " 51%|█████     | 49/96 [08:43<11:23, 14.55s/it]\n",
      " 52%|█████▏    | 50/96 [09:12<14:26, 18.85s/it]\n",
      " 53%|█████▎    | 51/96 [09:14<10:21, 13.80s/it]\n",
      " 54%|█████▍    | 52/96 [09:19<08:14, 11.25s/it]\n",
      " 55%|█████▌    | 53/96 [09:28<07:29, 10.46s/it]\n",
      " 56%|█████▋    | 54/96 [09:33<06:06,  8.73s/it]\n",
      " 57%|█████▋    | 55/96 [09:37<05:07,  7.50s/it]\n",
      " 58%|█████▊    | 56/96 [09:41<04:18,  6.46s/it]\n",
      " 59%|█████▉    | 57/96 [09:56<05:49,  8.95s/it]\n",
      " 60%|██████    | 58/96 [10:26<09:33, 15.09s/it]\n",
      " 61%|██████▏   | 59/96 [10:36<08:23, 13.62s/it]\n",
      " 62%|██████▎   | 60/96 [10:42<06:48, 11.34s/it]\n",
      " 64%|██████▎   | 61/96 [10:51<06:11, 10.60s/it]\n",
      " 65%|██████▍   | 62/96 [10:58<05:30,  9.71s/it]\n",
      " 66%|██████▌   | 63/96 [11:27<08:28, 15.41s/it]\n",
      " 67%|██████▋   | 64/96 [11:36<07:08, 13.40s/it]\n",
      " 68%|██████▊   | 65/96 [11:45<06:17, 12.19s/it]\n",
      " 69%|██████▉   | 66/96 [11:55<05:44, 11.50s/it]\n",
      " 70%|██████▉   | 67/96 [11:57<04:13,  8.73s/it]\n",
      " 71%|███████   | 68/96 [12:03<03:40,  7.89s/it]\n",
      " 72%|███████▏  | 69/96 [12:12<03:39,  8.13s/it]\n",
      " 73%|███████▎  | 70/96 [12:20<03:28,  8.00s/it]\n",
      " 74%|███████▍  | 71/96 [12:24<02:56,  7.05s/it]\n",
      " 75%|███████▌  | 72/96 [12:58<05:56, 14.87s/it]\n",
      " 76%|███████▌  | 73/96 [13:04<04:44, 12.38s/it]\n",
      " 77%|███████▋  | 74/96 [13:10<03:50, 10.49s/it]\n",
      " 78%|███████▊  | 75/96 [13:25<04:06, 11.74s/it]\n",
      " 79%|███████▉  | 76/96 [13:37<03:54, 11.72s/it]\n",
      " 80%|████████  | 77/96 [13:55<04:22, 13.82s/it]\n",
      " 81%|████████▏ | 78/96 [13:58<03:09, 10.54s/it]\n",
      " 82%|████████▏ | 79/96 [14:03<02:29,  8.81s/it]\n",
      " 83%|████████▎ | 80/96 [14:11<02:16,  8.53s/it]\n",
      " 84%|████████▍ | 81/96 [14:22<02:18,  9.23s/it]\n",
      " 85%|████████▌ | 82/96 [14:24<01:41,  7.24s/it]\n",
      " 86%|████████▋ | 83/96 [14:29<01:23,  6.43s/it]\n",
      " 88%|████████▊ | 84/96 [14:38<01:27,  7.26s/it]\n",
      " 89%|████████▊ | 85/96 [14:47<01:26,  7.86s/it]\n",
      " 90%|████████▉ | 86/96 [14:50<01:02,  6.24s/it]\n",
      " 91%|█████████ | 87/96 [14:55<00:54,  6.00s/it]\n",
      " 92%|█████████▏| 88/96 [15:03<00:51,  6.49s/it]\n",
      " 93%|█████████▎| 89/96 [15:08<00:41,  5.98s/it]\n",
      " 94%|█████████▍| 90/96 [15:12<00:32,  5.48s/it]\n",
      " 95%|█████████▍| 91/96 [15:21<00:32,  6.48s/it]\n",
      " 96%|█████████▌| 92/96 [15:38<00:38,  9.64s/it]\n",
      " 97%|█████████▋| 93/96 [15:42<00:23,  7.91s/it]\n",
      " 98%|█████████▊| 94/96 [15:46<00:13,  6.77s/it]\n",
      " 99%|█████████▉| 95/96 [16:02<00:09,  9.59s/it]\n",
      "100%|██████████| 96/96 [16:11<00:00,  9.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD, Nadam\n",
    "from keras.losses import mse\n",
    "from keras.activations import linear\n",
    "import talos as ta\n",
    "\n",
    "# np.random.seed(7)\n",
    "\n",
    "# The parameter 'p' should be dynamic and a part of the mapping\n",
    "\n",
    "p = {'lr': (2, 10, 30),\n",
    "     'first_neuron': [1],\n",
    "     'batch_size': [1, 2, 3, 4],\n",
    "     'epochs': [10,20,40],\n",
    "     'weight_regulizer': [None],\n",
    "     'emb_output_dims': [None],\n",
    "     'optimizer': ['SGD', 'nadam'],\n",
    "     'losses': [mse],\n",
    "     'activation': [linear]\n",
    "    }\n",
    "\n",
    "def keras_model(x_train, y_train, x_val, y_val, params):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'],\n",
    "                    input_dim=x_train.shape[1],\n",
    "                    activation=params['activation']))\n",
    "\n",
    "    model.compile(optimizer=params['optimizer'],\n",
    "                  loss=params['losses'],\n",
    "                  metrics=['mse'])\n",
    "\n",
    "    out = model.fit(diabetes_X_train, diabetes_y_train,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'],\n",
    "                    verbose=0,\n",
    "                    validation_data=[x_val, y_val])\n",
    "    \n",
    "    return out, model\n",
    "    \n",
    "\n",
    "    \n",
    "h = ta.Scan(x, y,\n",
    "            params=p,\n",
    "            dataset_name='first_linear_regression',\n",
    "            experiment_no='a',\n",
    "            model=keras_model,\n",
    "            grid_downsample=0.5)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploy package linear_regression_firstDataset have been saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<talos.commands.deploy.Deploy at 0x25503598c88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing deploy from Talos \n",
    "from talos import Deploy\n",
    "\n",
    "Deploy(h, 'linear_regression_firstDataset',metric='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# loading the best model\n",
    "\n",
    "import os,json,zipfile,shutil\n",
    "from keras.models import model_from_json\n",
    "archive = zipfile.ZipFile('linear_regression_firstDataset.zip', 'r')\n",
    "model_file = archive.open('linear_regression_firstDataset_model.json')\n",
    "weight_file = archive.open('linear_regression_firstDataset_model.h5')\n",
    "\n",
    "with zipfile.ZipFile('linear_regression_firstDataset.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./linear_regression_firstDataset_unzip')\n",
    "\n",
    "# json_file = open('model.json', 'r')\n",
    "loaded_model_json = model_file.read()\n",
    "\n",
    "# json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"./linear_regression_firstDataset/linear_regression_firstDataset_model.h5\")\n",
    "\n",
    "\n",
    "shutil.rmtree('./linear_regression_firstDataset_unzip')\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The maximum opset needed by this model is only 7.\n"
     ]
    }
   ],
   "source": [
    "# Testing ONNX ml tool\n",
    "import onnxmltools\n",
    "onnx_model = onnxmltools.convert_keras(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ir_version: 3\n",
       "producer_name: \"OnnxMLTools\"\n",
       "producer_version: \"1.3.1\"\n",
       "domain: \"onnxml\"\n",
       "model_version: 0\n",
       "doc_string: \"\"\n",
       "graph {\n",
       "  node {\n",
       "    input: \"dense_1_input_14_0\"\n",
       "    input: \"W\"\n",
       "    output: \"transformed_tensor\"\n",
       "    name: \"_class__keras_layers_core_Dense__\"\n",
       "    op_type: \"MatMul\"\n",
       "    domain: \"\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"transformed_tensor\"\n",
       "    input: \"B\"\n",
       "    output: \"biased_tensor_name\"\n",
       "    name: \"Add\"\n",
       "    op_type: \"Add\"\n",
       "    domain: \"\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"biased_tensor_name\"\n",
       "    output: \"dense_1_14_BiasAdd_01\"\n",
       "    name: \"Identity\"\n",
       "    op_type: \"Identity\"\n",
       "    domain: \"\"\n",
       "  }\n",
       "  name: \"e704ad28cdf745b2bf06ded1ab6e743d\"\n",
       "  initializer {\n",
       "    dims: 1\n",
       "    dims: 1\n",
       "    data_type: FLOAT\n",
       "    float_data: 162.32818603515625\n",
       "    name: \"W\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 1\n",
       "    data_type: FLOAT\n",
       "    float_data: 153.9892578125\n",
       "    name: \"B\"\n",
       "  }\n",
       "  input {\n",
       "    name: \"dense_1_input_14_0\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: FLOAT\n",
       "        shape {\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  input {\n",
       "    name: \"W\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: FLOAT\n",
       "        shape {\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  input {\n",
       "    name: \"B\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: FLOAT\n",
       "        shape {\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  output {\n",
       "    name: \"dense_1_14_BiasAdd_01\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: FLOAT\n",
       "        shape {\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "opset_import {\n",
       "  domain: \"\"\n",
       "  version: 7\n",
       "}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 10ms/step\n",
      "loss : 1956.4066162109375\n"
     ]
    }
   ],
   "source": [
    "keras_score = model.evaluate(diabetes_X_test, diabetes_y_pred)\n",
    "print(model.metrics_names[0],':', keras_score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) MSE or accuracy? What is the right metric in this case?  \n",
    "2) Try altering\n",
    "    - learning rate\n",
    "    - optimizer or loss function\n",
    "    - \n",
    "3) **Normailzation of data**  \n",
    "4) Check if anything is wrong with model.evaluate  \n",
    "5) Size of loss too large?  \n",
    "6) Why is the epoch mse value different from the final evaluated value?  \n",
    "7) How to validate if this dnn model is the right representation of linear regression?     \n",
    "The math behind the Keras code  \n",
    "8)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"../data/iris.csv\" , delimiter=\",\", header=None, index_col=False)\n",
    "class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "data.iloc[:,-1] = index\n",
    "data = data.loc[data[4] != 2]\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "model = svm.SVC(kernel='linear', C=1, gamma=1)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "score = model.score(x_test, y_test)\n",
    "\n",
    "prediction= model.predict(x_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, input_dim=4, activation=\"linear\", kernel_regularizer=<keras.reg...)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 1.7212 - acc: 0.1000\n",
      "Epoch 2/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.6915 - acc: 0.2000\n",
      "Epoch 3/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.6610 - acc: 0.3000\n",
      "Epoch 4/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.6308 - acc: 0.3750\n",
      "Epoch 5/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.6032 - acc: 0.5000\n",
      "Epoch 6/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.5788 - acc: 0.5250\n",
      "Epoch 7/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.5583 - acc: 0.5250\n",
      "Epoch 8/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.5412 - acc: 0.5500\n",
      "Epoch 9/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.5288 - acc: 0.5500\n",
      "Epoch 10/120\n",
      "40/40 [==============================] - 0s 519us/step - loss: 1.5187 - acc: 0.5500\n",
      "Epoch 11/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.5076 - acc: 0.5500\n",
      "Epoch 12/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.4977 - acc: 0.5500\n",
      "Epoch 13/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.4886 - acc: 0.5500\n",
      "Epoch 14/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.4791 - acc: 0.5500\n",
      "Epoch 15/120\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6521 - acc: 0.800 - 0s 390us/step - loss: 1.4699 - acc: 0.5500\n",
      "Epoch 16/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.4578 - acc: 0.5500\n",
      "Epoch 17/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.4475 - acc: 0.5500\n",
      "Epoch 18/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.4389 - acc: 0.5500\n",
      "Epoch 19/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.4280 - acc: 0.5500\n",
      "Epoch 20/120\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.3384 - acc: 0.600 - 0s 391us/step - loss: 1.4207 - acc: 0.5500\n",
      "Epoch 21/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.4089 - acc: 0.5500\n",
      "Epoch 22/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.3996 - acc: 0.5500\n",
      "Epoch 23/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.3900 - acc: 0.5500\n",
      "Epoch 24/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.3793 - acc: 0.5500\n",
      "Epoch 25/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.3715 - acc: 0.5500\n",
      "Epoch 26/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.3609 - acc: 0.5500\n",
      "Epoch 27/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.3507 - acc: 0.5500\n",
      "Epoch 28/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.3414 - acc: 0.5500\n",
      "Epoch 29/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.3311 - acc: 0.5500\n",
      "Epoch 30/120\n",
      "40/40 [==============================] - 0s 781us/step - loss: 1.3227 - acc: 0.5500\n",
      "Epoch 31/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.3125 - acc: 0.5500\n",
      "Epoch 32/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.3045 - acc: 0.5500\n",
      "Epoch 33/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.2975 - acc: 0.5500\n",
      "Epoch 34/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.2861 - acc: 0.5500\n",
      "Epoch 35/120\n",
      "40/40 [==============================] - 0s 781us/step - loss: 1.2796 - acc: 0.5500\n",
      "Epoch 36/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.2682 - acc: 0.5500\n",
      "Epoch 37/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.2601 - acc: 0.5500\n",
      "Epoch 38/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.2496 - acc: 0.5500\n",
      "Epoch 39/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.2407 - acc: 0.5500\n",
      "Epoch 40/120\n",
      "40/40 [==============================] - 0s 781us/step - loss: 1.2346 - acc: 0.5500\n",
      "Epoch 41/120\n",
      "40/40 [==============================] - 0s 781us/step - loss: 1.2238 - acc: 0.5500\n",
      "Epoch 42/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.2162 - acc: 0.5500\n",
      "Epoch 43/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.2065 - acc: 0.5500\n",
      "Epoch 44/120\n",
      "40/40 [==============================] - 0s 781us/step - loss: 1.1970 - acc: 0.5500\n",
      "Epoch 45/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.1869 - acc: 0.5500\n",
      "Epoch 46/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.1783 - acc: 0.5500\n",
      "Epoch 47/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.1697 - acc: 0.5500\n",
      "Epoch 48/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.1615 - acc: 0.5500\n",
      "Epoch 49/120\n",
      "40/40 [==============================] - 0s 781us/step - loss: 1.1513 - acc: 0.5500\n",
      "Epoch 50/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.1436 - acc: 0.5500\n",
      "Epoch 51/120\n",
      "40/40 [==============================] - 0s 781us/step - loss: 1.1345 - acc: 0.5500\n",
      "Epoch 52/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.1248 - acc: 0.5500\n",
      "Epoch 53/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.1154 - acc: 0.5500\n",
      "Epoch 54/120\n",
      "40/40 [==============================] - 0s 781us/step - loss: 1.1066 - acc: 0.5500\n",
      "Epoch 55/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.0975 - acc: 0.5500\n",
      "Epoch 56/120\n",
      "40/40 [==============================] - 0s 781us/step - loss: 1.0879 - acc: 0.5500\n",
      "Epoch 57/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.0788 - acc: 0.5500\n",
      "Epoch 58/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.0698 - acc: 0.5500\n",
      "Epoch 59/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.0599 - acc: 0.5500\n",
      "Epoch 60/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 1.0525 - acc: 0.5500\n",
      "Epoch 61/120\n",
      "40/40 [==============================] - 0s 781us/step - loss: 1.0443 - acc: 0.5500\n",
      "Epoch 62/120\n",
      "40/40 [==============================] - 0s 781us/step - loss: 1.0376 - acc: 0.5500\n",
      "Epoch 63/120\n",
      "40/40 [==============================] - 0s 781us/step - loss: 1.0289 - acc: 0.5500\n",
      "Epoch 64/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.0185 - acc: 0.5500\n",
      "Epoch 65/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 1.0094 - acc: 0.5500\n",
      "Epoch 66/120\n",
      "40/40 [==============================] - 0s 781us/step - loss: 1.0012 - acc: 0.5500\n",
      "Epoch 67/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 0.9927 - acc: 0.5500\n",
      "Epoch 68/120\n",
      "40/40 [==============================] - 0s 504us/step - loss: 0.9836 - acc: 0.5500\n",
      "Epoch 69/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.9779 - acc: 0.5500\n",
      "Epoch 70/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.9691 - acc: 0.5500\n",
      "Epoch 71/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.9602 - acc: 0.5500\n",
      "Epoch 72/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.9512 - acc: 0.5500\n",
      "Epoch 73/120\n",
      "40/40 [==============================] - 0s 781us/step - loss: 0.9433 - acc: 0.5500\n",
      "Epoch 74/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 0.9358 - acc: 0.5500\n",
      "Epoch 75/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.9296 - acc: 0.5500\n",
      "Epoch 76/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 0.9204 - acc: 0.5500\n",
      "Epoch 77/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.9137 - acc: 0.5500\n",
      "Epoch 78/120\n",
      "40/40 [==============================] - 0s 845us/step - loss: 0.9058 - acc: 0.5500\n",
      "Epoch 79/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.9006 - acc: 0.5500\n",
      "Epoch 80/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.8890 - acc: 0.5500\n",
      "Epoch 81/120\n",
      "40/40 [==============================] - 0s 781us/step - loss: 0.8833 - acc: 0.5500\n",
      "Epoch 82/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.8738 - acc: 0.5500\n",
      "Epoch 83/120\n",
      "40/40 [==============================] - 0s 781us/step - loss: 0.8691 - acc: 0.5500\n",
      "Epoch 84/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.8604 - acc: 0.5500\n",
      "Epoch 85/120\n",
      "40/40 [==============================] - 0s 0us/step - loss: 0.8515 - acc: 0.5500\n",
      "Epoch 86/120\n",
      "40/40 [==============================] - 0s 781us/step - loss: 0.8478 - acc: 0.5500\n",
      "Epoch 87/120\n",
      "40/40 [==============================] - 0s 0us/step - loss: 0.8379 - acc: 0.5500\n",
      "Epoch 88/120\n",
      "40/40 [==============================] - 0s 0us/step - loss: 0.8298 - acc: 0.5500\n",
      "Epoch 89/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.8224 - acc: 0.5500\n",
      "Epoch 90/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 0.8141 - acc: 0.5500\n",
      "Epoch 91/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.8063 - acc: 0.5500\n",
      "Epoch 92/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.8004 - acc: 0.5500\n",
      "Epoch 93/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.7934 - acc: 0.5500\n",
      "Epoch 94/120\n",
      "40/40 [==============================] - 0s 0us/step - loss: 0.7845 - acc: 0.5500\n",
      "Epoch 95/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.7774 - acc: 0.5500\n",
      "Epoch 96/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.7691 - acc: 0.6000\n",
      "Epoch 97/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.7625 - acc: 0.6750\n",
      "Epoch 98/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.7539 - acc: 0.6750\n",
      "Epoch 99/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.7477 - acc: 0.6750\n",
      "Epoch 100/120\n",
      "40/40 [==============================] - 0s 0us/step - loss: 0.7391 - acc: 0.7000\n",
      "Epoch 101/120\n",
      "40/40 [==============================] - 0s 0us/step - loss: 0.7335 - acc: 0.7000\n",
      "Epoch 102/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.7280 - acc: 0.7250\n",
      "Epoch 103/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.7187 - acc: 0.8000\n",
      "Epoch 104/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.7114 - acc: 0.8250\n",
      "Epoch 105/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.7075 - acc: 0.8250\n",
      "Epoch 106/120\n",
      "40/40 [==============================] - 0s 0us/step - loss: 0.6967 - acc: 0.8500\n",
      "Epoch 107/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.6897 - acc: 0.8750\n",
      "Epoch 108/120\n",
      "40/40 [==============================] - 0s 390us/step - loss: 0.6829 - acc: 0.9250\n",
      "Epoch 109/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.6751 - acc: 0.9250\n",
      "Epoch 110/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.6685 - acc: 0.9500\n",
      "Epoch 111/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.6649 - acc: 0.9250\n",
      "Epoch 112/120\n",
      "40/40 [==============================] - 0s 0us/step - loss: 0.6549 - acc: 0.9750\n",
      "Epoch 113/120\n",
      "40/40 [==============================] - 0s 0us/step - loss: 0.6483 - acc: 1.0000\n",
      "Epoch 114/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.6412 - acc: 1.0000\n",
      "Epoch 115/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.6353 - acc: 1.0000\n",
      "Epoch 116/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.6285 - acc: 1.0000\n",
      "Epoch 117/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.6201 - acc: 1.0000\n",
      "Epoch 118/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.6150 - acc: 1.0000\n",
      "Epoch 119/120\n",
      "40/40 [==============================] - 0s 0us/step - loss: 0.6075 - acc: 1.0000\n",
      "Epoch 120/120\n",
      "40/40 [==============================] - 0s 391us/step - loss: 0.6033 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c98933e6a0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.regularizers import l2\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1,input_dim=4,activation='linear', W_regularizer=l2(0.01)))\n",
    "\n",
    "model.compile(loss='categorical_hinge', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=120, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 3ms/step\n",
      "acc : 1.0\n"
     ]
    }
   ],
   "source": [
    "keras_score = model.evaluate(x_test, prediction)\n",
    "print(model.metrics_names[1],':', keras_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "predicted= model.predict(x_test)\n",
    "\n",
    "score = model.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
