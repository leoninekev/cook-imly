{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do -  \n",
    "1) Monkey patching sklearn models\n",
    "    + Do it for one method - say 'fit'\n",
    "    + Replicate this for the remaining methods\n",
    "2) Mapping -- tineyDB part  \n",
    "3) Testing -- writing learnings from the experiment  \n",
    "to the master sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo for Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mathematical representation\n",
    "1) Fit  \n",
    "2) Predict  \n",
    "3) Score  \n",
    "4) Loss  \n",
    "5) Optimization  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ $ Y_i = \\beta_0 + \\beta_1 x_{i1} +\\cdots + \\beta_p x_{ip} + \\epsilon_i,\\qquad i = 1,\\ldots,n $  \n",
    "\n",
    "+ **Score**\n",
    "  + $ {MSE} = \\frac{1}{n}\\sum_{i=1}^n (Y_i - \\hat Y_i)^2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from imly2 import dope\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "sc = StandardScaler()\n",
    "diabetes.data = sc.fit_transform(diabetes.data)\n",
    "\n",
    "x = diabetes_X\n",
    "y = diabetes.target\n",
    "\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "x_train = diabetes_X[:-20]\n",
    "x_test = diabetes_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "y_train = diabetes.target[:-20]\n",
    "y_test = diabetes.target[-20:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You must compile a model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f59210765e46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\MLSquare\\cook-imly\\Notebooks\\imly2.py\u001b[0m in \u001b[0;36mfit_keras\u001b[1;34m(self, x_train, y_train, x_test, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;31m# To delete the zip file that was created by Talos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;31m# os.remove('./linear_regression_firstDataset.zip')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;31m# Avoid using weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m                 raise RuntimeError('You must compile a model before '\n\u001b[0m\u001b[0;32m    682\u001b[0m                                    \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m                                    'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile a model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "m = dope(model)\n",
    "\n",
    "m.fit(x_train,y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-20739.2265625 [ 0.15318102  0.0165125   0.07544296  0.01525866  0.0227817   0.06917377\n",
      "  0.16571942  0.02403554 -0.00354894  0.02654322  0.1268504  -0.00731045\n",
      "  0.06415841  0.0353201  -0.02361037  0.08547369  0.04409697  0.04409697\n",
      "  0.10804279 -0.02235653]\n"
     ]
    }
   ],
   "source": [
    "y_pred = m.predict(x_test)\n",
    "score = m.score(x_test,y_test)\n",
    "\n",
    "print(score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The maximum opset needed by this model is only 7.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "onnx_model = m.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ir_version: 3\n",
       "producer_name: \"OnnxMLTools\"\n",
       "producer_version: \"1.3.1\"\n",
       "domain: \"onnxml\"\n",
       "model_version: 0\n",
       "doc_string: \"\"\n",
       "graph {\n",
       "  node {\n",
       "    input: \"dense_1_input_1_0\"\n",
       "    input: \"W\"\n",
       "    output: \"transformed_tensor\"\n",
       "    name: \"_class__keras_layers_core_Dense__\"\n",
       "    op_type: \"MatMul\"\n",
       "    domain: \"\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"transformed_tensor\"\n",
       "    input: \"B\"\n",
       "    output: \"biased_tensor_name\"\n",
       "    name: \"Add\"\n",
       "    op_type: \"Add\"\n",
       "    domain: \"\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"biased_tensor_name\"\n",
       "    output: \"dense_1_1_BiasAdd_01\"\n",
       "    name: \"Identity\"\n",
       "    op_type: \"Identity\"\n",
       "    domain: \"\"\n",
       "  }\n",
       "  name: \"0cc81e0bf31249b181b34caf386248c3\"\n",
       "  initializer {\n",
       "    dims: 1\n",
       "    dims: 1\n",
       "    data_type: FLOAT\n",
       "    float_data: -0.6744621396064758\n",
       "    name: \"W\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 1\n",
       "    data_type: FLOAT\n",
       "    float_data: 0.06278767436742783\n",
       "    name: \"B\"\n",
       "  }\n",
       "  input {\n",
       "    name: \"dense_1_input_1_0\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: FLOAT\n",
       "        shape {\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  input {\n",
       "    name: \"W\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: FLOAT\n",
       "        shape {\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  input {\n",
       "    name: \"B\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: FLOAT\n",
       "        shape {\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  output {\n",
       "    name: \"dense_1_1_BiasAdd_01\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: FLOAT\n",
       "        shape {\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "opset_import {\n",
       "  domain: \"\"\n",
       "  version: 7\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(x_train,y_train, using = 'sklearn') # executes sklearn fit\n",
    "\n",
    "y_pred = m.predict(x_test, using='sklearn') # executes sklearn predict\n",
    "\n",
    "score = m.score(x_test, y_test, using='sklearn') # sklearn equivalent\n",
    "\n",
    "m.save(using = 'sklearn') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'using': 'dnn', 'params': 'parameters'}\n"
     ]
    }
   ],
   "source": [
    "def test_function(model, **kwargs):\n",
    "    kwargs.setdefault('using','dnn')\n",
    "    kwargs.setdefault('params','parameters')\n",
    "    print(kwargs)\n",
    "    if kwargs['using']=='sklearn':\n",
    "        print('kwargs from kwargs -- ',kwargs['using'])\n",
    "        print('Model from kwargs -- ',model)\n",
    "    elif kwargs == {}:\n",
    "        print('Model from non-kwargs -- ', model)\n",
    "        \n",
    "        \n",
    "test_function('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1 = np.array([[1],[2]])[1]\n",
    "x_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_var' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1ff919b97252>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(a, b)\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_var' is not defined"
     ]
    }
   ],
   "source": [
    "my_func = \"\"\"\n",
    "def function(a,b):\n",
    "   constant = {input_var}\n",
    "   return a*b + constant\n",
    "\"\"\"\n",
    "my_func.format(input_var = 5)\n",
    "\n",
    "exec(my_func)\n",
    "function(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
