{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do -  \n",
    "1) Monkey patching sklearn models\n",
    "    + Do it for one method - say 'fit'\n",
    "    + Replicate this for the remaining methods\n",
    "2) Mapping -- tineyDB part  \n",
    "3) Testing -- writing learnings from the experiment  \n",
    "to the master sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo for Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mathematical representation\n",
    "1) Fit  \n",
    "2) Predict  \n",
    "3) Score  \n",
    "4) Loss  \n",
    "5) Optimization  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ $ Y_i = \\beta_0 + \\beta_1 x_{i1} +\\cdots + \\beta_p x_{ip} + \\epsilon_i,\\qquad i = 1,\\ldots,n $  \n",
    "\n",
    "+ **Score**\n",
    "  + $ {MSE} = \\frac{1}{n}\\sum_{i=1}^n (Y_i - \\hat Y_i)^2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from imly import dope\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "sc = StandardScaler()\n",
    "diabetes.data = sc.fit_transform(diabetes.data)\n",
    "\n",
    "x = diabetes_X\n",
    "y = diabetes.target\n",
    "\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "x_train = diabetes_X[:-20]\n",
    "x_test = diabetes_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "y_train = diabetes.target[:-20]\n",
    "y_test = diabetes.target[-20:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From talos.py ---  {'lr': [2, 10, 30], 'first_neuron': [1], 'batch_size': [10], 'epochs': [10], 'weight_regulizer': [None], 'emb_output_dims': [None], 'optimizer': ['nadam'], 'losses': ['mae', 'mse'], 'activation': ['linear'], 'model_name': ['LinearRegression']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:17<00:00,  7.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "Epoch 1/1\n",
      "422/422 [==============================] - ETA: 1s - loss: 147.4130 - mean_absolute_error: 147.413 - 0s 317us/step - loss: 152.7561 - mean_absolute_error: 152.7561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1ef715162e8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "m = dope(model)\n",
    "\n",
    "# p = {\n",
    "#     'batch_size':[100],\n",
    "#     'epochs':20,\n",
    "#     'optimizer':'adam'\n",
    "# }\n",
    "\n",
    "m.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'dense_1',\n",
       " 'trainable': True,\n",
       " 'batch_input_shape': (None, 1),\n",
       " 'dtype': 'float32',\n",
       " 'units': 1,\n",
       " 'activation': 'linear',\n",
       " 'use_bias': True,\n",
       " 'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "  'config': {'scale': 1.0,\n",
       "   'mode': 'fan_avg',\n",
       "   'distribution': 'uniform',\n",
       "   'seed': None}},\n",
       " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       " 'kernel_regularizer': None,\n",
       " 'bias_regularizer': None,\n",
       " 'activity_regularizer': None,\n",
       " 'kernel_constraint': None,\n",
       " 'bias_constraint': None}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.__dict__['model'].get_config()['layers'][0]['config']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo for Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset info #\n",
    "import experiment_automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dataset_name = \"uci_abalone\"\n",
    "dataset_info = experiment_automation_script.get_url(dataset_name)\n",
    "\n",
    "names = [\"sex\", \"length\", \"diameter\", \"height\", \"whole weight\",\n",
    "        \"shucked weight\", \"viscera weight\", \"shell weight\", \"rings\"]\n",
    "url = \"../data/abalone.data.csv\" if path.exists(\"../data/abalone.data.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, names=names, index_col=False)\n",
    "data.head()\n",
    "\n",
    "# Check for columns that contain missing values #\n",
    "col_names = data.columns\n",
    "\n",
    "num_data = data.shape[0]\n",
    "# for c in col_names:\n",
    "#     num_non = data[c].isin([None]).sum()\n",
    "#     if num_non > 0:\n",
    "#         print (c)\n",
    "#         print (num_non)\n",
    "#         print (\"{0:.2f}%\".format(float(num_non) / num_data * 100))\n",
    "#         print (\"\\n\")\n",
    "\n",
    "# Convert categorical fields #\n",
    "categorical_col = ['sex']\n",
    "for col in categorical_col:\n",
    "    b, c = np.unique(data[col], return_inverse=True)\n",
    "    data[col] = c\n",
    "\n",
    "    \n",
    "# Filter dataset to contain 'rings' 9 and 10 #\n",
    "data = data[data['rings'].isin([9,10])]\n",
    "data['rings'] = data['rings'].map({9: 0, 10: 1})\n",
    "\n",
    "\n",
    "feature_list = names[:7]\n",
    "X = data.loc[:, feature_list]\n",
    "Y = data[['rings']]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "m = dope(model)\n",
    "\n",
    "# p = {\n",
    "#     'batch_size':[100],\n",
    "#     'epochs':20,\n",
    "#     'optimizer':'adam'\n",
    "# }\n",
    "\n",
    "m.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 781us/step\n",
      "-20603.421875 [0.55056715 0.6557553  0.61039895 0.65672034 0.65093017 0.61522406\n",
      " 0.5409168  0.6499651  0.67119575 0.64803505 0.5708327  0.67409086\n",
      " 0.6190842  0.6412799  0.6866362  0.6026787  0.63452464 0.63452464\n",
      " 0.5853082  0.6856712 ]\n"
     ]
    }
   ],
   "source": [
    "y_pred = m.predict(x_test)\n",
    "score = m.score(x_test,y_test)\n",
    "\n",
    "print(score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SklearnKerasRegressor' object has no attribute 'layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-302775fdd21e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'SklearnKerasRegressor' object has no attribute 'layers'"
     ]
    }
   ],
   "source": [
    "m.layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ir_version: 3\n",
       "producer_name: \"OnnxMLTools\"\n",
       "producer_version: \"1.3.1\"\n",
       "domain: \"onnxml\"\n",
       "model_version: 0\n",
       "doc_string: \"\"\n",
       "graph {\n",
       "  node {\n",
       "    input: \"dense_1_input_0\"\n",
       "    input: \"W\"\n",
       "    output: \"transformed_tensor\"\n",
       "    name: \"_class__keras_layers_core_Dense__\"\n",
       "    op_type: \"MatMul\"\n",
       "    domain: \"\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"transformed_tensor\"\n",
       "    input: \"B\"\n",
       "    output: \"biased_tensor_name\"\n",
       "    name: \"Add\"\n",
       "    op_type: \"Add\"\n",
       "    domain: \"\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"biased_tensor_name\"\n",
       "    output: \"dense_1_BiasAdd_01\"\n",
       "    name: \"Identity\"\n",
       "    op_type: \"Identity\"\n",
       "    domain: \"\"\n",
       "  }\n",
       "  name: \"0dc434d033264e448b41c72ae812d590\"\n",
       "  initializer {\n",
       "    dims: 1\n",
       "    dims: 1\n",
       "    data_type: FLOAT\n",
       "    float_data: -0.8953593373298645\n",
       "    name: \"W\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 1\n",
       "    data_type: FLOAT\n",
       "    float_data: 0.6202828288078308\n",
       "    name: \"B\"\n",
       "  }\n",
       "  input {\n",
       "    name: \"dense_1_input_0\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: FLOAT\n",
       "        shape {\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  input {\n",
       "    name: \"W\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: FLOAT\n",
       "        shape {\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  input {\n",
       "    name: \"B\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: FLOAT\n",
       "        shape {\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  output {\n",
       "    name: \"dense_1_BiasAdd_01\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: FLOAT\n",
       "        shape {\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "opset_import {\n",
       "  domain: \"\"\n",
       "  version: 7\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(x_train,y_train, using = 'sklearn') # executes sklearn fit\n",
    "\n",
    "y_pred = m.predict(x_test, using='sklearn') # executes sklearn predict\n",
    "\n",
    "score = m.score(x_test, y_test, using='sklearn') # sklearn equivalent\n",
    "\n",
    "m.save(using = 'sklearn') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'using': 'dnn', 'params': 'parameters'}\n"
     ]
    }
   ],
   "source": [
    "def test_function(model, **kwargs):\n",
    "    kwargs.setdefault('using','dnn')\n",
    "    kwargs.setdefault('params','parameters')\n",
    "    print(kwargs)\n",
    "    if kwargs['using']=='sklearn':\n",
    "        print('kwargs from kwargs -- ',kwargs['using'])\n",
    "        print('Model from kwargs -- ',model)\n",
    "    elif kwargs == {}:\n",
    "        print('Model from non-kwargs -- ', model)\n",
    "        \n",
    "        \n",
    "test_function('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1 = np.array([[1],[2]])[1]\n",
    "x_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_var' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1ff919b97252>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(a, b)\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_var' is not defined"
     ]
    }
   ],
   "source": [
    "my_func = \"\"\"\n",
    "def function(a,b):\n",
    "   constant = {input_var}\n",
    "   return a*b + constant\n",
    "\"\"\"\n",
    "my_func.format(input_var = 5)\n",
    "\n",
    "exec(my_func)\n",
    "function(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
