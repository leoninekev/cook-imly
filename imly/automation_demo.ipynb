{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizing automation script to test IMLY's perfromance\n",
    "\n",
    "This notebook will show you how to use the automation_script to test the performance of IMLY on any given dataset. The results can be viewed in this [sheet](https://docs.google.com/spreadsheets/d/1E5jcq2w42gN8bMIaeaRJpAdhgSVN-2XDJ_YTHe4qfwY/edit?usp=sharing).\n",
    "\n",
    "## Step 1: Add dataset details to the sheet\n",
    "\n",
    "Add the following details to the [\"Dataset details\"](https://docs.google.com/spreadsheets/d/1E5jcq2w42gN8bMIaeaRJpAdhgSVN-2XDJ_YTHe4qfwY/edit?usp=sharing) sheet :   \n",
    "    1. Name - Name of your dataset\n",
    "    2. Link - A download link to your dataset with public access. Please make sure it's a csv file.\n",
    "    3. Algorithm - Name of the algorithm you expect IMLY to use on your dataset. ex - \"logistic_regression\"\n",
    "    \n",
    "## Step 2: Add client secret\n",
    "\n",
    "To be able to edit the sheet via automation_script you will have to add the client_secret.json file shared with you to cook-imly/data in your local repo.\n",
    "\n",
    "## Step 3: Data preperation\n",
    "\n",
    "The automation_script accepts the dataset as X(features) and Y(target). So the user is expected to split their dataset into X and Y before triggering the script. The following sample demonstrates the same for a simple dataset.\n",
    "\n",
    "**Note - The X and Y values are expected to be passed as a dataframe**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "dataset_name = \"uci_iris\" # Name of your dataset as mentioned in the \n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "# Gathering data and converting it into a dataframe\n",
    "url = dataset_info['url']\n",
    "data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
    "\n",
    "# This part of the preparation is specific to the dataset\n",
    "class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "data.iloc[:,-1] = index\n",
    "data = data.loc[data[4] != 2]\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run the script\n",
    "\n",
    "By calling the `run_imly()` function from automation_script you would be able to process your dataset with IMLY and record the performance to the above mentioned sheet.\n",
    "\n",
    "The following arguments are mandatory for the `run_imly()` function:\n",
    "    1. dataset_info - The dataset info gathered previously using `get_dataset_info()`\n",
    "    2. model_name - Name of the algorithm you're planning to use\n",
    "    3. X, Y\n",
    "    4. test_size - The test_size for train_test_split\n",
    "    \n",
    "`params` is an optional argument. You can add any legal params accepted by keras to this argument(sample shown below).\n",
    "\n",
    "```\n",
    "params = {\n",
    "        \"units\": 1,\n",
    "        \"batch_size\": 10,\n",
    "        \"epochs\": 100,\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"losses\": \"binary_crossentropy\",\n",
    "        \"activation\": \"sigmoid\"\n",
    "      }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automation_script.run_imly(dataset_info=dataset_info, \n",
    "                                      model_name='logistic_regression', \n",
    "                                      X=X, Y=Y, \n",
    "                                      test_size=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
