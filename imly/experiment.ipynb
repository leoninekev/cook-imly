{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments using IMLY ###\n",
    "\n",
    "This notebook contains experimental runs of IMLY with different datasets.  \n",
    "The readings of these experiments can be referred to in this [sheet](https://docs.google.com/spreadsheets/d/1E5jcq2w42gN8bMIaeaRJpAdhgSVN-2XDJ_YTHe4qfwY/edit?usp=sharing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #1\n",
    "\n",
    "#### Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x000002223F554978>\n",
      "From try --  <function glm at 0x000002223E336F28>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 1/3 [00:02<00:04,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x000002226462C908>\n",
      "From try --  <function glm at 0x000002223E336F28>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x00000222F8CB9E10>\n",
      "From try --  <function glm at 0x000002223E336F28>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "Epoch 1/1\n",
      "176/176 [==============================] - ETA: 0s - loss: 31020.2070 - mean_squared_error: 31020.20 - 0s 624us/step - loss: 29507.2088 - mean_squared_error: 29507.2088\n",
      "266/266 [==============================] - ETA:  - 0s 116us/step\n"
     ]
    }
   ],
   "source": [
    "import experiment_automation_script\n",
    "from os import path\n",
    "import pandas as pd\n",
    "\n",
    "dataset_info = experiment_automation_script.get_dataset_info(\"diabetes\")\n",
    "url = \"../data/diabetes.csv\" if path.exists(\"../data/diabetes.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, index_col=False)\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "experiment_automation_script.dopify(dataset_info, 'linear_regression', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #2\n",
    "\n",
    "#### UCI Abalone dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x0000025C4CE09C88>\n",
      "From try --  <function glm at 0x0000025C4CBA0048>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "from elif\n",
      "<keras.engine.sequential.Sequential object at 0x0000025C4CE09518>\n",
      "From except --  <function glm at 0x0000025C4CBA0048>\n",
      "Epoch 1/10\n",
      "529/529 [==============================] - ETA: 2s - loss: 0.7830 - acc: 0.406 - 0s 354us/step - loss: 0.7246 - acc: 0.4726\n",
      "Epoch 2/10\n",
      "529/529 [==============================] - ETA: 0s - loss: 0.6524 - acc: 0.562 - 0s 89us/step - loss: 0.7153 - acc: 0.4707\n",
      "Epoch 3/10\n",
      "529/529 [==============================] - ETA: 0s - loss: 0.7824 - acc: 0.312 - 0s 89us/step - loss: 0.7082 - acc: 0.4764\n",
      "Epoch 4/10\n",
      "529/529 [==============================] - ETA: 0s - loss: 0.7153 - acc: 0.437 - ETA: 0s - loss: 0.7007 - acc: 0.480 - 0s 118us/step - loss: 0.7012 - acc: 0.4783\n",
      "Epoch 5/10\n",
      "529/529 [==============================] - ETA: 0s - loss: 0.7122 - acc: 0.468 - 0s 118us/step - loss: 0.6965 - acc: 0.4877\n",
      "Epoch 6/10\n",
      "529/529 [==============================] - ETA: 0s - loss: 0.6591 - acc: 0.593 - 0s 89us/step - loss: 0.6924 - acc: 0.4934\n",
      "Epoch 7/10\n",
      "529/529 [==============================] - ETA: 0s - loss: 0.7516 - acc: 0.281 - 0s 89us/step - loss: 0.6897 - acc: 0.5180\n",
      "Epoch 8/10\n",
      "529/529 [==============================] - ETA: 0s - loss: 0.6986 - acc: 0.437 - 0s 89us/step - loss: 0.6871 - acc: 0.5198\n",
      "Epoch 9/10\n",
      "529/529 [==============================] - ETA: 0s - loss: 0.6705 - acc: 0.625 - 0s 89us/step - loss: 0.6855 - acc: 0.5406\n",
      "Epoch 10/10\n",
      "529/529 [==============================] - ETA: 0s - loss: 0.6752 - acc: 0.625 - 0s 89us/step - loss: 0.6839 - acc: 0.5425\n",
      "794/794 [==============================] - ETA:  - 0s 79us/step\n"
     ]
    }
   ],
   "source": [
    "import experiment_automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "dataset_info = experiment_automation_script.get_dataset_info(\"uci_abalone\")\n",
    "\n",
    "names = [\"sex\", \"length\", \"diameter\", \"height\", \"whole weight\",\n",
    "        \"shucked weight\", \"viscera weight\", \"shell weight\", \"rings\"]\n",
    "url = \"../data/abalone.data.csv\" if path.exists(\"../data/abalone.data.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, names=names, index_col=False)\n",
    "data.head()\n",
    "\n",
    "# Check for columns that contain missing values #\n",
    "col_names = data.columns\n",
    "\n",
    "num_data = data.shape[0]\n",
    "\n",
    "categorical_col = ['sex']\n",
    "for col in categorical_col:\n",
    "    b, c = np.unique(data[col], return_inverse=True)\n",
    "    data[col] = c\n",
    "\n",
    "    \n",
    "# Filter dataset to contain 'rings' 9 and 10 #\n",
    "data = data[data['rings'].isin([9,10])]\n",
    "data['rings'] = data['rings'].map({9: 0, 10: 1})\n",
    "\n",
    "\n",
    "feature_list = names[:7]\n",
    "X = data.loc[:, feature_list]\n",
    "Y = data[['rings']]\n",
    "\n",
    "\n",
    "experiment_automation_script.dopify(dataset_info, 'logistic_regression', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #3\n",
    "\n",
    "#### UCI Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x0000018AB8F652B0>\n",
      "From try --  <function glm at 0x0000018AB8D3D048>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "from elif\n",
      "<keras.engine.sequential.Sequential object at 0x0000018B7A124C88>\n",
      "From except --  <function glm at 0x0000018AB8D3D048>\n",
      "Epoch 1/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.4986 - acc: 0.750 - 0s 4ms/step - loss: 0.5196 - acc: 0.7000\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.5245 - acc: 0.687 - 0s 199us/step - loss: 0.5153 - acc: 0.7000\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.4964 - acc: 0.750 - 0s 299us/step - loss: 0.5101 - acc: 0.7250\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.5117 - acc: 0.718 - 0s 274us/step - loss: 0.5057 - acc: 0.7250\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.5176 - acc: 0.687 - 0s 274us/step - loss: 0.5009 - acc: 0.7250\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.5151 - acc: 0.687 - 0s 249us/step - loss: 0.4965 - acc: 0.7250\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.5140 - acc: 0.687 - 0s 274us/step - loss: 0.4922 - acc: 0.7500\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.5042 - acc: 0.781 - 0s 249us/step - loss: 0.4882 - acc: 0.8250\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.4671 - acc: 0.843 - 0s 249us/step - loss: 0.4839 - acc: 0.8500\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.4847 - acc: 0.843 - 0s 249us/step - loss: 0.4806 - acc: 0.8500\n",
      "60/60 [==============================] - ETA:  - 0s 781us/step\n"
     ]
    }
   ],
   "source": [
    "import experiment_automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "dataset_name = \"uci_iris\"\n",
    "dataset_info = experiment_automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "url = \"../data/iris.csv\" if path.exists(\"../data/iris.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
    "class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "data.iloc[:,-1] = index\n",
    "data = data.loc[data[4] != 2]\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "experiment_automation_script.dopify(dataset_info, 'logistic_regression', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from else\n",
      "input from __call__  --  Tensor(\"dense_1_input:0\", shape=(?, 4), dtype=float32)\n",
      "Epoch 1/1\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.6207 - acc: 0.468 - 0s 4ms/step - loss: 1.3985 - acc: 0.5500\n",
      "60/60 [==============================] - ETA:  - 0s 931us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4666666626930237"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "np.random.seed(7)\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1,input_dim=4,activation='sigmoid'))\n",
    "\n",
    "    # Compile the model #\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "    \n",
    "\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "scores = model.score(x_test, y_test)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input from __call__  --  Tensor(\"dense_2_input_1:0\", shape=(?, 4), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x175431b9f28>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model.__call__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #4\n",
    "\n",
    "#### UCI Adult salary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x0000022E25D08160>\n",
      "From try --  <function glm at 0x0000022E23B86F28>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:31<00:00, 31.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "from elif\n",
      "<keras.engine.sequential.Sequential object at 0x0000022EFAA60E10>\n",
      "From except --  <function glm at 0x0000022E23B86F28>\n",
      "Epoch 1/10\n",
      "18088/18088 [==============================] - ETA: 1:36 - loss: 4.5332 - acc: 0.718 - ETA: 6s - loss: 3.6769 - acc: 0.7719  - ETA: 3s - loss: 3.7101 - acc: 0.769 - ETA: 2s - loss: 3.7337 - acc: 0.768 - ETA: 2s - loss: 3.6822 - acc: 0.771 - ETA: 1s - loss: 3.7573 - acc: 0.766 - ETA: 1s - loss: 3.7464 - acc: 0.767 - ETA: 1s - loss: 3.7853 - acc: 0.765 - ETA: 1s - loss: 3.8051 - acc: 0.763 - ETA: 1s - loss: 3.8077 - acc: 0.763 - ETA: 1s - loss: 3.8414 - acc: 0.761 - ETA: 0s - loss: 3.8220 - acc: 0.762 - ETA: 0s - loss: 3.8507 - acc: 0.761 - ETA: 0s - loss: 3.8475 - acc: 0.761 - ETA: 0s - loss: 3.8289 - acc: 0.762 - ETA: 0s - loss: 3.8144 - acc: 0.763 - ETA: 0s - loss: 3.8425 - acc: 0.761 - ETA: 0s - loss: 3.8558 - acc: 0.760 - ETA: 0s - loss: 3.8683 - acc: 0.760 - ETA: 0s - loss: 3.8731 - acc: 0.759 - ETA: 0s - loss: 3.8738 - acc: 0.759 - ETA: 0s - loss: 3.8766 - acc: 0.759 - ETA: 0s - loss: 3.8831 - acc: 0.759 - 2s 85us/step - loss: 3.8789 - acc: 0.7593\n",
      "Epoch 2/10\n",
      "18088/18088 [==============================] - ETA: 8s - loss: 2.0148 - acc: 0.875 - ETA: 1s - loss: 3.8989 - acc: 0.758 - ETA: 1s - loss: 3.8647 - acc: 0.760 - ETA: 1s - loss: 3.9385 - acc: 0.755 - ETA: 1s - loss: 3.9161 - acc: 0.757 - ETA: 1s - loss: 3.9711 - acc: 0.753 - ETA: 0s - loss: 3.9173 - acc: 0.757 - ETA: 0s - loss: 3.9049 - acc: 0.757 - ETA: 0s - loss: 3.9260 - acc: 0.756 - ETA: 0s - loss: 3.9077 - acc: 0.757 - ETA: 0s - loss: 3.9347 - acc: 0.755 - ETA: 0s - loss: 3.9349 - acc: 0.755 - ETA: 0s - loss: 3.9341 - acc: 0.755 - ETA: 0s - loss: 3.9239 - acc: 0.756 - ETA: 0s - loss: 3.9277 - acc: 0.756 - ETA: 0s - loss: 3.9140 - acc: 0.757 - ETA: 0s - loss: 3.8853 - acc: 0.758 - ETA: 0s - loss: 3.8964 - acc: 0.758 - ETA: 0s - loss: 3.8959 - acc: 0.758 - ETA: 0s - loss: 3.9211 - acc: 0.756 - ETA: 0s - loss: 3.9029 - acc: 0.757 - ETA: 0s - loss: 3.8856 - acc: 0.758 - ETA: 0s - loss: 3.8753 - acc: 0.759 - 1s 79us/step - loss: 3.8789 - acc: 0.7593\n",
      "Epoch 3/10\n",
      "18088/18088 [==============================] - ETA: 0s - loss: 3.5258 - acc: 0.781 - ETA: 2s - loss: 3.8280 - acc: 0.762 - ETA: 1s - loss: 3.9851 - acc: 0.752 - ETA: 1s - loss: 4.0379 - acc: 0.749 - ETA: 1s - loss: 3.9821 - acc: 0.752 - ETA: 1s - loss: 3.9547 - acc: 0.754 - ETA: 1s - loss: 3.8826 - acc: 0.759 - ETA: 1s - loss: 3.8892 - acc: 0.758 - ETA: 1s - loss: 3.8887 - acc: 0.758 - ETA: 1s - loss: 3.8986 - acc: 0.758 - ETA: 1s - loss: 3.9023 - acc: 0.757 - ETA: 1s - loss: 3.9002 - acc: 0.758 - ETA: 1s - loss: 3.9089 - acc: 0.757 - ETA: 0s - loss: 3.9061 - acc: 0.757 - ETA: 0s - loss: 3.9108 - acc: 0.757 - ETA: 0s - loss: 3.9074 - acc: 0.757 - ETA: 0s - loss: 3.9008 - acc: 0.758 - ETA: 0s - loss: 3.8984 - acc: 0.758 - ETA: 0s - loss: 3.8928 - acc: 0.758 - ETA: 0s - loss: 3.8867 - acc: 0.758 - ETA: 0s - loss: 3.8915 - acc: 0.758 - ETA: 0s - loss: 3.8864 - acc: 0.758 - ETA: 0s - loss: 3.9044 - acc: 0.757 - ETA: 0s - loss: 3.9016 - acc: 0.757 - ETA: 0s - loss: 3.8968 - acc: 0.758 - ETA: 0s - loss: 3.8904 - acc: 0.758 - 2s 89us/step - loss: 3.8789 - acc: 0.7593\n",
      "Epoch 4/10\n",
      "18088/18088 [==============================] - ETA: 8s - loss: 4.5332 - acc: 0.718 - ETA: 1s - loss: 3.4601 - acc: 0.785 - ETA: 1s - loss: 3.9438 - acc: 0.755 - ETA: 1s - loss: 3.9360 - acc: 0.755 - ETA: 1s - loss: 3.8753 - acc: 0.759 - ETA: 1s - loss: 3.7756 - acc: 0.765 - ETA: 1s - loss: 3.8342 - acc: 0.762 - ETA: 1s - loss: 3.8674 - acc: 0.760 - ETA: 0s - loss: 3.7990 - acc: 0.764 - ETA: 0s - loss: 3.8022 - acc: 0.764 - ETA: 0s - loss: 3.7966 - acc: 0.764 - ETA: 0s - loss: 3.8538 - acc: 0.760 - ETA: 0s - loss: 3.8761 - acc: 0.759 - ETA: 0s - loss: 3.9021 - acc: 0.757 - ETA: 0s - loss: 3.9061 - acc: 0.757 - ETA: 0s - loss: 3.9036 - acc: 0.757 - ETA: 0s - loss: 3.9055 - acc: 0.757 - ETA: 0s - loss: 3.8988 - acc: 0.758 - ETA: 0s - loss: 3.8923 - acc: 0.758 - ETA: 0s - loss: 3.8835 - acc: 0.759 - ETA: 0s - loss: 3.8965 - acc: 0.758 - ETA: 0s - loss: 3.9004 - acc: 0.758 - ETA: 0s - loss: 3.8838 - acc: 0.759 - 1s 80us/step - loss: 3.8789 - acc: 0.7593\n",
      "Epoch 5/10\n",
      "18088/18088 [==============================] - ETA: 0s - loss: 3.5258 - acc: 0.781 - ETA: 2s - loss: 4.8432 - acc: 0.699 - ETA: 1s - loss: 4.0715 - acc: 0.747 - ETA: 1s - loss: 4.2164 - acc: 0.738 - ETA: 1s - loss: 4.1048 - acc: 0.745 - ETA: 1s - loss: 4.1190 - acc: 0.744 - ETA: 1s - loss: 4.0333 - acc: 0.749 - ETA: 1s - loss: 4.0295 - acc: 0.750 - ETA: 0s - loss: 4.0085 - acc: 0.751 - ETA: 0s - loss: 3.9979 - acc: 0.752 - ETA: 0s - loss: 3.9780 - acc: 0.753 - ETA: 0s - loss: 3.9284 - acc: 0.756 - ETA: 0s - loss: 3.9220 - acc: 0.756 - ETA: 0s - loss: 3.9300 - acc: 0.756 - ETA: 0s - loss: 3.9339 - acc: 0.755 - ETA: 0s - loss: 3.9098 - acc: 0.757 - ETA: 0s - loss: 3.8798 - acc: 0.759 - ETA: 0s - loss: 3.8786 - acc: 0.759 - ETA: 0s - loss: 3.8993 - acc: 0.758 - ETA: 0s - loss: 3.8950 - acc: 0.758 - ETA: 0s - loss: 3.8950 - acc: 0.758 - ETA: 0s - loss: 3.8903 - acc: 0.758 - 1s 74us/step - loss: 3.8789 - acc: 0.7593\n",
      "Epoch 6/10\n",
      "18088/18088 [==============================] - ETA: 8s - loss: 4.5332 - acc: 0.718 - ETA: 2s - loss: 4.0055 - acc: 0.751 - ETA: 1s - loss: 4.2755 - acc: 0.734 - ETA: 1s - loss: 4.1211 - acc: 0.744 - ETA: 1s - loss: 4.0079 - acc: 0.751 - ETA: 1s - loss: 3.9951 - acc: 0.752 - ETA: 1s - loss: 3.9144 - acc: 0.757 - ETA: 1s - loss: 3.9374 - acc: 0.755 - ETA: 1s - loss: 3.8795 - acc: 0.759 - ETA: 0s - loss: 3.9054 - acc: 0.757 - ETA: 0s - loss: 3.8868 - acc: 0.758 - ETA: 0s - loss: 3.8822 - acc: 0.759 - ETA: 0s - loss: 3.8846 - acc: 0.759 - ETA: 0s - loss: 3.8593 - acc: 0.760 - ETA: 0s - loss: 3.8870 - acc: 0.758 - ETA: 0s - loss: 3.8940 - acc: 0.758 - ETA: 0s - loss: 3.9003 - acc: 0.758 - ETA: 0s - loss: 3.9066 - acc: 0.757 - ETA: 0s - loss: 3.9087 - acc: 0.757 - ETA: 0s - loss: 3.9326 - acc: 0.756 - ETA: 0s - loss: 3.9180 - acc: 0.756 - ETA: 0s - loss: 3.9170 - acc: 0.757 - ETA: 0s - loss: 3.9198 - acc: 0.756 - ETA: 0s - loss: 3.9077 - acc: 0.757 - ETA: 0s - loss: 3.8943 - acc: 0.758 - 2s 87us/step - loss: 3.8789 - acc: 0.7593\n",
      "Epoch 7/10\n",
      "18088/18088 [==============================] - ETA: 0s - loss: 4.5332 - acc: 0.718 - ETA: 2s - loss: 4.6591 - acc: 0.710 - ETA: 1s - loss: 4.0583 - acc: 0.748 - ETA: 1s - loss: 3.7734 - acc: 0.765 - ETA: 1s - loss: 3.8103 - acc: 0.763 - ETA: 1s - loss: 3.8130 - acc: 0.763 - ETA: 1s - loss: 3.7470 - acc: 0.767 - ETA: 1s - loss: 3.7343 - acc: 0.768 - ETA: 1s - loss: 3.7034 - acc: 0.770 - ETA: 1s - loss: 3.7085 - acc: 0.769 - ETA: 0s - loss: 3.7581 - acc: 0.766 - ETA: 0s - loss: 3.7694 - acc: 0.766 - ETA: 0s - loss: 3.8013 - acc: 0.764 - ETA: 0s - loss: 3.8462 - acc: 0.761 - ETA: 0s - loss: 3.8359 - acc: 0.762 - ETA: 0s - loss: 3.8395 - acc: 0.761 - ETA: 0s - loss: 3.8653 - acc: 0.760 - ETA: 0s - loss: 3.8459 - acc: 0.761 - ETA: 0s - loss: 3.8540 - acc: 0.760 - ETA: 0s - loss: 3.8735 - acc: 0.759 - ETA: 0s - loss: 3.8768 - acc: 0.759 - ETA: 0s - loss: 3.8802 - acc: 0.759 - ETA: 0s - loss: 3.8851 - acc: 0.759 - ETA: 0s - loss: 3.8861 - acc: 0.758 - 1s 83us/step - loss: 3.8789 - acc: 0.7593\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18088/18088 [==============================] - ETA: 0s - loss: 2.5185 - acc: 0.843 - ETA: 1s - loss: 3.7777 - acc: 0.765 - ETA: 1s - loss: 3.7002 - acc: 0.770 - ETA: 1s - loss: 3.8389 - acc: 0.761 - ETA: 1s - loss: 3.8927 - acc: 0.758 - ETA: 1s - loss: 3.9841 - acc: 0.752 - ETA: 1s - loss: 3.9616 - acc: 0.754 - ETA: 1s - loss: 3.9240 - acc: 0.756 - ETA: 1s - loss: 3.9205 - acc: 0.756 - ETA: 1s - loss: 3.9288 - acc: 0.756 - ETA: 1s - loss: 3.9274 - acc: 0.756 - ETA: 0s - loss: 3.9181 - acc: 0.756 - ETA: 0s - loss: 3.9002 - acc: 0.758 - ETA: 0s - loss: 3.9099 - acc: 0.757 - ETA: 0s - loss: 3.9508 - acc: 0.754 - ETA: 0s - loss: 3.9193 - acc: 0.756 - ETA: 0s - loss: 3.9122 - acc: 0.757 - ETA: 0s - loss: 3.9372 - acc: 0.755 - ETA: 0s - loss: 3.9109 - acc: 0.757 - ETA: 0s - loss: 3.9299 - acc: 0.756 - ETA: 0s - loss: 3.9103 - acc: 0.757 - ETA: 0s - loss: 3.9177 - acc: 0.756 - ETA: 0s - loss: 3.8972 - acc: 0.758 - ETA: 0s - loss: 3.8891 - acc: 0.758 - ETA: 0s - loss: 3.8724 - acc: 0.759 - ETA: 0s - loss: 3.8845 - acc: 0.759 - ETA: 0s - loss: 3.9055 - acc: 0.757 - ETA: 0s - loss: 3.8925 - acc: 0.758 - 2s 96us/step - loss: 3.8789 - acc: 0.7593\n",
      "Epoch 9/10\n",
      "18088/18088 [==============================] - ETA: 8s - loss: 3.5258 - acc: 0.781 - ETA: 2s - loss: 4.0775 - acc: 0.747 - ETA: 1s - loss: 4.0647 - acc: 0.747 - ETA: 1s - loss: 3.9406 - acc: 0.755 - ETA: 1s - loss: 3.8721 - acc: 0.759 - ETA: 1s - loss: 3.8102 - acc: 0.763 - ETA: 1s - loss: 3.8605 - acc: 0.760 - ETA: 0s - loss: 3.8916 - acc: 0.758 - ETA: 0s - loss: 3.8926 - acc: 0.758 - ETA: 0s - loss: 3.8804 - acc: 0.759 - ETA: 0s - loss: 3.8848 - acc: 0.759 - ETA: 0s - loss: 3.8704 - acc: 0.759 - ETA: 0s - loss: 3.9132 - acc: 0.757 - ETA: 0s - loss: 3.8675 - acc: 0.760 - ETA: 0s - loss: 3.8958 - acc: 0.758 - ETA: 0s - loss: 3.8948 - acc: 0.758 - ETA: 0s - loss: 3.8828 - acc: 0.759 - ETA: 0s - loss: 3.8995 - acc: 0.758 - ETA: 0s - loss: 3.8834 - acc: 0.759 - ETA: 0s - loss: 3.8718 - acc: 0.759 - ETA: 0s - loss: 3.8857 - acc: 0.758 - 1s 73us/step - loss: 3.8789 - acc: 0.7593\n",
      "Epoch 10/10\n",
      "18088/18088 [==============================] - ETA: 0s - loss: 3.0221 - acc: 0.812 - ETA: 1s - loss: 3.7548 - acc: 0.767 - ETA: 1s - loss: 3.9036 - acc: 0.757 - ETA: 1s - loss: 3.8464 - acc: 0.761 - ETA: 1s - loss: 3.8632 - acc: 0.760 - ETA: 1s - loss: 3.8153 - acc: 0.763 - ETA: 0s - loss: 3.8375 - acc: 0.761 - ETA: 0s - loss: 3.8599 - acc: 0.760 - ETA: 0s - loss: 3.8869 - acc: 0.758 - ETA: 0s - loss: 3.8657 - acc: 0.760 - ETA: 0s - loss: 3.8917 - acc: 0.758 - ETA: 0s - loss: 3.8926 - acc: 0.758 - ETA: 0s - loss: 3.8981 - acc: 0.758 - ETA: 0s - loss: 3.8939 - acc: 0.758 - ETA: 0s - loss: 3.8745 - acc: 0.759 - ETA: 0s - loss: 3.8856 - acc: 0.758 - ETA: 0s - loss: 3.8932 - acc: 0.758 - ETA: 0s - loss: 3.8841 - acc: 0.759 - ETA: 0s - loss: 3.9041 - acc: 0.757 - ETA: 0s - loss: 3.8905 - acc: 0.758 - ETA: 0s - loss: 3.8785 - acc: 0.759 - 1s 71us/step - loss: 3.8789 - acc: 0.7593\n",
      "27134/27134 [==============================] - ETA: 13 - ETA: 0 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 26us/step\n"
     ]
    }
   ],
   "source": [
    "import experiment_automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "dataset_name = \"uci_adult_salary\"\n",
    "dataset_info = experiment_automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "\n",
    "names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "         'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', \n",
    "         'hours-per-week', 'native-country', 'target']\n",
    "url = \"../data/iris.csv\" if path.exists(\"../data/dataset.csv.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\" \", header=None, names=names)\n",
    "\n",
    "\n",
    "data = data[data[\"workclass\"] != \"?\"]\n",
    "data = data[data[\"occupation\"] != \"?\"]\n",
    "data = data[data[\"native-country\"] != \"?\"]\n",
    "\n",
    "# Convert categorical fields #\n",
    "categorical_col = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                   'relationship', 'race', 'sex', 'native-country', 'target']\n",
    "\n",
    "for col in categorical_col:\n",
    "    b, c = np.unique(data[col], return_inverse=True)\n",
    "    data[col] = c\n",
    "\n",
    "feature_list = names[:14]\n",
    "# Test train split #\n",
    "X = data.loc[:, feature_list]\n",
    "Y = data[['target']]\n",
    "\n",
    "experiment_automation_script.dopify(dataset_info, 'logistic_regression', X, Y, 0.60)\n",
    "\n",
    "# Split the dataset into test and train datasets\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #5\n",
    "\n",
    "#### UCI Ad dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x000001C8E1478668>\n",
      "From try --  <function glm at 0x000001C8E1236F28>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "from elif\n",
      "<keras.engine.sequential.Sequential object at 0x000001C8E1478940>\n",
      "From except --  <function glm at 0x000001C8E1236F28>\n",
      "Epoch 1/10\n",
      "943/943 [==============================] - ETA: 4s - loss: 0.7525 - acc: 0.500 - ETA: 0s - loss: 0.7753 - acc: 0.589 - ETA: 0s - loss: 0.6939 - acc: 0.658 - 0s 274us/step - loss: 0.6936 - acc: 0.6564\n",
      "Epoch 2/10\n",
      "943/943 [==============================] - ETA: 0s - loss: 0.4893 - acc: 0.781 - ETA: 0s - loss: 0.4560 - acc: 0.846 - 0s 135us/step - loss: 0.3951 - acc: 0.8791\n",
      "Epoch 3/10\n",
      "943/943 [==============================] - ETA: 0s - loss: 0.3706 - acc: 0.906 - ETA: 0s - loss: 0.2988 - acc: 0.921 - 0s 116us/step - loss: 0.2698 - acc: 0.9374\n",
      "Epoch 4/10\n",
      "943/943 [==============================] - ETA: 0s - loss: 0.1768 - acc: 0.968 - ETA: 0s - loss: 0.2124 - acc: 0.951 - 0s 116us/step - loss: 0.2017 - acc: 0.9512\n",
      "Epoch 5/10\n",
      "943/943 [==============================] - ETA: 0s - loss: 0.1759 - acc: 0.937 - ETA: 0s - loss: 0.1599 - acc: 0.968 - 0s 116us/step - loss: 0.1606 - acc: 0.9629\n",
      "Epoch 6/10\n",
      "943/943 [==============================] - ETA: 0s - loss: 0.1192 - acc: 0.968 - ETA: 0s - loss: 0.1271 - acc: 0.972 - 0s 116us/step - loss: 0.1356 - acc: 0.9692\n",
      "Epoch 7/10\n",
      "943/943 [==============================] - ETA: 0s - loss: 0.0763 - acc: 1.000 - ETA: 0s - loss: 0.1314 - acc: 0.970 - 0s 99us/step - loss: 0.1184 - acc: 0.9745\n",
      "Epoch 8/10\n",
      "943/943 [==============================] - ETA: 0s - loss: 0.1118 - acc: 0.968 - ETA: 0s - loss: 0.1037 - acc: 0.977 - 0s 116us/step - loss: 0.1057 - acc: 0.9735\n",
      "Epoch 9/10\n",
      "943/943 [==============================] - ETA: 0s - loss: 0.1372 - acc: 0.937 - ETA: 0s - loss: 0.1164 - acc: 0.966 - 0s 116us/step - loss: 0.0963 - acc: 0.9767\n",
      "Epoch 10/10\n",
      "943/943 [==============================] - ETA: 0s - loss: 0.1180 - acc: 0.937 - ETA: 0s - loss: 0.0916 - acc: 0.980 - 0s 116us/step - loss: 0.0881 - acc: 0.9809\n",
      "1416/1416 [==============================] - ETA:  - ETA:  - 0s 77us/step\n"
     ]
    }
   ],
   "source": [
    "import experiment_automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "dataset_name = \"uci_ad\"\n",
    "dataset_info = experiment_automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "url = \"../data/ad.data.csv\" if path.exists(\"../data/dataset.csv.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, index_col=False)\n",
    "\n",
    "# Check for columns that contain missing values #\n",
    "\n",
    "data = data.applymap(lambda val: np.nan if str(val).strip() == '?' else val)\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "# Label encoding #\n",
    "\n",
    "lb = LabelEncoder()\n",
    "Y = lb.fit_transform(data.iloc[:, -1])\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "\n",
    "# Normalize the X values #\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X = pd.DataFrame(X)\n",
    "Y = pd.DataFrame(Y)\n",
    "\n",
    "experiment_automation_script.dopify(dataset_info, 'logistic_regression', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #6\n",
    "\n",
    "#### UCI Mushroom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LinearRegression'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "\n",
    "model_name = 'linear_regression'\n",
    "model_mappings = {\n",
    "    'linear_regression': 'LinearRegression',\n",
    "    'logistic_regression': 'LogisticRegression'\n",
    "}\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "for key, value in model_mappings.items():\n",
    "    if key == model_name:\n",
    "        name = value\n",
    "\n",
    "module = __import__('sklearn.linear_model', fromlist=[name])\n",
    "imported_module = getattr(module, name)\n",
    "model = imported_module\n",
    "\n",
    "primal_model = model()\n",
    "\n",
    "# Primal\n",
    "primal_model.fit(x_train, y_train)\n",
    "primal_model.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes.data\n",
    "# sc = StandardScaler()\n",
    "# diabetes.data = sc.fit_transform(diabetes.data)\n",
    "\n",
    "X = diabetes.data\n",
    "Y = diabetes.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "# # Split the data into training/testing sets\n",
    "# x_train = diabetes_X[:-20]\n",
    "# x_test = diabetes_X[-20:]\n",
    "\n",
    "# # Split the targets into training/testing sets\n",
    "# y_train = diabetes.target[:-20]\n",
    "# y_test = diabetes.target[-20:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_data = np.column_stack([X,Y])\n",
    "# np.savetxt(\"diabetes.csv\", temp_data, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\shakk\\\\Anaconda2\\\\envs\\\\py36\\\\lib\\\\site-packages\\\\winmltools\\\\__init__.py'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import winmltools\n",
    "winmltools.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxmltools\n",
    "\n",
    "def f1(**kwargs):\n",
    "    params_json = json.load(open('../imly/architectures/sklearn/params.json'))\n",
    "    params = params_json['params']\n",
    "    kwargs.setdefault('params', params)\n",
    "    kwargs.setdefault('x_train', np.array([[1], [2]]))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(kwargs['params']['first_neuron'],\n",
    "                    input_dim=kwargs['x_train'].shape[1],\n",
    "                    activation=kwargs['params']['activation']))\n",
    "\n",
    "    model.compile(optimizer=kwargs['params']['optimizer'],\n",
    "                  loss=kwargs['params']['losses'],\n",
    "                  metrics=['acc'])\n",
    "    onnx_model = onnxmltools.convert_keras(model, target_opset=8)\n",
    "    print(type(model))\n",
    "    onnx_model\n",
    "    return onnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The maximum opset needed by this model is only 7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.engine.sequential.Sequential'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = f1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "onnx.onnx_ml_pb2.ModelProto"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)\n",
    "# cross check import (f1p1 and f2p2 combination) - Is it possible to edit after the export-import flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "onnx.save(model, './onnx_model.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test bed ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LogisticRegression': True}\n",
      "{'LinearRegression': True}\n"
     ]
    }
   ],
   "source": [
    "mapping = { \"KerasClassifier\": {\n",
    "    \"LogisticRegression\": True\n",
    "},\n",
    " \"KerasRegressor\": {\n",
    "     \"LinearRegression\": True\n",
    " }\n",
    "}\n",
    "\n",
    "name = \"LinearRegression\"\n",
    "\n",
    "for key, value in mapping.items():\n",
    "    test = mapping[key]\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "def glm(**kwargs):  # Should param_name be optional or mandatory?\n",
    "\n",
    "    # kwargs.setdefault('param_name', 'glm_1')\n",
    "    params_json = json.load(open('../imly/architectures/sklearn/params.json')) # Remove and make it generic\n",
    "    params = params_json['params'][kwargs['param_name']]\n",
    "    kwargs.setdefault('params', params)\n",
    "    kwargs.setdefault('x_train', np.array([[1], [2]]))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(kwargs['params']['first_neuron'], # Change first_neuron to input_size\n",
    "                    input_dim=kwargs['x_train'].shape[1], # Find a better way to pass input_dim. Through params maybe?\n",
    "                    activation=kwargs['params']['activation']))\n",
    "\n",
    "    model.compile(optimizer=kwargs['params']['optimizer'],\n",
    "                  loss=kwargs['params']['losses'],\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x17f81a0aeb8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm.__call__(param_name=\"log_reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
