{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments using IMLY ###\n",
    "\n",
    "This notebook contains experimental runs of IMLY with different datasets.  \n",
    "The readings of these experiments can be referred to in this [sheet](https://docs.google.com/spreadsheets/d/1E5jcq2w42gN8bMIaeaRJpAdhgSVN-2XDJ_YTHe4qfwY/edit?usp=sharing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #1\n",
    "\n",
    "#### Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "266/266 [==============================] - ETA:  - 0s 109us/step\n",
      "Uploading ../data/diabetes_linear_regression.pdf to Amazon S3 bucket mlsquare-datasets\n",
      "..."
     ]
    }
   ],
   "source": [
    "import automation_script\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dataset_info = automation_script.get_dataset_info(\"diabetes\")\n",
    "url = \"../data/diabetes.csv\" if path.exists(\"../data/diabetes.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, index_col=False)\n",
    "sc = StandardScaler()\n",
    "data = sc.fit_transform(data)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "# X = preprocessing.scale(X)\n",
    "# Y = preprocessing.normalize(Y)\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'linear_regression', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #2\n",
    "\n",
    "#### UCI Abalone dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "  round_epochs            val_loss                loss  lr units batch_size  \\\n",
      "0           10  0.6475951799056815  0.6550543823757687  30     1         10   \n",
      "\n",
      "  epochs weight_regulizer emb_output_dims optimizer               losses  \\\n",
      "0     10             None            None      adam  binary_crossentropy   \n",
      "\n",
      "  activation          model_name  \n",
      "0    sigmoid  LogisticRegression  \n",
      "794/794 [==============================] - ETA:  - 0s 79us/step\n"
     ]
    }
   ],
   "source": [
    "import experiment_automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "dataset_info = experiment_automation_script.get_dataset_info(\"uci_abalone\")\n",
    "\n",
    "names = [\"sex\", \"length\", \"diameter\", \"height\", \"whole weight\",\n",
    "        \"shucked weight\", \"viscera weight\", \"shell weight\", \"rings\"]\n",
    "url = \"../data/abalone.data.csv\" if path.exists(\"../data/abalone.data.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, names=names, index_col=False)\n",
    "data.head()\n",
    "\n",
    "# Check for columns that contain missing values #\n",
    "col_names = data.columns\n",
    "\n",
    "num_data = data.shape[0]\n",
    "\n",
    "categorical_col = ['sex']\n",
    "for col in categorical_col:\n",
    "    b, c = np.unique(data[col], return_inverse=True)\n",
    "    data[col] = c\n",
    "\n",
    "    \n",
    "# Filter dataset to contain 'rings' 9 and 10 #\n",
    "data = data[data['rings'].isin([9,10])]\n",
    "data['rings'] = data['rings'].map({9: 0, 10: 1})\n",
    "\n",
    "\n",
    "feature_list = names[:7]\n",
    "X = data.loc[:, feature_list]\n",
    "Y = data[['rings']]\n",
    "\n",
    "\n",
    "experiment_automation_script.dopify(dataset_info, 'logistic_regression', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #3\n",
    "\n",
    "#### UCI Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "  round_epochs            val_loss                loss  lr units batch_size  \\\n",
      "0          200  0.7741430004437765  0.7907322347164154  30     1         10   \n",
      "\n",
      "  epochs weight_regulizer emb_output_dims optimizer               losses  \\\n",
      "0    200             None            None      adam  binary_crossentropy   \n",
      "\n",
      "  activation          model_name  \n",
      "0    sigmoid  LogisticRegression  \n",
      "60/60 [==============================] - ETA:  - 0s 261us/step\n"
     ]
    }
   ],
   "source": [
    "import experiment_automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "dataset_name = \"uci_iris\"\n",
    "dataset_info = experiment_automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "url = \"../data/iris.csv\" if path.exists(\"../data/iris.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
    "class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "data.iloc[:,-1] = index\n",
    "data = data.loc[data[4] != 2]\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "params = {\n",
    "    'epochs': 200\n",
    "}\n",
    "\n",
    "experiment_automation_script.dopify(dataset_info, 'logistic_regression', X, Y, 0.60, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from else\n",
      "input from __call__  --  Tensor(\"dense_1_input:0\", shape=(?, 4), dtype=float32)\n",
      "Epoch 1/1\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.6207 - acc: 0.468 - 0s 4ms/step - loss: 1.3985 - acc: 0.5500\n",
      "60/60 [==============================] - ETA:  - 0s 931us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4666666626930237"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "np.random.seed(7)\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1,input_dim=4,activation='sigmoid'))\n",
    "\n",
    "    # Compile the model #\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "    \n",
    "\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "scores = model.score(x_test, y_test)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input from __call__  --  Tensor(\"dense_2_input_1:0\", shape=(?, 4), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x175431b9f28>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model.__call__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #4\n",
    "\n",
    "#### UCI Adult salary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x0000022E25D08160>\n",
      "From try --  <function glm at 0x0000022E23B86F28>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:31<00:00, 31.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "from elif\n",
      "<keras.engine.sequential.Sequential object at 0x0000022EFAA60E10>\n",
      "From except --  <function glm at 0x0000022E23B86F28>\n",
      "Epoch 1/10\n",
      "18088/18088 [==============================] - ETA: 1:36 - loss: 4.5332 - acc: 0.718 - ETA: 6s - loss: 3.6769 - acc: 0.7719  - ETA: 3s - loss: 3.7101 - acc: 0.769 - ETA: 2s - loss: 3.7337 - acc: 0.768 - ETA: 2s - loss: 3.6822 - acc: 0.771 - ETA: 1s - loss: 3.7573 - acc: 0.766 - ETA: 1s - loss: 3.7464 - acc: 0.767 - ETA: 1s - loss: 3.7853 - acc: 0.765 - ETA: 1s - loss: 3.8051 - acc: 0.763 - ETA: 1s - loss: 3.8077 - acc: 0.763 - ETA: 1s - loss: 3.8414 - acc: 0.761 - ETA: 0s - loss: 3.8220 - acc: 0.762 - ETA: 0s - loss: 3.8507 - acc: 0.761 - ETA: 0s - loss: 3.8475 - acc: 0.761 - ETA: 0s - loss: 3.8289 - acc: 0.762 - ETA: 0s - loss: 3.8144 - acc: 0.763 - ETA: 0s - loss: 3.8425 - acc: 0.761 - ETA: 0s - loss: 3.8558 - acc: 0.760 - ETA: 0s - loss: 3.8683 - acc: 0.760 - ETA: 0s - loss: 3.8731 - acc: 0.759 - ETA: 0s - loss: 3.8738 - acc: 0.759 - ETA: 0s - loss: 3.8766 - acc: 0.759 - ETA: 0s - loss: 3.8831 - acc: 0.759 - 2s 85us/step - loss: 3.8789 - acc: 0.7593\n",
      "Epoch 2/10\n",
      "18088/18088 [==============================] - ETA: 8s - loss: 2.0148 - acc: 0.875 - ETA: 1s - loss: 3.8989 - acc: 0.758 - ETA: 1s - loss: 3.8647 - acc: 0.760 - ETA: 1s - loss: 3.9385 - acc: 0.755 - ETA: 1s - loss: 3.9161 - acc: 0.757 - ETA: 1s - loss: 3.9711 - acc: 0.753 - ETA: 0s - loss: 3.9173 - acc: 0.757 - ETA: 0s - loss: 3.9049 - acc: 0.757 - ETA: 0s - loss: 3.9260 - acc: 0.756 - ETA: 0s - loss: 3.9077 - acc: 0.757 - ETA: 0s - loss: 3.9347 - acc: 0.755 - ETA: 0s - loss: 3.9349 - acc: 0.755 - ETA: 0s - loss: 3.9341 - acc: 0.755 - ETA: 0s - loss: 3.9239 - acc: 0.756 - ETA: 0s - loss: 3.9277 - acc: 0.756 - ETA: 0s - loss: 3.9140 - acc: 0.757 - ETA: 0s - loss: 3.8853 - acc: 0.758 - ETA: 0s - loss: 3.8964 - acc: 0.758 - ETA: 0s - loss: 3.8959 - acc: 0.758 - ETA: 0s - loss: 3.9211 - acc: 0.756 - ETA: 0s - loss: 3.9029 - acc: 0.757 - ETA: 0s - loss: 3.8856 - acc: 0.758 - ETA: 0s - loss: 3.8753 - acc: 0.759 - 1s 79us/step - loss: 3.8789 - acc: 0.7593\n",
      "Epoch 3/10\n",
      "18088/18088 [==============================] - ETA: 0s - loss: 3.5258 - acc: 0.781 - ETA: 2s - loss: 3.8280 - acc: 0.762 - ETA: 1s - loss: 3.9851 - acc: 0.752 - ETA: 1s - loss: 4.0379 - acc: 0.749 - ETA: 1s - loss: 3.9821 - acc: 0.752 - ETA: 1s - loss: 3.9547 - acc: 0.754 - ETA: 1s - loss: 3.8826 - acc: 0.759 - ETA: 1s - loss: 3.8892 - acc: 0.758 - ETA: 1s - loss: 3.8887 - acc: 0.758 - ETA: 1s - loss: 3.8986 - acc: 0.758 - ETA: 1s - loss: 3.9023 - acc: 0.757 - ETA: 1s - loss: 3.9002 - acc: 0.758 - ETA: 1s - loss: 3.9089 - acc: 0.757 - ETA: 0s - loss: 3.9061 - acc: 0.757 - ETA: 0s - loss: 3.9108 - acc: 0.757 - ETA: 0s - loss: 3.9074 - acc: 0.757 - ETA: 0s - loss: 3.9008 - acc: 0.758 - ETA: 0s - loss: 3.8984 - acc: 0.758 - ETA: 0s - loss: 3.8928 - acc: 0.758 - ETA: 0s - loss: 3.8867 - acc: 0.758 - ETA: 0s - loss: 3.8915 - acc: 0.758 - ETA: 0s - loss: 3.8864 - acc: 0.758 - ETA: 0s - loss: 3.9044 - acc: 0.757 - ETA: 0s - loss: 3.9016 - acc: 0.757 - ETA: 0s - loss: 3.8968 - acc: 0.758 - ETA: 0s - loss: 3.8904 - acc: 0.758 - 2s 89us/step - loss: 3.8789 - acc: 0.7593\n",
      "Epoch 4/10\n",
      "18088/18088 [==============================] - ETA: 8s - loss: 4.5332 - acc: 0.718 - ETA: 1s - loss: 3.4601 - acc: 0.785 - ETA: 1s - loss: 3.9438 - acc: 0.755 - ETA: 1s - loss: 3.9360 - acc: 0.755 - ETA: 1s - loss: 3.8753 - acc: 0.759 - ETA: 1s - loss: 3.7756 - acc: 0.765 - ETA: 1s - loss: 3.8342 - acc: 0.762 - ETA: 1s - loss: 3.8674 - acc: 0.760 - ETA: 0s - loss: 3.7990 - acc: 0.764 - ETA: 0s - loss: 3.8022 - acc: 0.764 - ETA: 0s - loss: 3.7966 - acc: 0.764 - ETA: 0s - loss: 3.8538 - acc: 0.760 - ETA: 0s - loss: 3.8761 - acc: 0.759 - ETA: 0s - loss: 3.9021 - acc: 0.757 - ETA: 0s - loss: 3.9061 - acc: 0.757 - ETA: 0s - loss: 3.9036 - acc: 0.757 - ETA: 0s - loss: 3.9055 - acc: 0.757 - ETA: 0s - loss: 3.8988 - acc: 0.758 - ETA: 0s - loss: 3.8923 - acc: 0.758 - ETA: 0s - loss: 3.8835 - acc: 0.759 - ETA: 0s - loss: 3.8965 - acc: 0.758 - ETA: 0s - loss: 3.9004 - acc: 0.758 - ETA: 0s - loss: 3.8838 - acc: 0.759 - 1s 80us/step - loss: 3.8789 - acc: 0.7593\n",
      "Epoch 5/10\n",
      "18088/18088 [==============================] - ETA: 0s - loss: 3.5258 - acc: 0.781 - ETA: 2s - loss: 4.8432 - acc: 0.699 - ETA: 1s - loss: 4.0715 - acc: 0.747 - ETA: 1s - loss: 4.2164 - acc: 0.738 - ETA: 1s - loss: 4.1048 - acc: 0.745 - ETA: 1s - loss: 4.1190 - acc: 0.744 - ETA: 1s - loss: 4.0333 - acc: 0.749 - ETA: 1s - loss: 4.0295 - acc: 0.750 - ETA: 0s - loss: 4.0085 - acc: 0.751 - ETA: 0s - loss: 3.9979 - acc: 0.752 - ETA: 0s - loss: 3.9780 - acc: 0.753 - ETA: 0s - loss: 3.9284 - acc: 0.756 - ETA: 0s - loss: 3.9220 - acc: 0.756 - ETA: 0s - loss: 3.9300 - acc: 0.756 - ETA: 0s - loss: 3.9339 - acc: 0.755 - ETA: 0s - loss: 3.9098 - acc: 0.757 - ETA: 0s - loss: 3.8798 - acc: 0.759 - ETA: 0s - loss: 3.8786 - acc: 0.759 - ETA: 0s - loss: 3.8993 - acc: 0.758 - ETA: 0s - loss: 3.8950 - acc: 0.758 - ETA: 0s - loss: 3.8950 - acc: 0.758 - ETA: 0s - loss: 3.8903 - acc: 0.758 - 1s 74us/step - loss: 3.8789 - acc: 0.7593\n",
      "Epoch 6/10\n",
      "18088/18088 [==============================] - ETA: 8s - loss: 4.5332 - acc: 0.718 - ETA: 2s - loss: 4.0055 - acc: 0.751 - ETA: 1s - loss: 4.2755 - acc: 0.734 - ETA: 1s - loss: 4.1211 - acc: 0.744 - ETA: 1s - loss: 4.0079 - acc: 0.751 - ETA: 1s - loss: 3.9951 - acc: 0.752 - ETA: 1s - loss: 3.9144 - acc: 0.757 - ETA: 1s - loss: 3.9374 - acc: 0.755 - ETA: 1s - loss: 3.8795 - acc: 0.759 - ETA: 0s - loss: 3.9054 - acc: 0.757 - ETA: 0s - loss: 3.8868 - acc: 0.758 - ETA: 0s - loss: 3.8822 - acc: 0.759 - ETA: 0s - loss: 3.8846 - acc: 0.759 - ETA: 0s - loss: 3.8593 - acc: 0.760 - ETA: 0s - loss: 3.8870 - acc: 0.758 - ETA: 0s - loss: 3.8940 - acc: 0.758 - ETA: 0s - loss: 3.9003 - acc: 0.758 - ETA: 0s - loss: 3.9066 - acc: 0.757 - ETA: 0s - loss: 3.9087 - acc: 0.757 - ETA: 0s - loss: 3.9326 - acc: 0.756 - ETA: 0s - loss: 3.9180 - acc: 0.756 - ETA: 0s - loss: 3.9170 - acc: 0.757 - ETA: 0s - loss: 3.9198 - acc: 0.756 - ETA: 0s - loss: 3.9077 - acc: 0.757 - ETA: 0s - loss: 3.8943 - acc: 0.758 - 2s 87us/step - loss: 3.8789 - acc: 0.7593\n",
      "Epoch 7/10\n",
      "18088/18088 [==============================] - ETA: 0s - loss: 4.5332 - acc: 0.718 - ETA: 2s - loss: 4.6591 - acc: 0.710 - ETA: 1s - loss: 4.0583 - acc: 0.748 - ETA: 1s - loss: 3.7734 - acc: 0.765 - ETA: 1s - loss: 3.8103 - acc: 0.763 - ETA: 1s - loss: 3.8130 - acc: 0.763 - ETA: 1s - loss: 3.7470 - acc: 0.767 - ETA: 1s - loss: 3.7343 - acc: 0.768 - ETA: 1s - loss: 3.7034 - acc: 0.770 - ETA: 1s - loss: 3.7085 - acc: 0.769 - ETA: 0s - loss: 3.7581 - acc: 0.766 - ETA: 0s - loss: 3.7694 - acc: 0.766 - ETA: 0s - loss: 3.8013 - acc: 0.764 - ETA: 0s - loss: 3.8462 - acc: 0.761 - ETA: 0s - loss: 3.8359 - acc: 0.762 - ETA: 0s - loss: 3.8395 - acc: 0.761 - ETA: 0s - loss: 3.8653 - acc: 0.760 - ETA: 0s - loss: 3.8459 - acc: 0.761 - ETA: 0s - loss: 3.8540 - acc: 0.760 - ETA: 0s - loss: 3.8735 - acc: 0.759 - ETA: 0s - loss: 3.8768 - acc: 0.759 - ETA: 0s - loss: 3.8802 - acc: 0.759 - ETA: 0s - loss: 3.8851 - acc: 0.759 - ETA: 0s - loss: 3.8861 - acc: 0.758 - 1s 83us/step - loss: 3.8789 - acc: 0.7593\n",
      "Epoch 8/10\n",
      "18088/18088 [==============================] - ETA: 0s - loss: 2.5185 - acc: 0.843 - ETA: 1s - loss: 3.7777 - acc: 0.765 - ETA: 1s - loss: 3.7002 - acc: 0.770 - ETA: 1s - loss: 3.8389 - acc: 0.761 - ETA: 1s - loss: 3.8927 - acc: 0.758 - ETA: 1s - loss: 3.9841 - acc: 0.752 - ETA: 1s - loss: 3.9616 - acc: 0.754 - ETA: 1s - loss: 3.9240 - acc: 0.756 - ETA: 1s - loss: 3.9205 - acc: 0.756 - ETA: 1s - loss: 3.9288 - acc: 0.756 - ETA: 1s - loss: 3.9274 - acc: 0.756 - ETA: 0s - loss: 3.9181 - acc: 0.756 - ETA: 0s - loss: 3.9002 - acc: 0.758 - ETA: 0s - loss: 3.9099 - acc: 0.757 - ETA: 0s - loss: 3.9508 - acc: 0.754 - ETA: 0s - loss: 3.9193 - acc: 0.756 - ETA: 0s - loss: 3.9122 - acc: 0.757 - ETA: 0s - loss: 3.9372 - acc: 0.755 - ETA: 0s - loss: 3.9109 - acc: 0.757 - ETA: 0s - loss: 3.9299 - acc: 0.756 - ETA: 0s - loss: 3.9103 - acc: 0.757 - ETA: 0s - loss: 3.9177 - acc: 0.756 - ETA: 0s - loss: 3.8972 - acc: 0.758 - ETA: 0s - loss: 3.8891 - acc: 0.758 - ETA: 0s - loss: 3.8724 - acc: 0.759 - ETA: 0s - loss: 3.8845 - acc: 0.759 - ETA: 0s - loss: 3.9055 - acc: 0.757 - ETA: 0s - loss: 3.8925 - acc: 0.758 - 2s 96us/step - loss: 3.8789 - acc: 0.7593\n",
      "Epoch 9/10\n",
      "18088/18088 [==============================] - ETA: 8s - loss: 3.5258 - acc: 0.781 - ETA: 2s - loss: 4.0775 - acc: 0.747 - ETA: 1s - loss: 4.0647 - acc: 0.747 - ETA: 1s - loss: 3.9406 - acc: 0.755 - ETA: 1s - loss: 3.8721 - acc: 0.759 - ETA: 1s - loss: 3.8102 - acc: 0.763 - ETA: 1s - loss: 3.8605 - acc: 0.760 - ETA: 0s - loss: 3.8916 - acc: 0.758 - ETA: 0s - loss: 3.8926 - acc: 0.758 - ETA: 0s - loss: 3.8804 - acc: 0.759 - ETA: 0s - loss: 3.8848 - acc: 0.759 - ETA: 0s - loss: 3.8704 - acc: 0.759 - ETA: 0s - loss: 3.9132 - acc: 0.757 - ETA: 0s - loss: 3.8675 - acc: 0.760 - ETA: 0s - loss: 3.8958 - acc: 0.758 - ETA: 0s - loss: 3.8948 - acc: 0.758 - ETA: 0s - loss: 3.8828 - acc: 0.759 - ETA: 0s - loss: 3.8995 - acc: 0.758 - ETA: 0s - loss: 3.8834 - acc: 0.759 - ETA: 0s - loss: 3.8718 - acc: 0.759 - ETA: 0s - loss: 3.8857 - acc: 0.758 - 1s 73us/step - loss: 3.8789 - acc: 0.7593\n",
      "Epoch 10/10\n",
      "18088/18088 [==============================] - ETA: 0s - loss: 3.0221 - acc: 0.812 - ETA: 1s - loss: 3.7548 - acc: 0.767 - ETA: 1s - loss: 3.9036 - acc: 0.757 - ETA: 1s - loss: 3.8464 - acc: 0.761 - ETA: 1s - loss: 3.8632 - acc: 0.760 - ETA: 1s - loss: 3.8153 - acc: 0.763 - ETA: 0s - loss: 3.8375 - acc: 0.761 - ETA: 0s - loss: 3.8599 - acc: 0.760 - ETA: 0s - loss: 3.8869 - acc: 0.758 - ETA: 0s - loss: 3.8657 - acc: 0.760 - ETA: 0s - loss: 3.8917 - acc: 0.758 - ETA: 0s - loss: 3.8926 - acc: 0.758 - ETA: 0s - loss: 3.8981 - acc: 0.758 - ETA: 0s - loss: 3.8939 - acc: 0.758 - ETA: 0s - loss: 3.8745 - acc: 0.759 - ETA: 0s - loss: 3.8856 - acc: 0.758 - ETA: 0s - loss: 3.8932 - acc: 0.758 - ETA: 0s - loss: 3.8841 - acc: 0.759 - ETA: 0s - loss: 3.9041 - acc: 0.757 - ETA: 0s - loss: 3.8905 - acc: 0.758 - ETA: 0s - loss: 3.8785 - acc: 0.759 - 1s 71us/step - loss: 3.8789 - acc: 0.7593\n",
      "27134/27134 [==============================] - ETA: 13 - ETA: 0 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 26us/step\n"
     ]
    }
   ],
   "source": [
    "import experiment_automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "dataset_name = \"uci_adult_salary\"\n",
    "dataset_info = experiment_automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "\n",
    "names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "         'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', \n",
    "         'hours-per-week', 'native-country', 'target']\n",
    "url = \"../data/iris.csv\" if path.exists(\"../data/dataset.csv.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\" \", header=None, names=names)\n",
    "\n",
    "\n",
    "data = data[data[\"workclass\"] != \"?\"]\n",
    "data = data[data[\"occupation\"] != \"?\"]\n",
    "data = data[data[\"native-country\"] != \"?\"]\n",
    "\n",
    "# Convert categorical fields #\n",
    "categorical_col = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                   'relationship', 'race', 'sex', 'native-country', 'target']\n",
    "\n",
    "for col in categorical_col:\n",
    "    b, c = np.unique(data[col], return_inverse=True)\n",
    "    data[col] = c\n",
    "\n",
    "feature_list = names[:14]\n",
    "# Test train split #\n",
    "X = data.loc[:, feature_list]\n",
    "Y = data[['target']]\n",
    "\n",
    "experiment_automation_script.dopify(dataset_info, 'logistic_regression', X, Y, 0.60)\n",
    "\n",
    "# Split the dataset into test and train datasets\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #5\n",
    "\n",
    "#### UCI Ad dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x000001C8E1478668>\n",
      "From try --  <function glm at 0x000001C8E1236F28>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "from elif\n",
      "<keras.engine.sequential.Sequential object at 0x000001C8E1478940>\n",
      "From except --  <function glm at 0x000001C8E1236F28>\n",
      "Epoch 1/10\n",
      "943/943 [==============================] - ETA: 4s - loss: 0.7525 - acc: 0.500 - ETA: 0s - loss: 0.7753 - acc: 0.589 - ETA: 0s - loss: 0.6939 - acc: 0.658 - 0s 274us/step - loss: 0.6936 - acc: 0.6564\n",
      "Epoch 2/10\n",
      "943/943 [==============================] - ETA: 0s - loss: 0.4893 - acc: 0.781 - ETA: 0s - loss: 0.4560 - acc: 0.846 - 0s 135us/step - loss: 0.3951 - acc: 0.8791\n",
      "Epoch 3/10\n",
      "943/943 [==============================] - ETA: 0s - loss: 0.3706 - acc: 0.906 - ETA: 0s - loss: 0.2988 - acc: 0.921 - 0s 116us/step - loss: 0.2698 - acc: 0.9374\n",
      "Epoch 4/10\n",
      "943/943 [==============================] - ETA: 0s - loss: 0.1768 - acc: 0.968 - ETA: 0s - loss: 0.2124 - acc: 0.951 - 0s 116us/step - loss: 0.2017 - acc: 0.9512\n",
      "Epoch 5/10\n",
      "943/943 [==============================] - ETA: 0s - loss: 0.1759 - acc: 0.937 - ETA: 0s - loss: 0.1599 - acc: 0.968 - 0s 116us/step - loss: 0.1606 - acc: 0.9629\n",
      "Epoch 6/10\n",
      "943/943 [==============================] - ETA: 0s - loss: 0.1192 - acc: 0.968 - ETA: 0s - loss: 0.1271 - acc: 0.972 - 0s 116us/step - loss: 0.1356 - acc: 0.9692\n",
      "Epoch 7/10\n",
      "943/943 [==============================] - ETA: 0s - loss: 0.0763 - acc: 1.000 - ETA: 0s - loss: 0.1314 - acc: 0.970 - 0s 99us/step - loss: 0.1184 - acc: 0.9745\n",
      "Epoch 8/10\n",
      "943/943 [==============================] - ETA: 0s - loss: 0.1118 - acc: 0.968 - ETA: 0s - loss: 0.1037 - acc: 0.977 - 0s 116us/step - loss: 0.1057 - acc: 0.9735\n",
      "Epoch 9/10\n",
      "943/943 [==============================] - ETA: 0s - loss: 0.1372 - acc: 0.937 - ETA: 0s - loss: 0.1164 - acc: 0.966 - 0s 116us/step - loss: 0.0963 - acc: 0.9767\n",
      "Epoch 10/10\n",
      "943/943 [==============================] - ETA: 0s - loss: 0.1180 - acc: 0.937 - ETA: 0s - loss: 0.0916 - acc: 0.980 - 0s 116us/step - loss: 0.0881 - acc: 0.9809\n",
      "1416/1416 [==============================] - ETA:  - ETA:  - 0s 77us/step\n"
     ]
    }
   ],
   "source": [
    "import experiment_automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "dataset_name = \"uci_ad\"\n",
    "dataset_info = experiment_automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "url = \"../data/ad.data.csv\" if path.exists(\"../data/dataset.csv.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, index_col=False)\n",
    "\n",
    "# Check for columns that contain missing values #\n",
    "\n",
    "data = data.applymap(lambda val: np.nan if str(val).strip() == '?' else val)\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "# Label encoding #\n",
    "\n",
    "lb = LabelEncoder()\n",
    "Y = lb.fit_transform(data.iloc[:, -1])\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "\n",
    "# Normalize the X values #\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X = pd.DataFrame(X)\n",
    "Y = pd.DataFrame(Y)\n",
    "\n",
    "experiment_automation_script.dopify(dataset_info, 'logistic_regression', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #6\n",
    "\n",
    "#### UCI Mushroom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset info #\n",
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "dataset_name = \"uci_mushroom\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields with missing values\n",
      "stalk-root\n",
      "2480\n",
      "30.53%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = ['classes', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment',\n",
    "        'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n",
    "        'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring',\n",
    "        'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color',\n",
    "        'population', 'habitat']\n",
    "url = \"../data/mushroom.data.csv\" if path.exists(\"../data/dataset.csv.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, names=names, index_col=False)\n",
    "\n",
    "# Check for columns that contain missing values #\n",
    "\n",
    "print(\"Fields with missing values\")\n",
    "col_names = data.columns\n",
    "num_data = data.shape[0]\n",
    "for c in col_names:\n",
    "    num_non = data[c].isin([\"?\"]).sum()\n",
    "    if num_non > 0:\n",
    "        print (c)\n",
    "        print (num_non)\n",
    "        print (\"{0:.2f}%\".format(float(num_non) / num_data * 100))\n",
    "        print (\"\\n\")\n",
    "\n",
    "data = data[data[\"stalk-root\"] != \"?\"]\n",
    "\n",
    "# Convert categorical fields #\n",
    "\n",
    "for col in names:\n",
    "    b, c = np.unique(data[col], return_inverse=True)\n",
    "    data[col] = c\n",
    "\n",
    "# Split the dataset into test and train datasets #\n",
    "feature_list = names[1:23]\n",
    "X = data.loc[:, feature_list]\n",
    "Y = data[['classes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "3387/3387 [==============================] - ETA:  - ETA:  - 0s 37us/step\n"
     ]
    }
   ],
   "source": [
    "automation_script.run_imly(dataset_info, 'logistic_regression', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #7\n",
    "\n",
    "#### Covertype dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "dataset_name = \"covertype\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "data = pd.read_csv(\"../data/covtype.data.csv\", delimiter=\",\", header=None, index_col=False)\n",
    "\n",
    "data = data[data[54].isin([1,2])]\n",
    "\n",
    "Y = data.iloc[:, -1]\n",
    "X = data.iloc[:,:-1]\n",
    "\n",
    "# Normalize the X values #\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# X = sc.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [11:53<00:00, 713.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "297085/297085 [==============================] - ETA: 5: - ETA: 1:25:1 - ETA: 5:04  - ETA: 2: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 53s - ETA: 47 - ETA: 41 - ETA: 38 - ETA: 34 - ETA: 32 - ETA: 30 - ETA: 28 - ETA: 26 - ETA: 25 - ETA: 24 - ETA: 23 - ETA: 22 - ETA: 21 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 10s 34us/step\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"epochs\": 200,\n",
    "    \"batch_size\":100\n",
    "}\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'logistic_regression', X, Y, 0.60, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #8\n",
    "\n",
    "#### TestData1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "dataset_name = \"test_data_1\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "data = pd.read_csv(\"../data/testData1.csv\", delimiter=\",\", header=0, index_col=0)\n",
    "\n",
    "\n",
    "Y = data.iloc[:, -1]\n",
    "X = data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "600/600 [==============================] - ETA:  - 0s 125us/step\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\":10\n",
    "}\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'logistic_regression', X, Y, 0.60, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #9\n",
    "\n",
    "#### TestData2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "dataset_name = \"test_data_2\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "data = pd.read_csv(\"../data/testData2.csv\", delimiter=\",\", header=0, index_col=0)\n",
    "\n",
    "\n",
    "Y = data.iloc[:, -1]\n",
    "X = data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique,count = np.unique(Y,return_counts=True)\n",
    "class1=count[0]/X.shape[0]*100\n",
    "class2=count[1]/X.shape[0]*100\n",
    "class_distribution = round(class1, 2)\n",
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "480/480 [==============================] - ETA:  - 0s 102us/step\n",
      "Confusion matrix, without normalization\n",
      "Uploading ../data/test_data_2_logistic_regression.pdf to Amazon S3 bucket mlsquare-datasets\n",
      "..."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\n",
    "    \"epochs\": 1000,\n",
    "    \"batch_size\":100\n",
    "}\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'logistic_regression', X, Y, 0.60, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #10\n",
    "\n",
    "#### UCI Airfoil dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dataset_name = \"uci_airfoil\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "data = pd.read_csv(\"../data/uci_airfoil_self_noise.csv\", delimiter=\",\", header=0, index_col=0)\n",
    "sc = StandardScaler()\n",
    "data = sc.fit_transform(data)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "Y = data.iloc[:, -1]\n",
    "X = data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "902/902 [==============================] - ETA:  - 0s 51us/step\n",
      "Uploading ../data/uci_airfoil_linear_regression.pdf to Amazon S3 bucket mlsquare-datasets\n",
      "...."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "automation_script.run_imly(dataset_info, 'linear_regression', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #11\n",
    "\n",
    "#### UCI Auto-mpg dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dataset_name = \"uci_auto_mpg\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "data = pd.read_csv(\"../data/uci_auto_mpg.csv\", delimiter=\",\", header=0, index_col='car name')\n",
    "data = data[data.horsepower != '?']\n",
    "sc = StandardScaler()\n",
    "data = sc.fit_transform(data)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "Y = data.iloc[:,1]\n",
    "X = data.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "236/236 [==============================] - ETA:  - 0s 106us/step\n",
      "Uploading ../data/uci_auto_mpg_linear_regression.pdf to Amazon S3 bucket mlsquare-datasets\n",
      "..."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "automation_script.run_imly(dataset_info, 'linear_regression', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test bed ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LinearRegression'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "\n",
    "model_name = 'linear_regression'\n",
    "model_mappings = {\n",
    "    'linear_regression': 'LinearRegression',\n",
    "    'logistic_regression': 'LogisticRegression'\n",
    "}\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "for key, value in model_mappings.items():\n",
    "    if key == model_name:\n",
    "        name = value\n",
    "\n",
    "module = __import__('sklearn.linear_model', fromlist=[name])\n",
    "imported_module = getattr(module, name)\n",
    "model = imported_module\n",
    "\n",
    "primal_model = model()\n",
    "\n",
    "# Primal\n",
    "primal_model.fit(x_train, y_train)\n",
    "primal_model.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "import experiment_automation_script\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "dataset_info = experiment_automation_script.get_dataset_info(\"diabetes\")\n",
    "url = \"../data/diabetes.csv\" if path.exists(\"../data/diabetes.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, index_col=False)\n",
    "sc = StandardScaler()\n",
    "data = sc.fit_transform(data)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "# diabetes = datasets.load_diabetes()\n",
    "# sc = StandardScaler()\n",
    "# diabetes = sc.fit_transform(diabetes)\n",
    "#####\n",
    "# # Use only one feature\n",
    "# diabetes_X = diabetes.data\n",
    "# # sc = StandardScaler()\n",
    "# # diabetes.data = sc.fit_transform(diabetes.data)\n",
    "\n",
    "# X = diabetes.data\n",
    "# Y = diabetes.target\n",
    "#####\n",
    "\n",
    "# X = preprocessing.scale(X)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "# # Split the data into training/testing sets\n",
    "# x_train = diabetes_X[:-20]\n",
    "# x_test = diabetes_X[-20:]\n",
    "\n",
    "# # Split the targets into training/testing sets\n",
    "# y_train = diabetes.target[:-20]\n",
    "# y_test = diabetes.target[-20:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "         0.01990842, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "        -0.06832974, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "         0.00286377, -0.02593034],\n",
       "       ...,\n",
       "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "        -0.04687948,  0.01549073],\n",
       "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "         0.04452837, -0.02593034],\n",
       "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "        -0.00421986,  0.00306441]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\shakk\\\\Anaconda2\\\\envs\\\\py36\\\\lib\\\\site-packages\\\\winmltools\\\\__init__.py'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import winmltools\n",
    "winmltools.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxmltools\n",
    "\n",
    "def f1(**kwargs):\n",
    "    params_json = json.load(open('../imly/architectures/sklearn/params.json'))\n",
    "    params = params_json['params'][kwargs['param_name']]\n",
    "    kwargs.setdefault('params', params)\n",
    "    kwargs.setdefault('x_train', np.array([[1], [2]]))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1,\n",
    "                    input_dim=10,\n",
    "                    activation='linear'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_logarithmic_error',\n",
    "                  metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "176/176 [==============================] - ETA: 1s - loss: 0.2475 - mean_squared_error: 1.59 - 0s 2ms/step - loss: 0.1927 - mean_squared_error: 1.3051\n",
      "Epoch 2/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1404 - mean_squared_error: 0.65 - 0s 146us/step - loss: 0.1885 - mean_squared_error: 1.2741\n",
      "Epoch 3/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1835 - mean_squared_error: 1.26 - 0s 183us/step - loss: 0.1846 - mean_squared_error: 1.2461\n",
      "Epoch 4/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1397 - mean_squared_error: 1.04 - 0s 123us/step - loss: 0.1802 - mean_squared_error: 1.2163\n",
      "Epoch 5/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1908 - mean_squared_error: 1.39 - 0s 169us/step - loss: 0.1765 - mean_squared_error: 1.1895\n",
      "Epoch 6/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.2381 - mean_squared_error: 1.53 - 0s 104us/step - loss: 0.1727 - mean_squared_error: 1.1671\n",
      "Epoch 7/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0898 - mean_squared_error: 0.58 - 0s 173us/step - loss: 0.1682 - mean_squared_error: 1.1385\n",
      "Epoch 8/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1478 - mean_squared_error: 1.17 - 0s 184us/step - loss: 0.1653 - mean_squared_error: 1.1167\n",
      "Epoch 9/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1670 - mean_squared_error: 1.13 - 0s 144us/step - loss: 0.1619 - mean_squared_error: 1.0956\n",
      "Epoch 10/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1209 - mean_squared_error: 1.31 - 0s 181us/step - loss: 0.1583 - mean_squared_error: 1.0743\n",
      "Epoch 11/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1768 - mean_squared_error: 1.19 - 0s 141us/step - loss: 0.1547 - mean_squared_error: 1.0536\n",
      "Epoch 12/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1232 - mean_squared_error: 1.09 - 0s 162us/step - loss: 0.1512 - mean_squared_error: 1.0367\n",
      "Epoch 13/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1126 - mean_squared_error: 1.12 - 0s 180us/step - loss: 0.1478 - mean_squared_error: 1.0175\n",
      "Epoch 14/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1868 - mean_squared_error: 1.23 - 0s 168us/step - loss: 0.1449 - mean_squared_error: 1.0013\n",
      "Epoch 15/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1960 - mean_squared_error: 1.00 - 0s 164us/step - loss: 0.1421 - mean_squared_error: 0.9847\n",
      "Epoch 16/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1275 - mean_squared_error: 1.12 - 0s 183us/step - loss: 0.1389 - mean_squared_error: 0.9692\n",
      "Epoch 17/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1564 - mean_squared_error: 0.85 - 0s 152us/step - loss: 0.1362 - mean_squared_error: 0.9551\n",
      "Epoch 18/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1576 - mean_squared_error: 1.08 - 0s 140us/step - loss: 0.1340 - mean_squared_error: 0.9420\n",
      "Epoch 19/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0741 - mean_squared_error: 0.56 - 0s 171us/step - loss: 0.1317 - mean_squared_error: 0.9296\n",
      "Epoch 20/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1936 - mean_squared_error: 0.94 - 0s 121us/step - loss: 0.1298 - mean_squared_error: 0.9174\n",
      "Epoch 21/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0871 - mean_squared_error: 0.76 - 0s 147us/step - loss: 0.1279 - mean_squared_error: 0.9067\n",
      "Epoch 22/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1722 - mean_squared_error: 1.12 - 0s 191us/step - loss: 0.1263 - mean_squared_error: 0.8956\n",
      "Epoch 23/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0510 - mean_squared_error: 0.80 - 0s 205us/step - loss: 0.1247 - mean_squared_error: 0.8853\n",
      "Epoch 24/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1314 - mean_squared_error: 1.16 - 0s 107us/step - loss: 0.1234 - mean_squared_error: 0.8751\n",
      "Epoch 25/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0419 - mean_squared_error: 0.54 - 0s 183us/step - loss: 0.1218 - mean_squared_error: 0.8644\n",
      "Epoch 26/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1877 - mean_squared_error: 0.96 - 0s 160us/step - loss: 0.1207 - mean_squared_error: 0.8564\n",
      "Epoch 27/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1035 - mean_squared_error: 0.80 - 0s 145us/step - loss: 0.1196 - mean_squared_error: 0.8476\n",
      "Epoch 28/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1396 - mean_squared_error: 0.78 - 0s 101us/step - loss: 0.1183 - mean_squared_error: 0.8379\n",
      "Epoch 29/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0730 - mean_squared_error: 0.46 - 0s 181us/step - loss: 0.1172 - mean_squared_error: 0.8286\n",
      "Epoch 30/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.2055 - mean_squared_error: 1.03 - 0s 107us/step - loss: 0.1162 - mean_squared_error: 0.8207\n",
      "Epoch 31/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1675 - mean_squared_error: 1.03 - 0s 182us/step - loss: 0.1152 - mean_squared_error: 0.8126\n",
      "Epoch 32/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1300 - mean_squared_error: 0.85 - 0s 104us/step - loss: 0.1142 - mean_squared_error: 0.8052\n",
      "Epoch 33/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1117 - mean_squared_error: 0.75 - 0s 165us/step - loss: 0.1133 - mean_squared_error: 0.7973\n",
      "Epoch 34/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0996 - mean_squared_error: 0.54 - 0s 169us/step - loss: 0.1124 - mean_squared_error: 0.7893\n",
      "Epoch 35/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1278 - mean_squared_error: 0.81 - 0s 179us/step - loss: 0.1116 - mean_squared_error: 0.7824\n",
      "Epoch 36/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1606 - mean_squared_error: 0.95 - 0s 155us/step - loss: 0.1106 - mean_squared_error: 0.7742\n",
      "Epoch 37/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0989 - mean_squared_error: 0.72 - 0s 103us/step - loss: 0.1096 - mean_squared_error: 0.7662\n",
      "Epoch 38/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0945 - mean_squared_error: 0.82 - 0s 149us/step - loss: 0.1085 - mean_squared_error: 0.7579\n",
      "Epoch 39/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1103 - mean_squared_error: 0.83 - 0s 147us/step - loss: 0.1076 - mean_squared_error: 0.7507\n",
      "Epoch 40/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1005 - mean_squared_error: 0.61 - 0s 180us/step - loss: 0.1067 - mean_squared_error: 0.7425\n",
      "Epoch 41/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1602 - mean_squared_error: 0.75 - 0s 165us/step - loss: 0.1056 - mean_squared_error: 0.7337\n",
      "Epoch 42/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1598 - mean_squared_error: 0.89 - 0s 154us/step - loss: 0.1045 - mean_squared_error: 0.7257\n",
      "Epoch 43/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0669 - mean_squared_error: 0.55 - 0s 143us/step - loss: 0.1037 - mean_squared_error: 0.7188\n",
      "Epoch 44/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1228 - mean_squared_error: 0.63 - 0s 133us/step - loss: 0.1027 - mean_squared_error: 0.7106\n",
      "Epoch 45/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0930 - mean_squared_error: 0.66 - 0s 128us/step - loss: 0.1017 - mean_squared_error: 0.7041\n",
      "Epoch 46/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0881 - mean_squared_error: 0.66 - 0s 150us/step - loss: 0.1008 - mean_squared_error: 0.6973\n",
      "Epoch 47/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1249 - mean_squared_error: 0.80 - 0s 146us/step - loss: 0.1000 - mean_squared_error: 0.6911\n",
      "Epoch 48/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1541 - mean_squared_error: 0.85 - 0s 168us/step - loss: 0.0993 - mean_squared_error: 0.6840\n",
      "Epoch 49/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0909 - mean_squared_error: 0.56 - 0s 163us/step - loss: 0.0983 - mean_squared_error: 0.6771\n",
      "Epoch 50/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0640 - mean_squared_error: 0.42 - 0s 145us/step - loss: 0.0976 - mean_squared_error: 0.6714\n",
      "Epoch 51/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1016 - mean_squared_error: 0.51 - 0s 130us/step - loss: 0.0969 - mean_squared_error: 0.6661\n",
      "Epoch 52/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1316 - mean_squared_error: 0.84 - 0s 115us/step - loss: 0.0962 - mean_squared_error: 0.6602\n",
      "Epoch 53/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0470 - mean_squared_error: 0.53 - 0s 104us/step - loss: 0.0955 - mean_squared_error: 0.6557\n",
      "Epoch 54/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1015 - mean_squared_error: 0.95 - 0s 118us/step - loss: 0.0950 - mean_squared_error: 0.6509\n",
      "Epoch 55/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1292 - mean_squared_error: 0.60 - 0s 102us/step - loss: 0.0943 - mean_squared_error: 0.6454\n",
      "Epoch 56/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0807 - mean_squared_error: 0.49 - 0s 100us/step - loss: 0.0939 - mean_squared_error: 0.6411\n",
      "Epoch 57/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0803 - mean_squared_error: 0.52 - 0s 99us/step - loss: 0.0933 - mean_squared_error: 0.6371\n",
      "Epoch 58/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1189 - mean_squared_error: 0.80 - 0s 101us/step - loss: 0.0929 - mean_squared_error: 0.6332\n",
      "Epoch 59/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1451 - mean_squared_error: 0.71 - 0s 97us/step - loss: 0.0925 - mean_squared_error: 0.6289\n",
      "Epoch 60/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1369 - mean_squared_error: 0.65 - 0s 100us/step - loss: 0.0921 - mean_squared_error: 0.6253\n",
      "Epoch 61/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0865 - mean_squared_error: 0.52 - 0s 95us/step - loss: 0.0917 - mean_squared_error: 0.6218\n",
      "Epoch 62/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1116 - mean_squared_error: 0.58 - 0s 117us/step - loss: 0.0913 - mean_squared_error: 0.6179\n",
      "Epoch 63/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1595 - mean_squared_error: 0.75 - 0s 103us/step - loss: 0.0910 - mean_squared_error: 0.6148\n",
      "Epoch 64/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0980 - mean_squared_error: 0.46 - 0s 102us/step - loss: 0.0907 - mean_squared_error: 0.6122\n",
      "Epoch 65/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1523 - mean_squared_error: 0.63 - 0s 115us/step - loss: 0.0904 - mean_squared_error: 0.6094\n",
      "Epoch 66/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1289 - mean_squared_error: 0.79 - 0s 97us/step - loss: 0.0901 - mean_squared_error: 0.6071\n",
      "Epoch 67/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0787 - mean_squared_error: 0.56 - 0s 100us/step - loss: 0.0898 - mean_squared_error: 0.6041\n",
      "Epoch 68/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0385 - mean_squared_error: 0.42 - 0s 101us/step - loss: 0.0894 - mean_squared_error: 0.6016\n",
      "Epoch 69/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0928 - mean_squared_error: 0.59 - 0s 118us/step - loss: 0.0892 - mean_squared_error: 0.5992\n",
      "Epoch 70/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1589 - mean_squared_error: 0.81 - 0s 94us/step - loss: 0.0889 - mean_squared_error: 0.5967\n",
      "Epoch 71/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1217 - mean_squared_error: 0.69 - 0s 99us/step - loss: 0.0887 - mean_squared_error: 0.5949\n",
      "Epoch 72/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1022 - mean_squared_error: 0.46 - 0s 100us/step - loss: 0.0884 - mean_squared_error: 0.5919\n",
      "Epoch 73/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0733 - mean_squared_error: 0.51 - 0s 95us/step - loss: 0.0882 - mean_squared_error: 0.5905\n",
      "Epoch 74/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0809 - mean_squared_error: 0.53 - 0s 96us/step - loss: 0.0880 - mean_squared_error: 0.5888\n",
      "Epoch 75/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0397 - mean_squared_error: 0.37 - 0s 98us/step - loss: 0.0878 - mean_squared_error: 0.5869\n",
      "Epoch 76/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1180 - mean_squared_error: 0.73 - 0s 97us/step - loss: 0.0876 - mean_squared_error: 0.5852\n",
      "Epoch 77/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1160 - mean_squared_error: 0.75 - 0s 97us/step - loss: 0.0874 - mean_squared_error: 0.5838\n",
      "Epoch 78/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0838 - mean_squared_error: 0.57 - 0s 112us/step - loss: 0.0873 - mean_squared_error: 0.5822\n",
      "Epoch 79/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0786 - mean_squared_error: 0.52 - 0s 108us/step - loss: 0.0871 - mean_squared_error: 0.5808\n",
      "Epoch 80/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1044 - mean_squared_error: 0.60 - 0s 109us/step - loss: 0.0870 - mean_squared_error: 0.5797\n",
      "Epoch 81/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0872 - mean_squared_error: 0.56 - 0s 116us/step - loss: 0.0868 - mean_squared_error: 0.5781\n",
      "Epoch 82/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0721 - mean_squared_error: 0.64 - 0s 143us/step - loss: 0.0867 - mean_squared_error: 0.5771\n",
      "Epoch 83/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0819 - mean_squared_error: 0.67 - 0s 124us/step - loss: 0.0866 - mean_squared_error: 0.5757\n",
      "Epoch 84/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0912 - mean_squared_error: 0.52 - 0s 149us/step - loss: 0.0865 - mean_squared_error: 0.5743\n",
      "Epoch 85/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1158 - mean_squared_error: 0.86 - 0s 119us/step - loss: 0.0863 - mean_squared_error: 0.5731\n",
      "Epoch 86/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0447 - mean_squared_error: 0.53 - 0s 117us/step - loss: 0.0862 - mean_squared_error: 0.5720\n",
      "Epoch 87/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1080 - mean_squared_error: 0.65 - 0s 130us/step - loss: 0.0861 - mean_squared_error: 0.5712\n",
      "Epoch 88/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0603 - mean_squared_error: 0.43 - 0s 117us/step - loss: 0.0860 - mean_squared_error: 0.5700\n",
      "Epoch 89/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0744 - mean_squared_error: 0.60 - 0s 160us/step - loss: 0.0859 - mean_squared_error: 0.5691\n",
      "Epoch 90/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0540 - mean_squared_error: 0.50 - 0s 113us/step - loss: 0.0858 - mean_squared_error: 0.5684\n",
      "Epoch 91/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0494 - mean_squared_error: 0.57 - 0s 117us/step - loss: 0.0857 - mean_squared_error: 0.5676\n",
      "Epoch 92/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0450 - mean_squared_error: 0.38 - 0s 144us/step - loss: 0.0857 - mean_squared_error: 0.5670\n",
      "Epoch 93/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0645 - mean_squared_error: 0.44 - 0s 118us/step - loss: 0.0856 - mean_squared_error: 0.5665\n",
      "Epoch 94/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0705 - mean_squared_error: 0.55 - 0s 137us/step - loss: 0.0855 - mean_squared_error: 0.5655\n",
      "Epoch 95/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0563 - mean_squared_error: 0.52 - 0s 127us/step - loss: 0.0854 - mean_squared_error: 0.5646\n",
      "Epoch 96/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1010 - mean_squared_error: 0.59 - 0s 112us/step - loss: 0.0853 - mean_squared_error: 0.5636\n",
      "Epoch 97/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0605 - mean_squared_error: 0.50 - 0s 104us/step - loss: 0.0852 - mean_squared_error: 0.5632\n",
      "Epoch 98/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0841 - mean_squared_error: 0.60 - 0s 105us/step - loss: 0.0851 - mean_squared_error: 0.5625\n",
      "Epoch 99/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - ETA: 0s - loss: 0.1378 - mean_squared_error: 0.71 - 0s 101us/step - loss: 0.0850 - mean_squared_error: 0.5621\n",
      "Epoch 100/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1041 - mean_squared_error: 0.74 - 0s 95us/step - loss: 0.0850 - mean_squared_error: 0.5616\n",
      "Epoch 101/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0733 - mean_squared_error: 0.53 - 0s 99us/step - loss: 0.0849 - mean_squared_error: 0.5611\n",
      "Epoch 102/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0376 - mean_squared_error: 0.44 - 0s 101us/step - loss: 0.0848 - mean_squared_error: 0.5605\n",
      "Epoch 103/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1014 - mean_squared_error: 0.53 - 0s 103us/step - loss: 0.0848 - mean_squared_error: 0.5600\n",
      "Epoch 104/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0523 - mean_squared_error: 0.45 - 0s 95us/step - loss: 0.0847 - mean_squared_error: 0.5594\n",
      "Epoch 105/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0795 - mean_squared_error: 0.63 - 0s 99us/step - loss: 0.0847 - mean_squared_error: 0.5591\n",
      "Epoch 106/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1355 - mean_squared_error: 0.70 - 0s 116us/step - loss: 0.0846 - mean_squared_error: 0.5588\n",
      "Epoch 107/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1136 - mean_squared_error: 0.68 - 0s 100us/step - loss: 0.0846 - mean_squared_error: 0.5586\n",
      "Epoch 108/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0979 - mean_squared_error: 0.63 - 0s 99us/step - loss: 0.0845 - mean_squared_error: 0.5578\n",
      "Epoch 109/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0752 - mean_squared_error: 0.68 - 0s 110us/step - loss: 0.0845 - mean_squared_error: 0.5576\n",
      "Epoch 110/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0771 - mean_squared_error: 0.44 - 0s 95us/step - loss: 0.0844 - mean_squared_error: 0.5573\n",
      "Epoch 111/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0909 - mean_squared_error: 0.61 - 0s 103us/step - loss: 0.0844 - mean_squared_error: 0.5567\n",
      "Epoch 112/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1071 - mean_squared_error: 0.57 - 0s 93us/step - loss: 0.0843 - mean_squared_error: 0.5561\n",
      "Epoch 113/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0515 - mean_squared_error: 0.40 - 0s 100us/step - loss: 0.0842 - mean_squared_error: 0.5557\n",
      "Epoch 114/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0839 - mean_squared_error: 0.62 - 0s 97us/step - loss: 0.0841 - mean_squared_error: 0.5551\n",
      "Epoch 115/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0637 - mean_squared_error: 0.39 - 0s 94us/step - loss: 0.0840 - mean_squared_error: 0.5548\n",
      "Epoch 116/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0577 - mean_squared_error: 0.39 - 0s 96us/step - loss: 0.0839 - mean_squared_error: 0.5541\n",
      "Epoch 117/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0815 - mean_squared_error: 0.59 - 0s 97us/step - loss: 0.0837 - mean_squared_error: 0.5535\n",
      "Epoch 118/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1032 - mean_squared_error: 0.50 - 0s 94us/step - loss: 0.0837 - mean_squared_error: 0.5530\n",
      "Epoch 119/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0312 - mean_squared_error: 0.38 - 0s 105us/step - loss: 0.0836 - mean_squared_error: 0.5525\n",
      "Epoch 120/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0812 - mean_squared_error: 0.62 - 0s 99us/step - loss: 0.0834 - mean_squared_error: 0.5519\n",
      "Epoch 121/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0859 - mean_squared_error: 0.50 - 0s 103us/step - loss: 0.0834 - mean_squared_error: 0.5513\n",
      "Epoch 122/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0858 - mean_squared_error: 0.52 - 0s 99us/step - loss: 0.0833 - mean_squared_error: 0.5506\n",
      "Epoch 123/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1292 - mean_squared_error: 0.88 - 0s 93us/step - loss: 0.0832 - mean_squared_error: 0.5505\n",
      "Epoch 124/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0413 - mean_squared_error: 0.47 - 0s 99us/step - loss: 0.0831 - mean_squared_error: 0.5499\n",
      "Epoch 125/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0632 - mean_squared_error: 0.35 - 0s 109us/step - loss: 0.0830 - mean_squared_error: 0.5494\n",
      "Epoch 126/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0472 - mean_squared_error: 0.35 - 0s 103us/step - loss: 0.0830 - mean_squared_error: 0.5489\n",
      "Epoch 127/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0936 - mean_squared_error: 0.57 - 0s 94us/step - loss: 0.0829 - mean_squared_error: 0.5485\n",
      "Epoch 128/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0902 - mean_squared_error: 0.60 - 0s 97us/step - loss: 0.0829 - mean_squared_error: 0.5482\n",
      "Epoch 129/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1008 - mean_squared_error: 0.63 - 0s 101us/step - loss: 0.0827 - mean_squared_error: 0.5475\n",
      "Epoch 130/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0870 - mean_squared_error: 0.43 - 0s 105us/step - loss: 0.0827 - mean_squared_error: 0.5473\n",
      "Epoch 131/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0698 - mean_squared_error: 0.52 - 0s 99us/step - loss: 0.0827 - mean_squared_error: 0.5470\n",
      "Epoch 132/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0472 - mean_squared_error: 0.50 - 0s 98us/step - loss: 0.0826 - mean_squared_error: 0.5466\n",
      "Epoch 133/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1200 - mean_squared_error: 0.66 - 0s 111us/step - loss: 0.0826 - mean_squared_error: 0.5466\n",
      "Epoch 134/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0400 - mean_squared_error: 0.44 - 0s 117us/step - loss: 0.0825 - mean_squared_error: 0.5461\n",
      "Epoch 135/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0478 - mean_squared_error: 0.44 - 0s 99us/step - loss: 0.0825 - mean_squared_error: 0.5457\n",
      "Epoch 136/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0884 - mean_squared_error: 0.59 - 0s 97us/step - loss: 0.0824 - mean_squared_error: 0.5458\n",
      "Epoch 137/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1082 - mean_squared_error: 0.56 - 0s 99us/step - loss: 0.0824 - mean_squared_error: 0.5456\n",
      "Epoch 138/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0603 - mean_squared_error: 0.61 - 0s 95us/step - loss: 0.0823 - mean_squared_error: 0.5451\n",
      "Epoch 139/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1005 - mean_squared_error: 0.59 - 0s 98us/step - loss: 0.0823 - mean_squared_error: 0.5451\n",
      "Epoch 140/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0692 - mean_squared_error: 0.41 - 0s 97us/step - loss: 0.0823 - mean_squared_error: 0.5448\n",
      "Epoch 141/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1134 - mean_squared_error: 0.60 - 0s 94us/step - loss: 0.0823 - mean_squared_error: 0.5444\n",
      "Epoch 142/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0800 - mean_squared_error: 0.54 - 0s 101us/step - loss: 0.0822 - mean_squared_error: 0.5442\n",
      "Epoch 143/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0576 - mean_squared_error: 0.40 - 0s 96us/step - loss: 0.0822 - mean_squared_error: 0.5440\n",
      "Epoch 144/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1224 - mean_squared_error: 0.57 - 0s 103us/step - loss: 0.0821 - mean_squared_error: 0.5438\n",
      "Epoch 145/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0848 - mean_squared_error: 0.50 - 0s 91us/step - loss: 0.0821 - mean_squared_error: 0.5435\n",
      "Epoch 146/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0558 - mean_squared_error: 0.43 - 0s 118us/step - loss: 0.0821 - mean_squared_error: 0.5433\n",
      "Epoch 147/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0866 - mean_squared_error: 0.55 - 0s 100us/step - loss: 0.0820 - mean_squared_error: 0.5432\n",
      "Epoch 148/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0442 - mean_squared_error: 0.33 - 0s 101us/step - loss: 0.0820 - mean_squared_error: 0.5429\n",
      "Epoch 149/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0744 - mean_squared_error: 0.54 - 0s 98us/step - loss: 0.0820 - mean_squared_error: 0.5427\n",
      "Epoch 150/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0813 - mean_squared_error: 0.63 - 0s 99us/step - loss: 0.0819 - mean_squared_error: 0.5424\n",
      "Epoch 151/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1693 - mean_squared_error: 0.87 - 0s 95us/step - loss: 0.0819 - mean_squared_error: 0.5424\n",
      "Epoch 152/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0536 - mean_squared_error: 0.36 - 0s 96us/step - loss: 0.0819 - mean_squared_error: 0.5418\n",
      "Epoch 153/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1064 - mean_squared_error: 0.58 - 0s 95us/step - loss: 0.0819 - mean_squared_error: 0.5418\n",
      "Epoch 154/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0702 - mean_squared_error: 0.43 - 0s 93us/step - loss: 0.0819 - mean_squared_error: 0.5415\n",
      "Epoch 155/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0839 - mean_squared_error: 0.57 - 0s 114us/step - loss: 0.0819 - mean_squared_error: 0.5415\n",
      "Epoch 156/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1048 - mean_squared_error: 0.65 - 0s 90us/step - loss: 0.0818 - mean_squared_error: 0.5415\n",
      "Epoch 157/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0982 - mean_squared_error: 0.52 - 0s 117us/step - loss: 0.0818 - mean_squared_error: 0.5412\n",
      "Epoch 158/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0612 - mean_squared_error: 0.38 - 0s 95us/step - loss: 0.0817 - mean_squared_error: 0.5411\n",
      "Epoch 159/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0847 - mean_squared_error: 0.40 - 0s 101us/step - loss: 0.0817 - mean_squared_error: 0.5409\n",
      "Epoch 160/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0391 - mean_squared_error: 0.37 - 0s 112us/step - loss: 0.0817 - mean_squared_error: 0.5406\n",
      "Epoch 161/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0841 - mean_squared_error: 0.61 - 0s 99us/step - loss: 0.0816 - mean_squared_error: 0.5401\n",
      "Epoch 162/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0647 - mean_squared_error: 0.41 - 0s 125us/step - loss: 0.0816 - mean_squared_error: 0.5401\n",
      "Epoch 163/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1028 - mean_squared_error: 0.65 - 0s 95us/step - loss: 0.0816 - mean_squared_error: 0.5402\n",
      "Epoch 164/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0894 - mean_squared_error: 0.50 - 0s 96us/step - loss: 0.0816 - mean_squared_error: 0.5398\n",
      "Epoch 165/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0946 - mean_squared_error: 0.71 - 0s 95us/step - loss: 0.0815 - mean_squared_error: 0.5393\n",
      "Epoch 166/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1093 - mean_squared_error: 0.68 - 0s 106us/step - loss: 0.0816 - mean_squared_error: 0.5392\n",
      "Epoch 167/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0522 - mean_squared_error: 0.38 - 0s 104us/step - loss: 0.0816 - mean_squared_error: 0.5392\n",
      "Epoch 168/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0744 - mean_squared_error: 0.58 - 0s 95us/step - loss: 0.0815 - mean_squared_error: 0.5391\n",
      "Epoch 169/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1150 - mean_squared_error: 0.63 - 0s 115us/step - loss: 0.0815 - mean_squared_error: 0.5387\n",
      "Epoch 170/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1145 - mean_squared_error: 0.62 - 0s 109us/step - loss: 0.0814 - mean_squared_error: 0.5386\n",
      "Epoch 171/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1393 - mean_squared_error: 0.79 - 0s 118us/step - loss: 0.0814 - mean_squared_error: 0.5384\n",
      "Epoch 172/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0875 - mean_squared_error: 0.46 - 0s 124us/step - loss: 0.0814 - mean_squared_error: 0.5383\n",
      "Epoch 173/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1038 - mean_squared_error: 0.56 - 0s 97us/step - loss: 0.0814 - mean_squared_error: 0.5381\n",
      "Epoch 174/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0803 - mean_squared_error: 0.56 - 0s 95us/step - loss: 0.0814 - mean_squared_error: 0.5379\n",
      "Epoch 175/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0821 - mean_squared_error: 0.50 - 0s 96us/step - loss: 0.0814 - mean_squared_error: 0.5377\n",
      "Epoch 176/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0893 - mean_squared_error: 0.64 - 0s 101us/step - loss: 0.0813 - mean_squared_error: 0.5374\n",
      "Epoch 177/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0706 - mean_squared_error: 0.55 - 0s 103us/step - loss: 0.0813 - mean_squared_error: 0.5371\n",
      "Epoch 178/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1293 - mean_squared_error: 0.74 - 0s 97us/step - loss: 0.0813 - mean_squared_error: 0.5369\n",
      "Epoch 179/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0448 - mean_squared_error: 0.47 - 0s 111us/step - loss: 0.0813 - mean_squared_error: 0.5367\n",
      "Epoch 180/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1171 - mean_squared_error: 0.56 - 0s 97us/step - loss: 0.0812 - mean_squared_error: 0.5367\n",
      "Epoch 181/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1062 - mean_squared_error: 0.57 - 0s 94us/step - loss: 0.0812 - mean_squared_error: 0.5366\n",
      "Epoch 182/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0569 - mean_squared_error: 0.50 - 0s 107us/step - loss: 0.0812 - mean_squared_error: 0.5363\n",
      "Epoch 183/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0839 - mean_squared_error: 0.51 - 0s 130us/step - loss: 0.0812 - mean_squared_error: 0.5361\n",
      "Epoch 184/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0536 - mean_squared_error: 0.37 - 0s 103us/step - loss: 0.0812 - mean_squared_error: 0.5360\n",
      "Epoch 185/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0566 - mean_squared_error: 0.42 - 0s 104us/step - loss: 0.0812 - mean_squared_error: 0.5359\n",
      "Epoch 186/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1479 - mean_squared_error: 0.83 - 0s 98us/step - loss: 0.0812 - mean_squared_error: 0.5361\n",
      "Epoch 187/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0453 - mean_squared_error: 0.36 - 0s 92us/step - loss: 0.0811 - mean_squared_error: 0.5357\n",
      "Epoch 188/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0762 - mean_squared_error: 0.50 - 0s 97us/step - loss: 0.0811 - mean_squared_error: 0.5358\n",
      "Epoch 189/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0955 - mean_squared_error: 0.49 - 0s 99us/step - loss: 0.0811 - mean_squared_error: 0.5356\n",
      "Epoch 190/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0584 - mean_squared_error: 0.52 - 0s 111us/step - loss: 0.0811 - mean_squared_error: 0.5350\n",
      "Epoch 191/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0790 - mean_squared_error: 0.55 - 0s 115us/step - loss: 0.0811 - mean_squared_error: 0.5346\n",
      "Epoch 192/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0475 - mean_squared_error: 0.48 - 0s 120us/step - loss: 0.0810 - mean_squared_error: 0.5346\n",
      "Epoch 193/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0492 - mean_squared_error: 0.44 - 0s 96us/step - loss: 0.0810 - mean_squared_error: 0.5342\n",
      "Epoch 194/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0584 - mean_squared_error: 0.36 - 0s 99us/step - loss: 0.0811 - mean_squared_error: 0.5340\n",
      "Epoch 195/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0974 - mean_squared_error: 0.64 - 0s 100us/step - loss: 0.0810 - mean_squared_error: 0.5342\n",
      "Epoch 196/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1122 - mean_squared_error: 0.63 - 0s 113us/step - loss: 0.0810 - mean_squared_error: 0.5340\n",
      "Epoch 197/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - ETA: 0s - loss: 0.0612 - mean_squared_error: 0.44 - 0s 105us/step - loss: 0.0809 - mean_squared_error: 0.5337\n",
      "Epoch 198/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0566 - mean_squared_error: 0.48 - 0s 94us/step - loss: 0.0809 - mean_squared_error: 0.5335\n",
      "Epoch 199/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0844 - mean_squared_error: 0.58 - 0s 92us/step - loss: 0.0809 - mean_squared_error: 0.5334\n",
      "Epoch 200/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0338 - mean_squared_error: 0.48 - 0s 98us/step - loss: 0.0809 - mean_squared_error: 0.5333\n",
      "Epoch 201/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0800 - mean_squared_error: 0.48 - 0s 99us/step - loss: 0.0809 - mean_squared_error: 0.5331\n",
      "Epoch 202/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0828 - mean_squared_error: 0.63 - 0s 120us/step - loss: 0.0809 - mean_squared_error: 0.5330\n",
      "Epoch 203/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0453 - mean_squared_error: 0.41 - 0s 96us/step - loss: 0.0809 - mean_squared_error: 0.5327\n",
      "Epoch 204/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0757 - mean_squared_error: 0.55 - 0s 90us/step - loss: 0.0809 - mean_squared_error: 0.5328\n",
      "Epoch 205/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0538 - mean_squared_error: 0.38 - 0s 94us/step - loss: 0.0808 - mean_squared_error: 0.5331\n",
      "Epoch 206/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0546 - mean_squared_error: 0.31 - 0s 102us/step - loss: 0.0808 - mean_squared_error: 0.5331\n",
      "Epoch 207/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0453 - mean_squared_error: 0.43 - 0s 97us/step - loss: 0.0808 - mean_squared_error: 0.5329\n",
      "Epoch 208/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0531 - mean_squared_error: 0.52 - 0s 100us/step - loss: 0.0808 - mean_squared_error: 0.5327\n",
      "Epoch 209/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0791 - mean_squared_error: 0.56 - 0s 105us/step - loss: 0.0808 - mean_squared_error: 0.5325\n",
      "Epoch 210/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0752 - mean_squared_error: 0.50 - 0s 104us/step - loss: 0.0808 - mean_squared_error: 0.5322\n",
      "Epoch 211/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0917 - mean_squared_error: 0.50 - 0s 109us/step - loss: 0.0807 - mean_squared_error: 0.5319\n",
      "Epoch 212/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0570 - mean_squared_error: 0.46 - 0s 133us/step - loss: 0.0807 - mean_squared_error: 0.5319\n",
      "Epoch 213/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0862 - mean_squared_error: 0.65 - 0s 160us/step - loss: 0.0807 - mean_squared_error: 0.5318\n",
      "Epoch 214/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0734 - mean_squared_error: 0.60 - 0s 99us/step - loss: 0.0807 - mean_squared_error: 0.5318\n",
      "Epoch 215/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1053 - mean_squared_error: 0.53 - 0s 93us/step - loss: 0.0807 - mean_squared_error: 0.5315\n",
      "Epoch 216/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1079 - mean_squared_error: 0.71 - 0s 98us/step - loss: 0.0807 - mean_squared_error: 0.5312\n",
      "Epoch 217/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0921 - mean_squared_error: 0.67 - 0s 96us/step - loss: 0.0807 - mean_squared_error: 0.5310\n",
      "Epoch 218/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0992 - mean_squared_error: 0.59 - 0s 94us/step - loss: 0.0806 - mean_squared_error: 0.5309\n",
      "Epoch 219/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0906 - mean_squared_error: 0.57 - 0s 98us/step - loss: 0.0806 - mean_squared_error: 0.5305\n",
      "Epoch 220/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0889 - mean_squared_error: 0.56 - 0s 96us/step - loss: 0.0806 - mean_squared_error: 0.5308\n",
      "Epoch 221/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0642 - mean_squared_error: 0.51 - 0s 96us/step - loss: 0.0806 - mean_squared_error: 0.5304\n",
      "Epoch 222/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0573 - mean_squared_error: 0.44 - 0s 108us/step - loss: 0.0806 - mean_squared_error: 0.5303\n",
      "Epoch 223/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0897 - mean_squared_error: 0.60 - 0s 118us/step - loss: 0.0806 - mean_squared_error: 0.5303\n",
      "Epoch 224/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1109 - mean_squared_error: 0.55 - 0s 106us/step - loss: 0.0805 - mean_squared_error: 0.5302\n",
      "Epoch 225/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0965 - mean_squared_error: 0.65 - 0s 108us/step - loss: 0.0805 - mean_squared_error: 0.5304\n",
      "Epoch 226/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1009 - mean_squared_error: 0.55 - 0s 99us/step - loss: 0.0806 - mean_squared_error: 0.5301\n",
      "Epoch 227/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0722 - mean_squared_error: 0.45 - 0s 97us/step - loss: 0.0806 - mean_squared_error: 0.5306\n",
      "Epoch 228/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0519 - mean_squared_error: 0.42 - 0s 96us/step - loss: 0.0805 - mean_squared_error: 0.5300\n",
      "Epoch 229/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0763 - mean_squared_error: 0.50 - 0s 99us/step - loss: 0.0805 - mean_squared_error: 0.5299\n",
      "Epoch 230/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0871 - mean_squared_error: 0.54 - 0s 99us/step - loss: 0.0805 - mean_squared_error: 0.5295\n",
      "Epoch 231/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0853 - mean_squared_error: 0.66 - 0s 92us/step - loss: 0.0805 - mean_squared_error: 0.5296\n",
      "Epoch 232/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0883 - mean_squared_error: 0.60 - 0s 95us/step - loss: 0.0805 - mean_squared_error: 0.5294\n",
      "Epoch 233/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0729 - mean_squared_error: 0.52 - 0s 118us/step - loss: 0.0804 - mean_squared_error: 0.5289\n",
      "Epoch 234/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0635 - mean_squared_error: 0.55 - 0s 92us/step - loss: 0.0804 - mean_squared_error: 0.5290\n",
      "Epoch 235/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0755 - mean_squared_error: 0.42 - 0s 98us/step - loss: 0.0805 - mean_squared_error: 0.5295\n",
      "Epoch 236/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1385 - mean_squared_error: 0.63 - 0s 94us/step - loss: 0.0804 - mean_squared_error: 0.5289\n",
      "Epoch 237/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0765 - mean_squared_error: 0.42 - 0s 95us/step - loss: 0.0804 - mean_squared_error: 0.5286\n",
      "Epoch 238/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0824 - mean_squared_error: 0.52 - 0s 97us/step - loss: 0.0804 - mean_squared_error: 0.5286\n",
      "Epoch 239/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0993 - mean_squared_error: 0.70 - 0s 99us/step - loss: 0.0804 - mean_squared_error: 0.5284\n",
      "Epoch 240/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0658 - mean_squared_error: 0.37 - 0s 97us/step - loss: 0.0803 - mean_squared_error: 0.5282\n",
      "Epoch 241/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0752 - mean_squared_error: 0.49 - 0s 109us/step - loss: 0.0803 - mean_squared_error: 0.5279\n",
      "Epoch 242/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0642 - mean_squared_error: 0.38 - 0s 101us/step - loss: 0.0804 - mean_squared_error: 0.5277\n",
      "Epoch 243/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1114 - mean_squared_error: 0.60 - 0s 103us/step - loss: 0.0804 - mean_squared_error: 0.5279\n",
      "Epoch 244/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0570 - mean_squared_error: 0.42 - 0s 94us/step - loss: 0.0803 - mean_squared_error: 0.5276\n",
      "Epoch 245/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1058 - mean_squared_error: 0.51 - 0s 106us/step - loss: 0.0803 - mean_squared_error: 0.5275\n",
      "Epoch 246/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0983 - mean_squared_error: 0.53 - 0s 109us/step - loss: 0.0803 - mean_squared_error: 0.5274\n",
      "Epoch 247/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0797 - mean_squared_error: 0.44 - 0s 101us/step - loss: 0.0803 - mean_squared_error: 0.5270\n",
      "Epoch 248/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0251 - mean_squared_error: 0.51 - 0s 109us/step - loss: 0.0802 - mean_squared_error: 0.5270\n",
      "Epoch 249/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1705 - mean_squared_error: 0.80 - 0s 102us/step - loss: 0.0802 - mean_squared_error: 0.5269\n",
      "Epoch 250/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1124 - mean_squared_error: 0.65 - 0s 107us/step - loss: 0.0802 - mean_squared_error: 0.5268\n",
      "Epoch 251/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0764 - mean_squared_error: 0.48 - 0s 95us/step - loss: 0.0802 - mean_squared_error: 0.5269\n",
      "Epoch 252/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0626 - mean_squared_error: 0.45 - 0s 95us/step - loss: 0.0802 - mean_squared_error: 0.5268\n",
      "Epoch 253/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0792 - mean_squared_error: 0.49 - 0s 93us/step - loss: 0.0802 - mean_squared_error: 0.5265\n",
      "Epoch 254/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0711 - mean_squared_error: 0.57 - 0s 104us/step - loss: 0.0802 - mean_squared_error: 0.5264\n",
      "Epoch 255/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1009 - mean_squared_error: 0.65 - 0s 101us/step - loss: 0.0801 - mean_squared_error: 0.5264\n",
      "Epoch 256/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0831 - mean_squared_error: 0.48 - 0s 97us/step - loss: 0.0801 - mean_squared_error: 0.5265\n",
      "Epoch 257/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0897 - mean_squared_error: 0.49 - 0s 102us/step - loss: 0.0802 - mean_squared_error: 0.5264\n",
      "Epoch 258/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0527 - mean_squared_error: 0.36 - 0s 97us/step - loss: 0.0801 - mean_squared_error: 0.5261\n",
      "Epoch 259/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0619 - mean_squared_error: 0.58 - 0s 92us/step - loss: 0.0801 - mean_squared_error: 0.5261\n",
      "Epoch 260/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1106 - mean_squared_error: 0.51 - 0s 100us/step - loss: 0.0801 - mean_squared_error: 0.5259\n",
      "Epoch 261/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0668 - mean_squared_error: 0.38 - 0s 97us/step - loss: 0.0801 - mean_squared_error: 0.5259\n",
      "Epoch 262/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0846 - mean_squared_error: 0.51 - 0s 96us/step - loss: 0.0801 - mean_squared_error: 0.5258\n",
      "Epoch 263/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0602 - mean_squared_error: 0.44 - 0s 96us/step - loss: 0.0801 - mean_squared_error: 0.5256\n",
      "Epoch 264/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0716 - mean_squared_error: 0.49 - 0s 96us/step - loss: 0.0800 - mean_squared_error: 0.5255\n",
      "Epoch 265/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0748 - mean_squared_error: 0.55 - 0s 93us/step - loss: 0.0800 - mean_squared_error: 0.5253\n",
      "Epoch 266/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0801 - mean_squared_error: 0.45 - 0s 93us/step - loss: 0.0800 - mean_squared_error: 0.5253\n",
      "Epoch 267/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0782 - mean_squared_error: 0.59 - 0s 98us/step - loss: 0.0801 - mean_squared_error: 0.5252\n",
      "Epoch 268/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0956 - mean_squared_error: 0.57 - 0s 107us/step - loss: 0.0800 - mean_squared_error: 0.5247\n",
      "Epoch 269/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0804 - mean_squared_error: 0.55 - 0s 101us/step - loss: 0.0800 - mean_squared_error: 0.5244\n",
      "Epoch 270/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0950 - mean_squared_error: 0.61 - 0s 101us/step - loss: 0.0800 - mean_squared_error: 0.5244\n",
      "Epoch 271/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0761 - mean_squared_error: 0.41 - 0s 111us/step - loss: 0.0800 - mean_squared_error: 0.5244\n",
      "Epoch 272/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0547 - mean_squared_error: 0.40 - 0s 102us/step - loss: 0.0800 - mean_squared_error: 0.5245\n",
      "Epoch 273/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0794 - mean_squared_error: 0.44 - 0s 137us/step - loss: 0.0800 - mean_squared_error: 0.5245\n",
      "Epoch 274/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0497 - mean_squared_error: 0.47 - 0s 121us/step - loss: 0.0800 - mean_squared_error: 0.5243\n",
      "Epoch 275/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0740 - mean_squared_error: 0.54 - 0s 114us/step - loss: 0.0800 - mean_squared_error: 0.5243\n",
      "Epoch 276/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1027 - mean_squared_error: 0.63 - 0s 103us/step - loss: 0.0799 - mean_squared_error: 0.5239\n",
      "Epoch 277/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0556 - mean_squared_error: 0.46 - 0s 117us/step - loss: 0.0799 - mean_squared_error: 0.5237\n",
      "Epoch 278/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0946 - mean_squared_error: 0.60 - 0s 106us/step - loss: 0.0799 - mean_squared_error: 0.5236\n",
      "Epoch 279/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0673 - mean_squared_error: 0.59 - 0s 132us/step - loss: 0.0799 - mean_squared_error: 0.5237\n",
      "Epoch 280/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0509 - mean_squared_error: 0.43 - 0s 126us/step - loss: 0.0799 - mean_squared_error: 0.5235\n",
      "Epoch 281/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0772 - mean_squared_error: 0.57 - 0s 114us/step - loss: 0.0799 - mean_squared_error: 0.5234\n",
      "Epoch 282/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1148 - mean_squared_error: 0.64 - 0s 110us/step - loss: 0.0799 - mean_squared_error: 0.5235\n",
      "Epoch 283/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0534 - mean_squared_error: 0.52 - 0s 120us/step - loss: 0.0798 - mean_squared_error: 0.5233\n",
      "Epoch 284/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0751 - mean_squared_error: 0.52 - 0s 111us/step - loss: 0.0798 - mean_squared_error: 0.5234\n",
      "Epoch 285/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0927 - mean_squared_error: 0.52 - 0s 123us/step - loss: 0.0799 - mean_squared_error: 0.5235\n",
      "Epoch 286/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0295 - mean_squared_error: 0.39 - 0s 115us/step - loss: 0.0798 - mean_squared_error: 0.5232\n",
      "Epoch 287/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0590 - mean_squared_error: 0.32 - 0s 113us/step - loss: 0.0798 - mean_squared_error: 0.5233\n",
      "Epoch 288/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0304 - mean_squared_error: 0.41 - 0s 111us/step - loss: 0.0797 - mean_squared_error: 0.5234\n",
      "Epoch 289/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0780 - mean_squared_error: 0.63 - 0s 113us/step - loss: 0.0797 - mean_squared_error: 0.5238\n",
      "Epoch 290/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0539 - mean_squared_error: 0.56 - 0s 122us/step - loss: 0.0797 - mean_squared_error: 0.5236\n",
      "Epoch 291/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0648 - mean_squared_error: 0.43 - 0s 121us/step - loss: 0.0797 - mean_squared_error: 0.5236\n",
      "Epoch 292/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0788 - mean_squared_error: 0.68 - 0s 126us/step - loss: 0.0796 - mean_squared_error: 0.5235\n",
      "Epoch 293/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0510 - mean_squared_error: 0.53 - 0s 106us/step - loss: 0.0796 - mean_squared_error: 0.5232\n",
      "Epoch 294/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0486 - mean_squared_error: 0.44 - 0s 114us/step - loss: 0.0796 - mean_squared_error: 0.5233\n",
      "Epoch 295/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - ETA: 0s - loss: 0.1138 - mean_squared_error: 0.74 - 0s 113us/step - loss: 0.0795 - mean_squared_error: 0.5231\n",
      "Epoch 296/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0582 - mean_squared_error: 0.51 - 0s 111us/step - loss: 0.0795 - mean_squared_error: 0.5236\n",
      "Epoch 297/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0881 - mean_squared_error: 0.45 - 0s 122us/step - loss: 0.0794 - mean_squared_error: 0.5231\n",
      "Epoch 298/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0816 - mean_squared_error: 0.57 - 0s 162us/step - loss: 0.0794 - mean_squared_error: 0.5230\n",
      "Epoch 299/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0884 - mean_squared_error: 0.49 - 0s 139us/step - loss: 0.0793 - mean_squared_error: 0.5227\n",
      "Epoch 300/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0667 - mean_squared_error: 0.57 - 0s 145us/step - loss: 0.0792 - mean_squared_error: 0.5223\n",
      "Epoch 301/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0902 - mean_squared_error: 0.52 - 0s 143us/step - loss: 0.0791 - mean_squared_error: 0.5220\n",
      "Epoch 302/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1086 - mean_squared_error: 0.71 - 0s 133us/step - loss: 0.0791 - mean_squared_error: 0.5222\n",
      "Epoch 303/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0941 - mean_squared_error: 0.48 - 0s 161us/step - loss: 0.0790 - mean_squared_error: 0.5224\n",
      "Epoch 304/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0386 - mean_squared_error: 0.45 - 0s 218us/step - loss: 0.0790 - mean_squared_error: 0.5225\n",
      "Epoch 305/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0948 - mean_squared_error: 0.72 - 0s 156us/step - loss: 0.0790 - mean_squared_error: 0.5223\n",
      "Epoch 306/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0367 - mean_squared_error: 0.35 - 0s 159us/step - loss: 0.0789 - mean_squared_error: 0.5220\n",
      "Epoch 307/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0866 - mean_squared_error: 0.49 - 0s 141us/step - loss: 0.0789 - mean_squared_error: 0.5218\n",
      "Epoch 308/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0429 - mean_squared_error: 0.50 - 0s 136us/step - loss: 0.0789 - mean_squared_error: 0.5221\n",
      "Epoch 309/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0400 - mean_squared_error: 0.46 - 0s 129us/step - loss: 0.0789 - mean_squared_error: 0.5223\n",
      "Epoch 310/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0857 - mean_squared_error: 0.48 - 0s 118us/step - loss: 0.0788 - mean_squared_error: 0.5220\n",
      "Epoch 311/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0531 - mean_squared_error: 0.35 - 0s 144us/step - loss: 0.0788 - mean_squared_error: 0.5219\n",
      "Epoch 312/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0623 - mean_squared_error: 0.44 - 0s 122us/step - loss: 0.0788 - mean_squared_error: 0.5217\n",
      "Epoch 313/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0798 - mean_squared_error: 0.51 - 0s 99us/step - loss: 0.0787 - mean_squared_error: 0.5215\n",
      "Epoch 314/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0680 - mean_squared_error: 0.38 - 0s 120us/step - loss: 0.0787 - mean_squared_error: 0.5215\n",
      "Epoch 315/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0876 - mean_squared_error: 0.48 - 0s 109us/step - loss: 0.0786 - mean_squared_error: 0.5215\n",
      "Epoch 316/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0308 - mean_squared_error: 0.40 - 0s 108us/step - loss: 0.0786 - mean_squared_error: 0.5215\n",
      "Epoch 317/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0959 - mean_squared_error: 0.68 - 0s 140us/step - loss: 0.0785 - mean_squared_error: 0.5213\n",
      "Epoch 318/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0746 - mean_squared_error: 0.46 - 0s 125us/step - loss: 0.0785 - mean_squared_error: 0.5213\n",
      "Epoch 319/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1132 - mean_squared_error: 0.73 - 0s 110us/step - loss: 0.0784 - mean_squared_error: 0.5217\n",
      "Epoch 320/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0877 - mean_squared_error: 0.65 - 0s 113us/step - loss: 0.0784 - mean_squared_error: 0.5223\n",
      "Epoch 321/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0694 - mean_squared_error: 0.52 - 0s 109us/step - loss: 0.0783 - mean_squared_error: 0.5221\n",
      "Epoch 322/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1033 - mean_squared_error: 0.44 - 0s 107us/step - loss: 0.0783 - mean_squared_error: 0.5224\n",
      "Epoch 323/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0729 - mean_squared_error: 0.39 - 0s 110us/step - loss: 0.0782 - mean_squared_error: 0.5228\n",
      "Epoch 324/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0614 - mean_squared_error: 0.43 - 0s 118us/step - loss: 0.0782 - mean_squared_error: 0.5227\n",
      "Epoch 325/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0583 - mean_squared_error: 0.46 - 0s 120us/step - loss: 0.0781 - mean_squared_error: 0.5229\n",
      "Epoch 326/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0546 - mean_squared_error: 0.53 - 0s 114us/step - loss: 0.0782 - mean_squared_error: 0.5230\n",
      "Epoch 327/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0757 - mean_squared_error: 0.57 - 0s 119us/step - loss: 0.0781 - mean_squared_error: 0.5229\n",
      "Epoch 328/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0655 - mean_squared_error: 0.49 - 0s 108us/step - loss: 0.0781 - mean_squared_error: 0.5229\n",
      "Epoch 329/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0733 - mean_squared_error: 0.44 - 0s 118us/step - loss: 0.0781 - mean_squared_error: 0.5234\n",
      "Epoch 330/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0268 - mean_squared_error: 0.46 - 0s 106us/step - loss: 0.0780 - mean_squared_error: 0.5239\n",
      "Epoch 331/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0594 - mean_squared_error: 0.48 - 0s 108us/step - loss: 0.0780 - mean_squared_error: 0.5244\n",
      "Epoch 332/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0807 - mean_squared_error: 0.48 - 0s 122us/step - loss: 0.0780 - mean_squared_error: 0.5251\n",
      "Epoch 333/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1024 - mean_squared_error: 0.57 - 0s 115us/step - loss: 0.0780 - mean_squared_error: 0.5252\n",
      "Epoch 334/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0294 - mean_squared_error: 0.34 - 0s 113us/step - loss: 0.0779 - mean_squared_error: 0.5247\n",
      "Epoch 335/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0594 - mean_squared_error: 0.54 - 0s 112us/step - loss: 0.0780 - mean_squared_error: 0.5250\n",
      "Epoch 336/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1109 - mean_squared_error: 0.54 - 0s 126us/step - loss: 0.0779 - mean_squared_error: 0.5250\n",
      "Epoch 337/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0864 - mean_squared_error: 0.43 - 0s 94us/step - loss: 0.0779 - mean_squared_error: 0.5254\n",
      "Epoch 338/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0761 - mean_squared_error: 0.45 - 0s 91us/step - loss: 0.0779 - mean_squared_error: 0.5253\n",
      "Epoch 339/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1310 - mean_squared_error: 0.66 - 0s 100us/step - loss: 0.0779 - mean_squared_error: 0.5257\n",
      "Epoch 340/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0412 - mean_squared_error: 0.42 - 0s 98us/step - loss: 0.0778 - mean_squared_error: 0.5259\n",
      "Epoch 341/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0656 - mean_squared_error: 0.59 - 0s 99us/step - loss: 0.0778 - mean_squared_error: 0.5260\n",
      "Epoch 342/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0881 - mean_squared_error: 0.50 - 0s 120us/step - loss: 0.0778 - mean_squared_error: 0.5257\n",
      "Epoch 343/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0890 - mean_squared_error: 0.67 - 0s 96us/step - loss: 0.0778 - mean_squared_error: 0.5255\n",
      "Epoch 344/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0808 - mean_squared_error: 0.57 - 0s 112us/step - loss: 0.0777 - mean_squared_error: 0.5255\n",
      "Epoch 345/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0566 - mean_squared_error: 0.44 - 0s 138us/step - loss: 0.0777 - mean_squared_error: 0.5257\n",
      "Epoch 346/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1251 - mean_squared_error: 0.71 - 0s 115us/step - loss: 0.0777 - mean_squared_error: 0.5257\n",
      "Epoch 347/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0587 - mean_squared_error: 0.44 - 0s 140us/step - loss: 0.0777 - mean_squared_error: 0.5257\n",
      "Epoch 348/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1138 - mean_squared_error: 0.59 - 0s 119us/step - loss: 0.0777 - mean_squared_error: 0.5258\n",
      "Epoch 349/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0467 - mean_squared_error: 0.51 - 0s 122us/step - loss: 0.0777 - mean_squared_error: 0.5261\n",
      "Epoch 350/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0786 - mean_squared_error: 0.65 - 0s 120us/step - loss: 0.0777 - mean_squared_error: 0.5264\n",
      "Epoch 351/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0577 - mean_squared_error: 0.44 - 0s 123us/step - loss: 0.0776 - mean_squared_error: 0.5264\n",
      "Epoch 352/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0354 - mean_squared_error: 0.31 - 0s 146us/step - loss: 0.0777 - mean_squared_error: 0.5266\n",
      "Epoch 353/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1317 - mean_squared_error: 0.89 - 0s 142us/step - loss: 0.0776 - mean_squared_error: 0.5265\n",
      "Epoch 354/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0893 - mean_squared_error: 0.57 - 0s 116us/step - loss: 0.0776 - mean_squared_error: 0.5267\n",
      "Epoch 355/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0839 - mean_squared_error: 0.54 - 0s 153us/step - loss: 0.0776 - mean_squared_error: 0.5265\n",
      "Epoch 356/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0591 - mean_squared_error: 0.41 - 0s 113us/step - loss: 0.0776 - mean_squared_error: 0.5262\n",
      "Epoch 357/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0898 - mean_squared_error: 0.53 - 0s 142us/step - loss: 0.0775 - mean_squared_error: 0.5260\n",
      "Epoch 358/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0706 - mean_squared_error: 0.44 - 0s 115us/step - loss: 0.0775 - mean_squared_error: 0.5262\n",
      "Epoch 359/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1270 - mean_squared_error: 0.70 - 0s 131us/step - loss: 0.0775 - mean_squared_error: 0.5261\n",
      "Epoch 360/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0615 - mean_squared_error: 0.35 - 0s 105us/step - loss: 0.0775 - mean_squared_error: 0.5265\n",
      "Epoch 361/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0606 - mean_squared_error: 0.43 - 0s 110us/step - loss: 0.0775 - mean_squared_error: 0.5263\n",
      "Epoch 362/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0807 - mean_squared_error: 0.54 - 0s 101us/step - loss: 0.0775 - mean_squared_error: 0.5262\n",
      "Epoch 363/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1107 - mean_squared_error: 0.62 - 0s 112us/step - loss: 0.0775 - mean_squared_error: 0.5265\n",
      "Epoch 364/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0673 - mean_squared_error: 0.51 - 0s 92us/step - loss: 0.0775 - mean_squared_error: 0.5271\n",
      "Epoch 365/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0559 - mean_squared_error: 0.36 - 0s 97us/step - loss: 0.0774 - mean_squared_error: 0.5271\n",
      "Epoch 366/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0570 - mean_squared_error: 0.47 - 0s 94us/step - loss: 0.0774 - mean_squared_error: 0.5269\n",
      "Epoch 367/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0390 - mean_squared_error: 0.53 - 0s 93us/step - loss: 0.0774 - mean_squared_error: 0.5268\n",
      "Epoch 368/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0699 - mean_squared_error: 0.41 - 0s 94us/step - loss: 0.0774 - mean_squared_error: 0.5267\n",
      "Epoch 369/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0624 - mean_squared_error: 0.60 - 0s 98us/step - loss: 0.0774 - mean_squared_error: 0.5265\n",
      "Epoch 370/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0396 - mean_squared_error: 0.41 - 0s 96us/step - loss: 0.0774 - mean_squared_error: 0.5267\n",
      "Epoch 371/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0789 - mean_squared_error: 0.62 - 0s 93us/step - loss: 0.0774 - mean_squared_error: 0.5267\n",
      "Epoch 372/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1026 - mean_squared_error: 0.65 - 0s 102us/step - loss: 0.0773 - mean_squared_error: 0.5263\n",
      "Epoch 373/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0627 - mean_squared_error: 0.53 - 0s 93us/step - loss: 0.0774 - mean_squared_error: 0.5267\n",
      "Epoch 374/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0700 - mean_squared_error: 0.53 - 0s 91us/step - loss: 0.0773 - mean_squared_error: 0.5267\n",
      "Epoch 375/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0546 - mean_squared_error: 0.40 - 0s 94us/step - loss: 0.0773 - mean_squared_error: 0.5270\n",
      "Epoch 376/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0639 - mean_squared_error: 0.49 - 0s 105us/step - loss: 0.0773 - mean_squared_error: 0.5270\n",
      "Epoch 377/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0995 - mean_squared_error: 0.72 - 0s 125us/step - loss: 0.0773 - mean_squared_error: 0.5266\n",
      "Epoch 378/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0936 - mean_squared_error: 0.60 - 0s 151us/step - loss: 0.0773 - mean_squared_error: 0.5273\n",
      "Epoch 379/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0669 - mean_squared_error: 0.56 - 0s 106us/step - loss: 0.0773 - mean_squared_error: 0.5274\n",
      "Epoch 380/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1135 - mean_squared_error: 0.66 - 0s 101us/step - loss: 0.0773 - mean_squared_error: 0.5275\n",
      "Epoch 381/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0337 - mean_squared_error: 0.33 - 0s 94us/step - loss: 0.0773 - mean_squared_error: 0.5270\n",
      "Epoch 382/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1160 - mean_squared_error: 0.69 - 0s 98us/step - loss: 0.0772 - mean_squared_error: 0.5268\n",
      "Epoch 383/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0736 - mean_squared_error: 0.56 - 0s 100us/step - loss: 0.0772 - mean_squared_error: 0.5270\n",
      "Epoch 384/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1019 - mean_squared_error: 0.58 - 0s 96us/step - loss: 0.0772 - mean_squared_error: 0.5270\n",
      "Epoch 385/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0517 - mean_squared_error: 0.41 - 0s 102us/step - loss: 0.0772 - mean_squared_error: 0.5268\n",
      "Epoch 386/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0854 - mean_squared_error: 0.50 - 0s 93us/step - loss: 0.0772 - mean_squared_error: 0.5270\n",
      "Epoch 387/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0554 - mean_squared_error: 0.47 - 0s 102us/step - loss: 0.0772 - mean_squared_error: 0.5273\n",
      "Epoch 388/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1049 - mean_squared_error: 0.61 - 0s 98us/step - loss: 0.0772 - mean_squared_error: 0.5277\n",
      "Epoch 389/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0724 - mean_squared_error: 0.52 - 0s 101us/step - loss: 0.0771 - mean_squared_error: 0.5279\n",
      "Epoch 390/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1184 - mean_squared_error: 0.56 - 0s 103us/step - loss: 0.0771 - mean_squared_error: 0.5279\n",
      "Epoch 391/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0479 - mean_squared_error: 0.46 - 0s 98us/step - loss: 0.0771 - mean_squared_error: 0.5279\n",
      "Epoch 392/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1160 - mean_squared_error: 0.68 - 0s 96us/step - loss: 0.0771 - mean_squared_error: 0.5277\n",
      "Epoch 393/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - ETA: 0s - loss: 0.1225 - mean_squared_error: 0.74 - 0s 105us/step - loss: 0.0771 - mean_squared_error: 0.5277\n",
      "Epoch 394/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0914 - mean_squared_error: 0.50 - 0s 103us/step - loss: 0.0771 - mean_squared_error: 0.5276\n",
      "Epoch 395/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0752 - mean_squared_error: 0.62 - 0s 93us/step - loss: 0.0771 - mean_squared_error: 0.5277\n",
      "Epoch 396/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1424 - mean_squared_error: 0.81 - 0s 94us/step - loss: 0.0771 - mean_squared_error: 0.5277\n",
      "Epoch 397/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0742 - mean_squared_error: 0.51 - 0s 99us/step - loss: 0.0771 - mean_squared_error: 0.5284\n",
      "Epoch 398/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0541 - mean_squared_error: 0.39 - 0s 104us/step - loss: 0.0771 - mean_squared_error: 0.5281\n",
      "Epoch 399/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0620 - mean_squared_error: 0.51 - 0s 100us/step - loss: 0.0771 - mean_squared_error: 0.5278\n",
      "Epoch 400/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0880 - mean_squared_error: 0.58 - 0s 97us/step - loss: 0.0771 - mean_squared_error: 0.5275\n",
      "Epoch 401/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1267 - mean_squared_error: 0.61 - 0s 99us/step - loss: 0.0771 - mean_squared_error: 0.5281\n",
      "Epoch 402/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0829 - mean_squared_error: 0.70 - 0s 97us/step - loss: 0.0770 - mean_squared_error: 0.5282\n",
      "Epoch 403/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0766 - mean_squared_error: 0.41 - 0s 98us/step - loss: 0.0770 - mean_squared_error: 0.5286\n",
      "Epoch 404/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1127 - mean_squared_error: 0.61 - 0s 95us/step - loss: 0.0769 - mean_squared_error: 0.5291\n",
      "Epoch 405/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0409 - mean_squared_error: 0.49 - 0s 109us/step - loss: 0.0768 - mean_squared_error: 0.5295\n",
      "Epoch 406/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0671 - mean_squared_error: 0.55 - 0s 95us/step - loss: 0.0768 - mean_squared_error: 0.5299\n",
      "Epoch 407/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1066 - mean_squared_error: 0.67 - 0s 99us/step - loss: 0.0767 - mean_squared_error: 0.5309\n",
      "Epoch 408/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0743 - mean_squared_error: 0.56 - 0s 102us/step - loss: 0.0766 - mean_squared_error: 0.5312\n",
      "Epoch 409/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0722 - mean_squared_error: 0.56 - 0s 100us/step - loss: 0.0766 - mean_squared_error: 0.5315\n",
      "Epoch 410/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0652 - mean_squared_error: 0.57 - 0s 99us/step - loss: 0.0766 - mean_squared_error: 0.5316\n",
      "Epoch 411/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0525 - mean_squared_error: 0.48 - 0s 103us/step - loss: 0.0765 - mean_squared_error: 0.5319\n",
      "Epoch 412/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1009 - mean_squared_error: 0.62 - 0s 97us/step - loss: 0.0765 - mean_squared_error: 0.5325\n",
      "Epoch 413/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1215 - mean_squared_error: 0.59 - 0s 101us/step - loss: 0.0764 - mean_squared_error: 0.5330\n",
      "Epoch 414/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0784 - mean_squared_error: 0.46 - 0s 95us/step - loss: 0.0764 - mean_squared_error: 0.5334\n",
      "Epoch 415/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1239 - mean_squared_error: 0.66 - 0s 97us/step - loss: 0.0764 - mean_squared_error: 0.5344\n",
      "Epoch 416/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0496 - mean_squared_error: 0.47 - 0s 98us/step - loss: 0.0762 - mean_squared_error: 0.5345\n",
      "Epoch 417/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0746 - mean_squared_error: 0.54 - 0s 110us/step - loss: 0.0761 - mean_squared_error: 0.5347\n",
      "Epoch 418/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0723 - mean_squared_error: 0.41 - 0s 96us/step - loss: 0.0760 - mean_squared_error: 0.5346\n",
      "Epoch 419/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1178 - mean_squared_error: 0.83 - 0s 97us/step - loss: 0.0759 - mean_squared_error: 0.5344\n",
      "Epoch 420/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0425 - mean_squared_error: 0.48 - 0s 99us/step - loss: 0.0758 - mean_squared_error: 0.5346\n",
      "Epoch 421/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0694 - mean_squared_error: 0.57 - 0s 97us/step - loss: 0.0756 - mean_squared_error: 0.5349\n",
      "Epoch 422/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1152 - mean_squared_error: 0.64 - 0s 96us/step - loss: 0.0756 - mean_squared_error: 0.5362\n",
      "Epoch 423/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1368 - mean_squared_error: 0.70 - 0s 99us/step - loss: 0.0754 - mean_squared_error: 0.5370\n",
      "Epoch 424/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0686 - mean_squared_error: 0.50 - 0s 104us/step - loss: 0.0752 - mean_squared_error: 0.5379\n",
      "Epoch 425/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0764 - mean_squared_error: 0.53 - 0s 99us/step - loss: 0.0751 - mean_squared_error: 0.5392\n",
      "Epoch 426/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0417 - mean_squared_error: 0.34 - 0s 98us/step - loss: 0.0750 - mean_squared_error: 0.5402\n",
      "Epoch 427/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0693 - mean_squared_error: 0.52 - 0s 98us/step - loss: 0.0749 - mean_squared_error: 0.5412\n",
      "Epoch 428/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0593 - mean_squared_error: 0.51 - 0s 100us/step - loss: 0.0749 - mean_squared_error: 0.5425\n",
      "Epoch 429/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0432 - mean_squared_error: 0.37 - 0s 101us/step - loss: 0.0747 - mean_squared_error: 0.5433\n",
      "Epoch 430/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0905 - mean_squared_error: 0.58 - 0s 93us/step - loss: 0.0747 - mean_squared_error: 0.5440\n",
      "Epoch 431/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0887 - mean_squared_error: 0.46 - 0s 96us/step - loss: 0.0746 - mean_squared_error: 0.5443\n",
      "Epoch 432/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0630 - mean_squared_error: 0.49 - 0s 99us/step - loss: 0.0746 - mean_squared_error: 0.5457\n",
      "Epoch 433/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0543 - mean_squared_error: 0.55 - 0s 99us/step - loss: 0.0745 - mean_squared_error: 0.5465\n",
      "Epoch 434/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0624 - mean_squared_error: 0.55 - 0s 99us/step - loss: 0.0744 - mean_squared_error: 0.5477\n",
      "Epoch 435/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0395 - mean_squared_error: 0.43 - 0s 100us/step - loss: 0.0743 - mean_squared_error: 0.5482\n",
      "Epoch 436/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0760 - mean_squared_error: 0.62 - 0s 98us/step - loss: 0.0743 - mean_squared_error: 0.5484\n",
      "Epoch 437/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0563 - mean_squared_error: 0.62 - 0s 92us/step - loss: 0.0742 - mean_squared_error: 0.5492\n",
      "Epoch 438/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0692 - mean_squared_error: 0.50 - 0s 106us/step - loss: 0.0742 - mean_squared_error: 0.5505\n",
      "Epoch 439/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0348 - mean_squared_error: 0.46 - 0s 127us/step - loss: 0.0741 - mean_squared_error: 0.5508\n",
      "Epoch 440/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0940 - mean_squared_error: 0.70 - 0s 152us/step - loss: 0.0741 - mean_squared_error: 0.5514\n",
      "Epoch 441/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0776 - mean_squared_error: 0.45 - 0s 129us/step - loss: 0.0741 - mean_squared_error: 0.5524\n",
      "Epoch 442/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0760 - mean_squared_error: 0.53 - 0s 131us/step - loss: 0.0740 - mean_squared_error: 0.5532\n",
      "Epoch 443/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0816 - mean_squared_error: 0.63 - 0s 121us/step - loss: 0.0740 - mean_squared_error: 0.5537\n",
      "Epoch 444/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0546 - mean_squared_error: 0.53 - 0s 199us/step - loss: 0.0739 - mean_squared_error: 0.5542\n",
      "Epoch 445/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0705 - mean_squared_error: 0.56 - 0s 125us/step - loss: 0.0739 - mean_squared_error: 0.5551\n",
      "Epoch 446/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0626 - mean_squared_error: 0.52 - 0s 137us/step - loss: 0.0739 - mean_squared_error: 0.5556\n",
      "Epoch 447/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0793 - mean_squared_error: 0.59 - 0s 104us/step - loss: 0.0738 - mean_squared_error: 0.5556\n",
      "Epoch 448/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0592 - mean_squared_error: 0.41 - 0s 143us/step - loss: 0.0738 - mean_squared_error: 0.5560\n",
      "Epoch 449/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0694 - mean_squared_error: 0.56 - 0s 163us/step - loss: 0.0738 - mean_squared_error: 0.5565\n",
      "Epoch 450/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0705 - mean_squared_error: 0.49 - 0s 201us/step - loss: 0.0737 - mean_squared_error: 0.5571\n",
      "Epoch 451/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0918 - mean_squared_error: 0.63 - 0s 175us/step - loss: 0.0737 - mean_squared_error: 0.5577\n",
      "Epoch 452/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0641 - mean_squared_error: 0.46 - 0s 229us/step - loss: 0.0737 - mean_squared_error: 0.5579\n",
      "Epoch 453/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0525 - mean_squared_error: 0.58 - 0s 112us/step - loss: 0.0736 - mean_squared_error: 0.5582\n",
      "Epoch 454/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0904 - mean_squared_error: 0.48 - 0s 148us/step - loss: 0.0737 - mean_squared_error: 0.5596\n",
      "Epoch 455/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0706 - mean_squared_error: 0.63 - 0s 169us/step - loss: 0.0736 - mean_squared_error: 0.5601\n",
      "Epoch 456/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0562 - mean_squared_error: 0.35 - 0s 156us/step - loss: 0.0736 - mean_squared_error: 0.5602\n",
      "Epoch 457/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0550 - mean_squared_error: 0.42 - 0s 137us/step - loss: 0.0736 - mean_squared_error: 0.5599\n",
      "Epoch 458/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1060 - mean_squared_error: 0.54 - 0s 134us/step - loss: 0.0735 - mean_squared_error: 0.5605\n",
      "Epoch 459/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0515 - mean_squared_error: 0.53 - 0s 142us/step - loss: 0.0735 - mean_squared_error: 0.5612\n",
      "Epoch 460/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0647 - mean_squared_error: 0.53 - 0s 175us/step - loss: 0.0735 - mean_squared_error: 0.5618\n",
      "Epoch 461/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0789 - mean_squared_error: 0.57 - 0s 136us/step - loss: 0.0735 - mean_squared_error: 0.5618\n",
      "Epoch 462/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0756 - mean_squared_error: 0.64 - 0s 150us/step - loss: 0.0735 - mean_squared_error: 0.5622\n",
      "Epoch 463/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0820 - mean_squared_error: 0.64 - 0s 150us/step - loss: 0.0734 - mean_squared_error: 0.5624\n",
      "Epoch 464/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0681 - mean_squared_error: 0.65 - 0s 154us/step - loss: 0.0734 - mean_squared_error: 0.5625\n",
      "Epoch 465/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0988 - mean_squared_error: 0.78 - 0s 149us/step - loss: 0.0734 - mean_squared_error: 0.5626\n",
      "Epoch 466/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0533 - mean_squared_error: 0.37 - 0s 189us/step - loss: 0.0734 - mean_squared_error: 0.5638\n",
      "Epoch 467/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0603 - mean_squared_error: 0.38 - 0s 181us/step - loss: 0.0733 - mean_squared_error: 0.5642\n",
      "Epoch 468/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0726 - mean_squared_error: 0.59 - 0s 160us/step - loss: 0.0734 - mean_squared_error: 0.5644\n",
      "Epoch 469/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0861 - mean_squared_error: 0.74 - 0s 237us/step - loss: 0.0733 - mean_squared_error: 0.5643\n",
      "Epoch 470/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0494 - mean_squared_error: 0.40 - 0s 161us/step - loss: 0.0733 - mean_squared_error: 0.5642\n",
      "Epoch 471/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0682 - mean_squared_error: 0.54 - 0s 158us/step - loss: 0.0733 - mean_squared_error: 0.5648\n",
      "Epoch 472/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0824 - mean_squared_error: 0.66 - 0s 135us/step - loss: 0.0733 - mean_squared_error: 0.5654\n",
      "Epoch 473/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0620 - mean_squared_error: 0.50 - 0s 115us/step - loss: 0.0733 - mean_squared_error: 0.5662\n",
      "Epoch 474/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0831 - mean_squared_error: 0.84 - 0s 160us/step - loss: 0.0733 - mean_squared_error: 0.5664\n",
      "Epoch 475/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0639 - mean_squared_error: 0.59 - 0s 201us/step - loss: 0.0732 - mean_squared_error: 0.5663\n",
      "Epoch 476/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0733 - mean_squared_error: 0.57 - 0s 121us/step - loss: 0.0732 - mean_squared_error: 0.5668\n",
      "Epoch 477/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0914 - mean_squared_error: 0.63 - 0s 135us/step - loss: 0.0732 - mean_squared_error: 0.5666\n",
      "Epoch 478/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0832 - mean_squared_error: 0.53 - 0s 124us/step - loss: 0.0732 - mean_squared_error: 0.5663\n",
      "Epoch 479/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0752 - mean_squared_error: 0.66 - 0s 147us/step - loss: 0.0732 - mean_squared_error: 0.5664\n",
      "Epoch 480/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0550 - mean_squared_error: 0.61 - 0s 183us/step - loss: 0.0732 - mean_squared_error: 0.5666\n",
      "Epoch 481/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0971 - mean_squared_error: 0.67 - 0s 145us/step - loss: 0.0732 - mean_squared_error: 0.5673\n",
      "Epoch 482/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0891 - mean_squared_error: 0.56 - 0s 127us/step - loss: 0.0732 - mean_squared_error: 0.5676\n",
      "Epoch 483/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0922 - mean_squared_error: 0.45 - 0s 131us/step - loss: 0.0732 - mean_squared_error: 0.5678\n",
      "Epoch 484/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0671 - mean_squared_error: 0.49 - 0s 152us/step - loss: 0.0732 - mean_squared_error: 0.5683\n",
      "Epoch 485/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0392 - mean_squared_error: 0.44 - 0s 185us/step - loss: 0.0731 - mean_squared_error: 0.5679\n",
      "Epoch 486/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1105 - mean_squared_error: 0.57 - 0s 172us/step - loss: 0.0732 - mean_squared_error: 0.5679\n",
      "Epoch 487/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0754 - mean_squared_error: 0.60 - 0s 184us/step - loss: 0.0731 - mean_squared_error: 0.5679\n",
      "Epoch 488/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0863 - mean_squared_error: 0.67 - 0s 150us/step - loss: 0.0731 - mean_squared_error: 0.5679\n",
      "Epoch 489/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0773 - mean_squared_error: 0.63 - 0s 115us/step - loss: 0.0731 - mean_squared_error: 0.5674\n",
      "Epoch 490/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0586 - mean_squared_error: 0.62 - 0s 154us/step - loss: 0.0731 - mean_squared_error: 0.5675\n",
      "Epoch 491/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - ETA: 0s - loss: 0.1137 - mean_squared_error: 0.56 - 0s 100us/step - loss: 0.0731 - mean_squared_error: 0.5678\n",
      "Epoch 492/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0528 - mean_squared_error: 0.43 - 0s 195us/step - loss: 0.0731 - mean_squared_error: 0.5676\n",
      "Epoch 493/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0616 - mean_squared_error: 0.59 - 0s 127us/step - loss: 0.0731 - mean_squared_error: 0.5677\n",
      "Epoch 494/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0516 - mean_squared_error: 0.44 - 0s 105us/step - loss: 0.0730 - mean_squared_error: 0.5675\n",
      "Epoch 495/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0653 - mean_squared_error: 0.60 - 0s 106us/step - loss: 0.0730 - mean_squared_error: 0.5674\n",
      "Epoch 496/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0770 - mean_squared_error: 0.47 - 0s 108us/step - loss: 0.0730 - mean_squared_error: 0.5677\n",
      "Epoch 497/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0320 - mean_squared_error: 0.55 - 0s 108us/step - loss: 0.0730 - mean_squared_error: 0.5679\n",
      "Epoch 498/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0741 - mean_squared_error: 0.53 - 0s 107us/step - loss: 0.0730 - mean_squared_error: 0.5678\n",
      "Epoch 499/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0731 - mean_squared_error: 0.54 - 0s 169us/step - loss: 0.0730 - mean_squared_error: 0.5679\n",
      "Epoch 500/500\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0832 - mean_squared_error: 0.67 - 0s 125us/step - loss: 0.0730 - mean_squared_error: 0.5683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x185fe3e27b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = f1(param_name='glm_1')\n",
    "model.fit(x_train, y_train, epochs=500, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5481227216244245"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "score = mean_squared_error(y_test, y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "onnx.onnx_ml_pb2.ModelProto"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)\n",
    "# cross check import (f1p1 and f2p2 combination) - Is it possible to edit after the export-import flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "onnx.save(model, './onnx_model.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LogisticRegression': True}\n",
      "{'LinearRegression': True}\n"
     ]
    }
   ],
   "source": [
    "mapping = { \"KerasClassifier\": {\n",
    "    \"LogisticRegression\": True\n",
    "},\n",
    " \"KerasRegressor\": {\n",
    "     \"LinearRegression\": True\n",
    " }\n",
    "}\n",
    "\n",
    "name = \"LinearRegression\"\n",
    "\n",
    "for key, value in mapping.items():\n",
    "    test = mapping[key]\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "def glm(**kwargs):  # Should param_name be optional or mandatory?\n",
    "\n",
    "    # kwargs.setdefault('param_name', 'glm_1')\n",
    "    params_json = json.load(open('../imly/architectures/sklearn/params.json')) # Remove and make it generic\n",
    "    params = params_json['params'][kwargs['param_name']]\n",
    "    kwargs.setdefault('params', params)\n",
    "    kwargs.setdefault('x_train', np.array([[1], [2]]))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(kwargs['params']['first_neuron'], # Change first_neuron to input_size\n",
    "                    input_dim=kwargs['x_train'].shape[1], # Find a better way to pass input_dim. Through params maybe?\n",
    "                    activation=kwargs['params']['activation']))\n",
    "\n",
    "    model.compile(optimizer=kwargs['params']['optimizer'],\n",
    "                  loss=kwargs['params']['losses'],\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x17f81a0aeb8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm.__call__(param_name=\"log_reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import experiment_automation_script\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# dataset_info = experiment_automation_script.get_dataset_info(\"diabetes\")\n",
    "url = \"../data/diabetes.csv\" if path.exists(\"../data/diabetes.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, index_col=False)\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - ETA: 11 - 2s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5110251939386354, -4.287840857541651]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import random\n",
    "\n",
    "random.seed(7)\n",
    "# def create_model():\n",
    "def coeff_determination(y_true, y_pred): # Read and understand the workflow\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "params_json = json.load(open('../imly/architectures/sklearn/params.json')) # Remove and make it generic\n",
    "params = params_json['params']['log_reg']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1,  # Change first_neuron to input_size\n",
    "                input_dim=10,  # Find a better way to pass input_dim. Through params maybe?\n",
    "                activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=[coeff_determination])  # Dealing with accuracy in regression models\n",
    "#     return model\n",
    "\n",
    "# model = KerasRegressor(build_fn=create_model)\n",
    "# model.fit(x_train, y_train)\n",
    "# model.score(x_test,y_test)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class kerasWrapper(build_fn):\n",
    "    def __init__():\n",
    "        self.build_fn = build_fn\n",
    "\n",
    "\n",
    "class myWrapper(kerasWrapper):\n",
    "    def __init__(self, build_fn, **kwargs):\n",
    "        super(kerasWrapper, self).__init__(build_fn=build_fn)\n",
    "        \n",
    "    def fit():\n",
    "        \n",
    "\n",
    "class create_model(**kwargs):\n",
    "    def __init__(self, kwargs):\n",
    "        try:\n",
    "            self.x_train = kwargs['x_train']\n",
    "        except KeyError:\n",
    "            self.x_train = None\n",
    "            \n",
    "    def __call__():\n",
    "        print(self.x_train)\n",
    "        \n",
    "\n",
    "\n",
    "build_fn = create_model()\n",
    "\n",
    "model = myWrapper(build_fn=build_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed --  __root__\n",
      "scope --  ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'declare_local_operator', 'declare_local_variable', 'delete_local_operator', 'delete_local_variable', 'find_sink_variables', 'get_local_variable_or_declare_one', 'get_onnx_variable_name', 'get_unique_operator_name', 'get_unique_variable_name', 'name', 'onnx_operator_names', 'onnx_variable_names', 'operators', 'parent_scopes', 'target_opset', 'variable_name_mapping', 'variables']\n",
      "Seed --  input\n",
      "Seed --  SklearnLinearClassifier\n",
      "Seed --  label\n",
      "Seed --  probabilities\n",
      "Seed --  LinearClassifier\n",
      "Seed --  probability_tensor\n",
      "Seed --  probability_tensor_normalized\n",
      "Seed --  Normalizer\n",
      "Seed --  ZipMap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The maximum opset needed by this model is only 1.\n"
     ]
    }
   ],
   "source": [
    "from winmltools import convert_sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from onnxmltools.convert.common.data_types import FloatTensorType, Int64TensorType\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X, Y)\n",
    "\n",
    "onnx_model = convert_sklearn(model, 7, initial_types=[('input', FloatTensorType([1, 2]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "LinearRegression\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SklearnKerasClassifier'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"LogisticRegression\"\n",
    "\n",
    "wrapper_mapping_json = json.load(open('../imly/wrappers/keras_wrapper_mapping.json'))\n",
    "\n",
    "for key, value in wrapper_mapping_json.items():\n",
    "    for name in value:\n",
    "        print(name)\n",
    "        if model_name == name:\n",
    "            wrapper = key\n",
    "            \n",
    "wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wrappers.sklearn.keras_classifier.SklearnKerasClassifier"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "wrapper_class = 'SklearnKerasClassifier'\n",
    "\n",
    "path = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', wrapper_class)\n",
    "module_path = re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', path).lower()\n",
    "package_name = module_path.split('_')[0]\n",
    "wrapper_name = '_'.join(module_path.split('_')[1:3])\n",
    "\n",
    "module_path = 'wrappers.' + package_name + '.' + wrapper_name\n",
    "module_path\n",
    "wrapper_module = __import__(module_path, fromlist=[wrapper_class])\n",
    "function = getattr(wrapper_module, wrapper_class)\n",
    "function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = 'sklearn_keras_classifier'\n",
    "'_'.join(module_path.split('_')[1:3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"../data/uci_carbon_nanotubes.csv\"\n",
    "data = pd.read_csv(url, delimiter=\";\")\n",
    "data\n",
    "# frames = [X, Y]\n",
    "# data = pd.concat(frames, axis=1)\n",
    "# data.to_csv('../data/uci_auto_mpg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-a287d78b0081>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmean_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmean_vectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mcl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Mean Vector class %s: %s\\n'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_vectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcl\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mean_vectors = []\n",
    "for cl in range(1,4):\n",
    "    mean_vectors.append(np.mean(X[y==cl], axis=0))\n",
    "    print('Mean Vector class %s: %s\\n' %(cl, mean_vectors[cl-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x22703d0f3c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Testing concordance ###\n",
    "\n",
    "from automation_script import get_dataset_info\n",
    "from imly import dope\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_info = get_dataset_info(\"diabetes\")\n",
    "url = \"../data/diabetes.csv\" if path.exists(\"../data/diabetes.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, index_col=False)\n",
    "sc = StandardScaler()\n",
    "data = sc.fit_transform(data)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "m = dope(model)\n",
    "\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "\n",
    "m.fit(x_train, y_train)\n",
    "\n",
    "# score = m.score(x_test, y_test)\n",
    "\n",
    "\n",
    "### Automation script ###\n",
    "\n",
    "# params = {\n",
    "#     'epochs': 200\n",
    "# }\n",
    "\n",
    "# experiment_automation_script.dopify(dataset_info, 'logistic_regression', X, Y, 0.60, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)\n",
    "sklearn_pred = model.predict(x_test)\n",
    "keras_pred = m.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989899125789394"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.correlations import concordance_correlation_coefficient as ccc\n",
    "\n",
    "ccc(sklearn_pred, keras_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x22704f6fb38>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.scatter(sklearn_pred, keras_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:15<00:00, 15.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x261561d9358>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Testing CCC ###\n",
    "\n",
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from imly import dope\n",
    "\n",
    "dataset_name = \"uci_auto_mpg\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "data = pd.read_csv(\"../data/uci_auto_mpg.csv\", delimiter=\",\", header=0, index_col='car name')\n",
    "data = data[data.horsepower != '?']\n",
    "sc = StandardScaler()\n",
    "data = sc.fit_transform(data)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "Y = data.iloc[:,1]\n",
    "X = data.iloc[:,2:]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "m = dope(model)\n",
    "\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "\n",
    "m.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)\n",
    "sklearn_pred = model.predict(x_test)\n",
    "keras_pred = m.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9894374129958334"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.correlations import concordance_correlation_coefficient as ccc\n",
    "\n",
    "ccc(sklearn_pred, keras_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x26156618e10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3X+Q3HWd5/HnezoN9KDHRBkVGnKJt1RYI5KYKURTtSXoEsQFRgIC69ZirVspbpe60vJSF8orApR1jJfaUvf0TqNnLXtwGgQdw8Je/BEsr6iLR+Ikhgi5RYSYDiVRGO4ks9CZvO+P7m+np+f77f5297d/fl+Pqqnpnv5Ofz/pTH3e3+/n8/68P+buiIhI+oz0ugEiItIbCgAiIimlACAiklIKACIiKaUAICKSUgoAIiIppQAgIpJSCgAiIimlACAiklJLet2Aes4++2xfvnx5r5shIjIw9u7d+1t3H49zbF8HgOXLl7Nnz55eN0NEZGCY2fNxj9UQkIhISikAiIiklAKAiEhKKQCIiKSUAoCISEopAIiIpFRfp4GKiKTF9EyBrTsPcXR2jnPHcmxav5LJNfmOnlMBQESkx6ZnCtz+nQPMFecBKMzOcft3DgB0NAhoCEhEpMe27jxU6fwDc8V5tu481NHz6g5ARKTDGg3vHJ2dC/29qJ8nRXcAIiIdFAzvFGbncE4N70zPFCrHnDuWC/3dqJ8nRXcAIiId1Gh4Z+vOQxRm5zDAq47JZTNsWr+yo21TABAR6aCoYZzgTiAIDg6VIJDvUhZQIkNAZvYNM3vRzJ6MeP39ZvaKme0rf92RxHlFRPpd1DBOxmzRnUHQ+T+++fKOd/6Q3BzA3wFXNjjmf7r76vLX3QmdV0Skr21av5JcNrPgZ7lshnn30OM7PfFbLZEA4O4/AV5K4r1ERAbF9EyBdVO7WLH5EdZN7VowsRuYXJPnnusuIj+Wwyhd4QfPw3R64rdaN+cA3mtm+4GjwL9194NdPLeISKLCFm99cvs+7nr4IFuuXrVgCGdyTT50SKf696E7E7/VzCNuQ5p+I7PlwD+4+ztDXvsXwEl3/72ZXQV80d0viHifjcBGgGXLlq19/vnYm9uIiHTNuqldFCKGa+JO5nai/IOZ7XX3iVjHdiMAhBz7HDDh7r+td9zExIRrS0gR6bWwjvpT2/cRp/fMZoyt11/clUldaC4AdGUhmJm9zcys/PiS8nl/141zi4i0I2oh11m5bKzfL847dz3cnyPeicwBmNk3gfcDZ5vZEWALkAVw968A1wP/2sxOAHPATZ7UrYeISAdFLeQ6IztCLptZ9FqYl48XO9W8tiQSANz95gavfwn4UhLnEhHppqi0zNnjRT5/42ru3HGQ2bnmOvhelH4Oo1pAIiJ1RKVljpRGtdm35Qq+cOPqyLROgLGq4aI4tYG6RQFARFKtUS7/pvUryWZs0e/Nu1c67sk1eR7ffDlfuHE12ZGFx2ZHjDuvWVV53qvSz2FUC0hEUissl3/Tt/dz18MHmT1e5NyxHJddOE5Uuk/QcQfDN8H3fiz9HEYBQERSK+xqvHjSK5O2hdk57tt9uO571HbcUYu+AueO5ULXD3RzBXBAQ0AiklpJXHU323FH1Qbq5grggAKAiKRWu1fdrXTcUbWBepEFpCEgEUmdIA0zbCOWuJaOZhfV/Imr0TBRtygAiEiq1E78Vm/EMpbL8urrJyjONw4JM3dc0dF2doMCgIgMrbAFV2ETv07pin7mjiuYnilw18MH667erZfzP0gUAERkKIWleNaWX6728vFiJad/ck2e6ZlC6CrfXk3YdoICgIgMvLhX+o3q9tTm9AeBoB/KNnSCAoCIDLRmr/TrCUsL7ZcJ205QGqiIDLSoK/2MLS7f0EgvFmP1kgKAiAy0qMVcUZuuR8lmbGjG9uPSEJCIDJyoCdpWtZPTP8gUAERkoEzPFNj07f0UT7a/p1R+LMfjmy9PoFWDSQFARAbG9EyBTz+wv+nhnTDDlM7ZKs0BiMhACLJ9kuj8DXpWf6ef6A5ARHqqui5Pxox5d/Ih+fZh2T7tSHvnD8ltCv8N4E+AF939nSGvG/BF4CrgOPBxd/9ZEucWkcFVm8MfXN0Hufx7nn+Jx54+xtHy9olJSVu6Z5SkhoD+DriyzusfAi4of20E/ktC5xWRAVbvqn6uOM99uw9X9s6NI06NHo39n5JIAHD3nwAv1TnkWuDvvWQ3MGZm5yRxbhEZXElug7h0NFvZl7d2w5VgSVgva+/3o27NAeSBX1c9P1L+2Qu1B5rZRkp3CSxbtqwrjROR3ojaHrFZ2Yyx5erSxutx9uWVkm4FgLA12aF3de6+DdgGMDExkeSwn4j0mU3rVzZdt2csl+XOa1Yt6OAvu3CcrTsP8ant+yodfprz++PqVgA4Apxf9fw84GiXzi0ifar6aj3uncCrr58AqHTwUcXgqt9fwnVrHcAO4M+t5FLgFXdfNPwjIsNveqbAuqldrNj8COumdgGlzvy5qQ/zhRtXN/z94ryzdeehyvOoYnDVx0i4RAKAmX0T+F/ASjM7YmafMLNbzezW8iGPAs8CzwBfA/4qifOKyGAJrtaDzJ7gan16pgDEv2KvnjyOmkhOcoJ5WCUyBOTuNzd43YG/TuJcIjK4oq7WP7l9H59+YD83v+f8ymKweqrz+KMmkpXr35hKQYhI19S7Kp93577dh3n7+Gjd96jN49+0fuWitE/l+sejACAiLakdyw+GceqJc1X+7LHj/NmlyyobupjBaHYEIzyPf3JNnnuuu4j8WC7yGAmnWkAi0rRWMm+mZwocL2fw1DPvzmcnL+KzkxfFbs8wb9vYSboDEJGmNZt5EwSMl4833sClla0cpTUKACLStKic/cLsXOhQUDOVPG9+z/mND5JEaAhIRJpWL1Pnk9v38akH9uFeqs/jTqytGzNm3Pye85sa+pH2KACISNMapWkGL8cZ8gFtzdgrCgAiskCwQUu9Qmr5hIq4gVI2e0kBQEQqorJ7qjdmCYqvPbS30PYOXWE7f0n3KACISEVUds99uw9Xnhdm53hob4ENa/Pc/9PDtLpFr4Z9ek8BQCTFaod74g7rzBXneezpYxFF3eNRrZ7eUxqoSEqFFWZrJgM/CBqtUq2e3lMAEBli9co1hA33OOG7N4UJJohboYnf/qAAIDKkGpVejhqCiTuqc9mF40yuyTOWyzbVrjNPy6hWT59QABAZUo3KNbQ7BPPY08cAuPOaVYuqcYbJmPFnly7j4N1XqvPvE5oEFhlSjTZK2bR+JZse3E9xvrWZ3OB9ard1NBbeReSyuuLvVwoAIkNqbDQbuhJ3wZV/G1k8547lFmURBVs6NlpIJv1BAUBkwMRZqTs9U+D3/xxeevn46ycq71E82VoEyGUzXHbhOJu+vb/yHoXZOTZ9ez9bb7hY+f0DwrzVVRzVb2J2JfBFIAN83d2nal7/OLAVCFIQvuTuX2/0vhMTE75nz5622ycyLGpX6sKpIRY4deU90mBbxVw20/Qq3mBoJygEVzvUExjLZdm35Yqm3luSY2Z73X0izrFt3wGYWQb4MvDHwBHgCTPb4e6/qDl0u7vf1u75RNIsamL3zh0Hee3EycprjYq1zRXnY+29W23JCGBWmTOI+s04lT+lPySRBXQJ8Iy7P+vurwPfAq5N4H1FpEbUxO7sXLHpK/rgKj6u4klanjCW/pREAMgDv656fqT8s1obzOznZvagmWnHB5EmBAu6kux+l45med+/elOC73jqfWUwJBEAwi4iav9OHwaWu/u7gB8C90a+mdlGM9tjZnuOHTuWQPNEBlv1gq4oIy3sovjy8SI/OzzbRssWy2aMLVevSvQ9pXOSCABHgOor+vOAo9UHuPvv3P218tOvAWuj3szdt7n7hLtPjI+PJ9A8kcEWZzvFFpN5mCuebO0Xy7IjxtLRLEapuufW6y9WyucASSIN9AngAjNbQSnL5ybgT6sPMLNz3P2F8tNrgKcSOK9IKvRT1czsiPGGM5Ywe7yoHP8h0HYAcPcTZnYbsJNSGug33P2gmd0N7HH3HcC/MbNrgBPAS8DH2z2vSFo0U6a5E4J0T23eMnwSWQfQKVoHIBKe+5+kpaNZRk9bsmC3r+rdv9TpD5aurgMQkc6aXJNnz/MvLdiVKym5bIYtV69SB59SCgAifSSqzENQeTNpKtKWbhoCEukTYUM9waRrWFG3dmlP3uHUzBCQ9gMQ6RNh6Z7Fk55I51+7TEA7cgloCEikb3Qq3bO2iJuyeSSgACDSI7Xj/WflsokVUgur2DnvXrnyV+cvoCEgkZ6Ynimw6cH9C/br/X+vnSDbSk2HKvmxHM9NfZhf3nMV+bHcopos1VtCiigAiPTAXQ8fXFRZc/6kM9JGAKge15+eKUQuHuunlcXSWxoCEumBqInd1060Vpunelw/yCaK0u5m8DI8FABEuigY90/Sc1MfXvC8XvE4Zf9INQ0BiXRJnLLOrQwArZvaxfRMofK83hCPFn5JNQUAkS6JU9bZWRwEGgWFwuwct3/nQCUIRA3x5Mdy6vxlAQUAkQQFO3et2PxIU1fm1aqDQH4sx+dvXE2+wbh9dXbPpvUryWUzC17X0I+E0RyASBuqc/nPymV59fUTleye4MocSgXdminrHJRfri7V0KgiaBBggqv8sJpCItVUC0ikRXHLNAcdeStlnQ0qHTjAJ7fva3geSTfVAhLpgjhj+rDwynzD2nxTE73BIrHgTiJqKMhAQzzSNAUAkRbFHdOvnpR97Olji1bnxhGM8YeN7xvwsUuXaYhHmqYAINKiuAuqXn3tRGUyuF7QyFj9e4Ojs3NMrslzz3UXkR/LVTZi//yNq/ns5EWx2y0S0CSwSIs2rV8ZWr//tCUjvPr6qZ/NzhUrQzhRE8HV4/frpnaFHhMEnMk1eV3tSyISuQMwsyvN7JCZPWNmm0NeP93Mtpdf/6mZLU/ivCLdVp3muXXnITaszS+4Gt96w8WMjZ626PfmivPcueNgrBRNpXFKt7QdAMwsA3wZ+BDwDuBmM3tHzWGfAF529z8APg98rt3zinRb9UreYHL2/t2HuezCcX419WEe33w5k2vykameQannDWvzleGejBkb1i68og8mi+sdI5KEJO4ALgGecfdn3f114FvAtTXHXAvcW378IPABswYDniJ9Jizrx4H7dx9esOCr3lj+px7Yx327DzNfTr+ed+ehvYUFvz89U+ChvYW6x4gkIYkAkAd+XfX8SPlnoce4+wngFeDNYW9mZhvNbI+Z7Tl2rDMbYYvEVT3kE3Vl78CnH9hf6aDn66ytCXuptkZ/WKBRHX/phCQCQNjlTu2feZxjSj903+buE+4+MT4+3nbjRFpVO+RTz7w7mx7cz+q7vt/Suaqzg6IyhVTHX5KWRAA4Apxf9fw84GjUMWa2BDgLeCmBc4t0TNyFXoHivLe8pWN1SmlUeqnq+EvSkggATwAXmNkKMzsNuAnYUXPMDuCW8uPrgV3ezzUoROjeFbeygKRX2l4H4O4nzOw2YCeQAb7h7gfN7G5gj7vvAP4r8N/M7BlKV/43tXtekVbVbsYeVSitmeJtjWQzBg7Fkwuve5aOZtly9apFWUCgYm7SeSoGJ6kSVpAtl82wYW2ex54+tqDDhcYVOOPImPE3H70YUKcunddMMTgFAEmVqFW2xsKshFw2wz3Xlcor1KvAGYcBv6rZtlGkU1QNVCRC1Lh+7WVQkHY5uSbfcDOWRjR5K/1KAUBSY3qmwEgT6w+DYHHZheMt7dULmryV/qZicJIKwdh/vUVaYZZvfmTR8FBcGTNtwi59TXcAkgrN5vTDqU4/qvMP7gqWjmbJjiy8R8hlM/zNRy9W5y99TQFAUqETOf3Bvr0zd1zB1hsuXlAVVFf+Mgg0BCSpkGROf7Xq7R7V4cugUQCQoVK7yOuyC8d5aO8R5oon6/7eaHaE4w2OCaMMHxlkCgAy8KZnCtz18EFePr6wDk9hdo77dh+O9R7/4bp3Nb3oSxk+MugUAGSgTc8U2PTgforz7S1orC2/MDaaxR1emSsuWBmslbwyTBQAZGCE1fDZuvNQ253/0tEsEG8cXx2+DBOVgpCBEFXDp906PQBjueyCK3118jLImikFoTsAGQhRu2QlIajhX5id4/bvHAB0pS/poHUAMhBazeO/4C1nNnW8tl6UNFEAkIHQarrls8eOA9BECSBtvSipoQAgAyFsl6w4gto/7vH/2JXbL2mhACADYXJNng1r2xuXj7PMS7n9kiaaBJa+FL6it9Cx8xkoC0hSp60AYGZvArYDy4HngI+6+8shx80DB8pPD7v7Ne2cV4ZbbcpnYXaO+3cfbqkkcxz5sRyPb768Q+8u0r/aHQLaDPzI3S8AflR+HmbO3VeXv9T5S113PXxwUYpns51/doRFcwbZESttzl5FQz6SZu0GgGuBe8uP7wUm23w/SbnpmcKimj6teMMZWe657qIFJZq33nAxW69X2WaRQLtzAG919xcA3P0FM3tLxHFnmNke4AQw5e7TbZ5XhlRSOfizx4uRpR3U4YuUNAwAZvZD4G0hL32mifMsc/ejZvZ2YJeZHXD3X0acbyOwEWDZsmVNnEKGQVI5+ErlFGmsYQBw9w9GvWZmvzGzc8pX/+cAL0a8x9Hy92fN7MfAGiA0ALj7NmAblGoBNfwXyFCJ2rgllx0BLHb5B43rizTW7hzADuCW8uNbgO/VHmBmS83s9PLjs4F1wC/aPK/0memZAuumdrFi8yOsm9rF9ExrKZthC75y2Qz3XPeuRWP6Y7ls6HssHc1qmEckhnbnAKaAB8zsE8Bh4AYAM5sAbnX3vwT+EPiqmZ2kFHCm3F0BYIiEpW02W1StOu9/bDTL6UtGQit0Vr9fVIXQLVevSuqfJjLUVA5a2rbm7u+HZu5kzDjp3nCBVVRHHidDJ2yPAF39S5qpHLR0Tb20zaAOT9QdQdB5h435B1U542zQog5fpDWqBSRtiZu2OVec566HD1aeB1f9YZ1/QFU5RTpLAUBaNj1TqNuB13r5eLEyORy2wUstpXKKdJaGgGSBuGPqwRV8s4JhnUZX9yrRINJ5CgBS0Uw2z507FtfriSPo+KPy/aGU4qnJXJHOUwCQiqh9d2snY6dnCpV9dJs1YsaKzY8wNpolO2IUT57KQoub+SMiydAcgFREDcvU/rx6MrdZ8+44pfkADMZyWRVmE+kR3QFIRdSwTO1kbBLVOgGK886Zpy9h35YrEnk/EWmO7gCkYtP6lYvq5Wcz1vZkbL29fJXqKdI7CgCyUO3C8JCF4lE1eALZEWPpaOmYjJUKuGXMQo9VqqdI7ygASMXWnYcWTMoCFE/6osVed16zipHw/ryy8cqWq1eRy2Yqq4HnQ0qOKNVTpLc0ByAVUcMxhdk51k3tWrBBe1DnJ5AdMbbecHFlEnfd1K7QNNG49YFEpPMUAKSy+CuqLKBBZXI4aoP24E4h6NCjgslJd3419eFkGi4ibdEQUMo1qsljxJoWABZ2+lFj+xrzF+kfCgApV68mT34sF9nZh6nu3KM2dtGYv0j/UABIuaihGgMe33w5+Ygr9to54NrOfXJNftEOXlroJdJfNAeQco0Wf21avzJ0s5YNa/M89vSxukXjVKtfpL9pR7CUC9uNKxj3D4qyAdp1S2RAaEcwqat6J66MGfPule/Vk75BNdB7rruIxzdf3ssmi0gHtDUHYGY3mNlBMztZ3gg+6rgrzeyQmT1jZpvbOadEm54psG5qFys2P8K6qV2VzVdqj6nO+qleqBWW8RNUAxWR4dPuJPCTwHXAT6IOMLMM8GXgQ8A7gJvN7B1tnldqVHfszqmr9+ogMD1T4NMP7I/M+omT3ikiw6OtAODuT7l7o8vDS4Bn3P1Zd38d+BZwbTvnlcXq1fKHUwEirCRDI8rdFxlO3UgDzQO/rnp+pPyzUGa20cz2mNmeY8eOdbxxw6JRLf84e/BC4/ROERkeDQOAmf3QzJ4M+Yp7FR9WNizyMtTdt7n7hLtPjI+PxzyFRF2lj5gxPVOINYyTy2b42KXLlLsvkhINs4Dc/YNtnuMIcH7V8/OAo22+p9QIy9eH0uTu7d85wNhotu5GLtqHVyR9upEG+gRwgZmtAArATcCfduG8qRJ03J9+YP+icf654jynLxkhl80syvf/2KXL+OzkRd1sqoj0iXbTQD9iZkeA9wKPmNnO8s/PNbNHAdz9BHAbsBN4CnjA3VvfVHbIxUnljDK5Jr+gRHO1V+aKbFibXzAe58BDewuxz9FO20Sk/2glcB8JW5Wby2aaGodfN7UrtLRDUNMn6rVGC72SaNsgChbNaRW0DIpmVgKrGFwfaZTKGUe9KpyNMoU63bZBE2dthcggUwDoI8100FHDMfWqcLZTo7+d4DGo0hj0JF1UC6iPnJXLMju3OFMnSOUMhh5qh2OCK1M4VYEzbJgiqrJnnDz/RlVDh1Eag56ki+4A+sT0TIFXXz8R+lqQyhlc5bd6ZdpOjf40bvCiXc1k2OkOoA8ENXrqlWkIOvjJNfnI7RvjXJk2qtEfNekZ/E6aJkTbuWMSGQQKAD3WTI2eo7NzTM8UQqt2wsIr01ayV1odWhpWaQx6ki4KAB0StwOOW6MHSh381p2HQjt/g8qVaaOOPEq9oaW0dnppC3qSLpoD6IBm0gfjTig2SuV0Fl6xtjJHoElPkXTRHUAHNOqAq+8MRk/L8Orri+8ADBgbzTJ7vLjgDiLYyatWfiy3YKevMI068jRm+oikmQJAB0R1tMGdQPXQTJSzclm2XL1q0fBD1MTkZReOhxaDq9aoI9ekp0i6KAC0KGxf3aCiZtSVNBB7vH92rhg6bh81MdloLiFOR65JT5F0US2gFoTVxQnkshk2rM3z0N5C7M6+njh1egBWbH4kcpMFlXoWSQ/VAuqwelfbc8V5Hnv6WGXBVbviTsBGDe8EAUSdv4jUUgBoQaNOuTA7x9adh9i0fmXodmjNiDsBm8aVuiLSHs0B0PyiqaiaPdWCCd9Gx45mR1h65ukUZucWLfBqpgPX+L2INCv1AaCVRVMW87J+rjjPGdnFO3EtPOYkvyiP8bdbe16LlkSkGakPAK2sfp2ts7du2LGfv3F1ZK2f6iEedeAi0k2pDwD1Vr9GXZHXS/Osde5YrtKpK8deRPpJu3sC32BmB83spJlFph2Z2XNmdsDM9plZX+V1Rk2yjo1mI8s5hE24ZkeMbGbh2FB1B99OKWYRkU5o9w7gSeA64Ksxjr3M3X/b5vkSF7X61X3xoq1gaCjIyw/uDsZGs7iXFm/VLgqrXcSlDl9E+kVbdwDu/pS7D/T+eFFX5q9EZO4EQ0aTa/I8vvlyPn/jav65eLKS6TPvXrnyV2cvIv2sW3MADnzfzBz4qrtv69J5Ywm7Mo8qqla7PaNKKIvIoGp4B2BmPzSzJ0O+rm3iPOvc/d3Ah4C/NrM/qnO+jWa2x8z2HDt2rIlTJCtsnB8Wb8+oEsoiMqgaBgB3/6C7vzPk63txT+LuR8vfXwS+C1xS59ht7j7h7hPj4+NxT5G4YGgoE5L0X13aWfvGisig6ngpCDM708zeGDwGrqA0edz3JtfkORlRLC+4wlcJBhEZVG3NAZjZR4D/BIwDj5jZPndfb2bnAl9396uAtwLftdKV9BLgv7v7/2iz3R0RlvffaJMUlWAQkUGlctBlYSWeo0o757IZ5fCLSF9SOegWRGXzVJd21gIuERkmqS8FEaiXzaMFXCIyjHQHUKZsHhFJm6EMANMzBdZN7WLF5kdYN7WrkrNfj7J5RCRthm4SOGwyNztivOGMJcweL9bN0mm3Hr+ISK81Mwk8dHMAYZO5xZPOy+Ua/vU2fNFYv4ikydANAcUpwVC9kldEJK2G7g4g7mYtnarVo2EkERkUQ3cHEFXErVYnsnv+/fQBPrV9X+gmMiIi/Wbo7gBqSzOclcvy6usnKM6fmuxOKrun+mr/rFy2sidANZWGFpF+NXQBABZP5nZiWKY22yis8w8UyvsLKwiISD8ZygBQqxPZPWHZRvVEZR6JiPTK0M0BxNHKQrFazU4izxXn+eT2fS2fT0Qkaam4A4BTw0CF2TmM0h6VUH9dQD1xs41qtXo+EZGkpeIOIBivDzrs2rXPrawLCMs2yo4YS0ezDX9X6xBEpB+kIgDcueNgw/H6Zod0gi0jq8tEb73hYmbuuIIv3Li6YSqq9gwWkV4b+iGg6ZlC3QydQCvrAqImlyfX5Nnz/Evcv/vworuNds4nIpKkob8DiDPU0omqn489fSyy81eVURHpB20FADPbamZPm9nPzey7ZjYWcdyVZnbIzJ4xs83tnLNZjYZaOrXDV73zakcxEekH7Q4B/QC43d1PmNnngNuBf1d9gJllgC8DfwwcAZ4wsx3u/os2zx1LVLbO0tEsM3dc0fXz5sdy6vxFpC+0dQfg7t939xPlp7uB80IOuwR4xt2fdffXgW8B17Zz3mZEbfSy5epVPTmvhn5EpF8kOQn8F8D2kJ/ngV9XPT8CvCfB89ZVWxuoWxU6e3VeEZG4GgYAM/sh8LaQlz7j7t8rH/MZ4ARwf9hbhPwschsyM9sIbARYtmxZo+bF0quNXrTBjIj0s4YBwN0/WO91M7sF+BPgAx6+v+QR4Pyq5+cBR+ucbxuwDUpbQjZqn4iItKbdLKArKU36XuPuxyMOewK4wMxWmNlpwE3AjnbOKyIi7Wt3HcCXgDcCPzCzfWb2FQAzO9fMHgUoTxLfBuwEngIecPeDbZ5XRETa1NYksLv/QcTPjwJXVT1/FHi0nXOJiEiyhn4lsIiIhFMAEBFJKQtP3OkPZnYMeL7mx2cDv+1Bc1oxKG0dlHbC4LR1UNoJamsn9LKd/9Ldx+Mc2NcBIIyZ7XH3iV63I45BaeugtBMGp62D0k5QWzthUNqpISARkZRSABARSalBDADbet2AJgxKWwelnTA4bR2UdoLa2gkD0c6BmwMQEZFkDOIdgIiIJKDvA8Ag7DpWPv8NZnbQzE6aWeTsv5k9Z2YHyqUz9nSzjVVtiNvWnn6m5Ta8ycx+YGb/VP6+NOK4+fJnus/MulZrqtFnZGanm9n28us/NbPl3WpbSFsMVRQIAAADk0lEQVQatfXjZnas6nP8yx618xtm9qKZPRnxupnZ35b/HT83s3d3u43ldjRq5/vN7JWqz/OObrexIXfv6y/gCmBJ+fHngM+FHJMBfgm8HTgN2A+8o8vt/ENgJfBjYKLOcc8BZ/f4M23Y1n74TMvt+I/A5vLjzWH//+XXft+DtjX8jIC/Ar5SfnwTsL1H/+dx2vpx4Eu9aF9NO/4IeDfwZMTrVwH/SKnU/KXAT/u0ne8H/qHXn2e9r76/A/AB2HUMwN2fcvfGO9D3gZht7flnWnYtcG/58b3AZA/aECXOZ1Td/geBD5hZ2B4ZndYv/58NuftPgJfqHHIt8PdeshsYM7NzutO6U2K0s+/1fQCo8ReUIn+tsF3H+nUnFge+b2Z7y5vf9Kt++Uzf6u4vAJS/vyXiuDPMbI+Z7TazbgWJOJ9R5ZjyhcwrwJu70rqIdpRF/X9uKA+rPGhm54e83g/65W8zjvea2X4z+0cz6+w+tC1IckvIlnV717FWxWlnDOvc/aiZvYVSGe2ny1cSiUqgrV35TKF+W5t4m2Xlz/XtwC4zO+Duv0ymhZHifEZd+xwbiNOOh4FvuvtrZnYrpTuXyzvesub1y2fayM8olWX4vZldBUwDF/S4TQv0RQDwLu861qpG7Yz5HkfL3180s+9SujVPPAAk0NaufKZQv61m9hszO8fdXyjf5r8Y8R7B5/qsmf0YWENpzLuT4nxGwTFHzGwJcBa9GTZo2FZ3/13V069RmnPrR13722yHu//fqsePmtl/NrOz3b1vahn1/RDQMO06ZmZnmtkbg8eUJrhDMwj6QL98pjuAW8qPbwEW3b2Y2VIzO738+GxgHfCLLrQtzmdU3f7rgV0RFzGd1rCtNePo11DawKkf7QD+vJwNdCnwSjBM2E/M7G3BfI+ZXUKpv/1d/d/qsl7PQjf6Ap6hNN63r/wVZFScCzxaddxVwP+hdNX3mR608yOUrkxeA34D7KxtJ6UMjP3lr4O9aGfctvbDZ1puw5uBHwH/VP7+pvLPJ4Cvlx+/DzhQ/lwPAJ/oYvsWfUbA3ZQuWADOAL5d/jv+38Dbe/E5xmzrPeW/y/3AY8CFPWrnN4EXgGL57/QTwK3AreXXDfhy+d9xgDpZdz1u521Vn+du4H29+r+P+tJKYBGRlOr7ISAREekMBQARkZRSABARSSkFABGRlFIAEBFJKQUAEZGUUgAQEUkpBQARkZT6/yMMciLdP5xFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(sklearn_pred, keras_pred)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../data/test2_pdf.pdf\", bbox_inches='tight') # write pdf to local disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ../data/test_pdf.pdf to Amazon S3 bucket mlsquare-datasets\n",
      "..."
     ]
    }
   ],
   "source": [
    "### Test upload to AWS S3 ###\n",
    "import boto\n",
    "import sys\n",
    "from boto.s3.key import Key\n",
    "# from boto.s3.key import Key\n",
    "bucket_name = 'mlsquare-datasets'\n",
    "AWS_ACCESS_KEY_ID = 'AKIAJXRNK62PGFLPIJTA'\n",
    "AWS_SECRET_ACCESS_KEY = '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'\n",
    "REGION_HOST = 's3.ap-south-1.amazonaws.com'\n",
    "\n",
    "# bucket_name = AWS_ACCESS_KEY_ID.lower() + '-dump'\n",
    "conn = boto.connect_s3(AWS_ACCESS_KEY_ID,\n",
    "        AWS_SECRET_ACCESS_KEY, host=REGION_HOST)\n",
    "bucket = conn.get_bucket('mlsquare-pdf', validate=False)\n",
    "\n",
    "# bucket = conn.create_bucket(bucket_name,\n",
    "#     location=boto.s3.connection.Location.DEFAULT)\n",
    "\n",
    "testfile = \"../data/test_pdf.pdf\"\n",
    "print ('Uploading %s to Amazon S3 bucket %s' % (testfile, bucket_name))\n",
    "\n",
    "def percent_cb(complete, total):\n",
    "    sys.stdout.write('.')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "k = Key(bucket)\n",
    "k.key = 'my test file'\n",
    "k.set_contents_from_filename(testfile,\n",
    "    cb=percent_cb, num_cb=10) # upload file\n",
    "url = k.generate_url(expires_in=0, query_auth=False) # get url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/uci_abalone_logistic.pdf'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'uci_abalone'\n",
    "algo = 'logistic'\n",
    "'../data/' + ('_').join([name,algo]) + '.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
